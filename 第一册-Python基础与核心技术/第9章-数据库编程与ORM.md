# ç¬¬9ç« ï¼šæ•°æ®åº“ç¼–ç¨‹ä¸ORM - æ•°æ®æŒä¹…åŒ–çš„è‰ºæœ¯

> **æ ¸å¿ƒæ€æƒ³**ï¼šæ•°æ®åº“å°±åƒä¸€ä¸ªæ™ºèƒ½åŒ–çš„å›¾ä¹¦é¦†ï¼Œä¸ä»…è¦èƒ½å­˜å‚¨å¤§é‡çš„ä¹¦ç±ï¼ˆæ•°æ®ï¼‰ï¼Œè¿˜è¦æä¾›é«˜æ•ˆçš„æ£€ç´¢ã€åˆ†ç±»ã€å€Ÿé˜…ç®¡ç†ç³»ç»Ÿï¼Œç¡®ä¿ä¿¡æ¯çš„å‡†ç¡®æ€§ã€å®Œæ•´æ€§å’Œå¯è®¿é—®æ€§ã€‚

## æœ¬ç« å­¦ä¹ ç›®æ ‡

é€šè¿‡æœ¬ç« å­¦ä¹ ï¼Œæ‚¨å°†æŒæ¡ï¼š
1. **æ•°æ®åº“åŸºç¡€ç†è®º**ï¼šå…³ç³»å‹æ•°æ®åº“çš„æ ¸å¿ƒæ¦‚å¿µå’Œè®¾è®¡åŸåˆ™
2. **SQLè¯­è¨€ç²¾é€š**ï¼šä»åŸºç¡€æŸ¥è¯¢åˆ°é«˜çº§ä¼˜åŒ–çš„å®Œæ•´SQLæŠ€èƒ½
3. **Pythonæ•°æ®åº“ç¼–ç¨‹**ï¼šä½¿ç”¨Pythonè¿›è¡Œæ•°æ®åº“æ“ä½œçš„æœ€ä½³å®è·µ
4. **ORMæ¡†æ¶åº”ç”¨**ï¼šç°ä»£å¯¹è±¡å…³ç³»æ˜ å°„æŠ€æœ¯çš„æ·±åº¦åº”ç”¨
5. **æ•°æ®åº“è®¾è®¡ä¸ä¼˜åŒ–**ï¼šé«˜æ€§èƒ½æ•°æ®åº“æ¶æ„çš„è®¾è®¡å’Œè°ƒä¼˜
6. **NoSQLæ•°æ®åº“**ï¼šç°ä»£éå…³ç³»å‹æ•°æ®åº“çš„åº”ç”¨åœºæ™¯

## æœ¬ç« çŸ¥è¯†ç»“æ„

```mermaid
graph TD
    A[ç¬¬9ç« ï¼šæ•°æ®åº“ç¼–ç¨‹ä¸ORM] --> B[9.1 æ•°æ®åº“åŸºç¡€ä¸SQL]
    A --> C[9.2 Pythonæ•°æ®åº“ç¼–ç¨‹]
    A --> D[9.3 ORMæ¡†æ¶è¯¦è§£]
    A --> E[9.4 æ•°æ®åº“è®¾è®¡ä¸ä¼˜åŒ–]
    A --> F[9.5 NoSQLä¸ç°ä»£æ•°æ®å­˜å‚¨]
    
    B --> B1[å…³ç³»å‹æ•°æ®åº“ç†è®º]
    B --> B2[SQLè¯­è¨€æ ¸å¿ƒ]
    B --> B3[æ•°æ®åº“è®¾è®¡åŸåˆ™]
    
    C --> C1[æ•°æ®åº“è¿æ¥ç®¡ç†]
    C --> C2[äº‹åŠ¡å¤„ç†]
    C --> C3[è¿æ¥æ± æŠ€æœ¯]
    
    D --> D1[SQLAlchemyæ ¸å¿ƒ]
    D --> D2[æ¨¡å‹å®šä¹‰ä¸å…³ç³»]
    D --> D3[æŸ¥è¯¢æ„å»ºå™¨]
    
    E --> E1[æ€§èƒ½ä¼˜åŒ–ç­–ç•¥]
    E --> E2[ç´¢å¼•è®¾è®¡]
    E --> E3[æŸ¥è¯¢ä¼˜åŒ–]
    
    F --> F1[MongoDBåº”ç”¨]
    F --> F2[Redisç¼“å­˜]
    F --> F3[æ•°æ®å­˜å‚¨é€‰å‹]
```

---

## 9.1 æ•°æ®åº“åŸºç¡€ä¸SQL - æ•°æ®ç®¡ç†çš„åŸºçŸ³

> **æ¯”å–»ç†è§£**ï¼šå…³ç³»å‹æ•°æ®åº“å°±åƒä¸€ä¸ªç°ä»£åŒ–çš„å›¾ä¹¦é¦†ç®¡ç†ç³»ç»Ÿï¼Œæ¯ä¸ªè¡¨å°±æ˜¯ä¸€ä¸ªä¹¦æ¶ï¼Œæ¯è¡Œæ•°æ®å°±æ˜¯ä¸€æœ¬ä¹¦ï¼Œæ¯åˆ—å°±æ˜¯ä¹¦çš„å±æ€§ï¼ˆæ ‡é¢˜ã€ä½œè€…ã€ISBNç­‰ï¼‰ï¼Œè€ŒSQLå°±æ˜¯å›¾ä¹¦ç®¡ç†å‘˜ç”¨æ¥æŸ¥æ‰¾ã€æ•´ç†ã€å€Ÿé˜…å›¾ä¹¦çš„æ ‡å‡†åŒ–æ“ä½œè¯­è¨€ã€‚

### 9.1.1 å…³ç³»å‹æ•°æ®åº“æ ¸å¿ƒæ¦‚å¿µ

#### ğŸ“š æ•°æ®åº“ç†è®ºåŸºç¡€

```python
# database/db_concepts.py
from dataclasses import dataclass
from typing import List, Dict, Any, Optional, Union
from enum import Enum
import sqlite3
import json
from datetime import datetime

class DataType(Enum):
    """æ•°æ®ç±»å‹æšä¸¾ - å›¾ä¹¦é¦†çš„åˆ†ç±»æ ‡ç­¾"""
    INTEGER = "INTEGER"
    TEXT = "TEXT"
    REAL = "REAL"
    BLOB = "BLOB"
    BOOLEAN = "BOOLEAN"
    DATETIME = "DATETIME"

@dataclass
class Column:
    """
    åˆ—å®šä¹‰ - å›¾ä¹¦å±æ€§å®šä¹‰
    å°±åƒå›¾ä¹¦é¦†ä¸ºæ¯æœ¬ä¹¦å®šä¹‰çš„å±æ€§ï¼šä¹¦åã€ä½œè€…ã€ISBNç­‰
    """
    name: str
    data_type: DataType
    primary_key: bool = False
    not_null: bool = False
    unique: bool = False
    default: Any = None
    foreign_key: Optional[str] = None
    
    def to_sql(self) -> str:
        """è½¬æ¢ä¸ºSQLåˆ—å®šä¹‰"""
        sql_parts = [f"{self.name} {self.data_type.value}"]
        
        if self.primary_key:
            sql_parts.append("PRIMARY KEY")
        if self.not_null:
            sql_parts.append("NOT NULL")
        if self.unique:
            sql_parts.append("UNIQUE")
        if self.default is not None:
            if isinstance(self.default, str):
                sql_parts.append(f"DEFAULT '{self.default}'")
            else:
                sql_parts.append(f"DEFAULT {self.default}")
        if self.foreign_key:
            sql_parts.append(f"REFERENCES {self.foreign_key}")
        
        return " ".join(sql_parts)

@dataclass
class Table:
    """
    è¡¨å®šä¹‰ - å›¾ä¹¦é¦†çš„ä¹¦æ¶
    æ¯ä¸ªä¹¦æ¶æœ‰ç‰¹å®šçš„ä¸»é¢˜å’Œç»„ç»‡æ–¹å¼
    """
    name: str
    columns: List[Column]
    description: str = ""
    
    def get_primary_key(self) -> Optional[Column]:
        """è·å–ä¸»é”®åˆ—"""
        for column in self.columns:
            if column.primary_key:
                return column
        return None
    
    def get_column(self, name: str) -> Optional[Column]:
        """æ ¹æ®åç§°è·å–åˆ—"""
        for column in self.columns:
            if column.name == name:
                return column
        return None
    
    def to_create_sql(self) -> str:
        """ç”ŸæˆCREATE TABLEè¯­å¥"""
        column_definitions = [col.to_sql() for col in self.columns]
        columns_sql = ",\n    ".join(column_definitions)
        
        return f"""CREATE TABLE {self.name} (
    {columns_sql}
);"""

class DatabaseSchema:
    """
    æ•°æ®åº“æ¨¡å¼ - å›¾ä¹¦é¦†çš„æ•´ä½“å¸ƒå±€è®¾è®¡
    å®šä¹‰æ‰€æœ‰è¡¨åŠå…¶å…³ç³»
    """
    
    def __init__(self, name: str):
        self.name = name
        self.tables: Dict[str, Table] = {}
        self.relationships: List[Dict[str, str]] = []
    
    def add_table(self, table: Table):
        """æ·»åŠ è¡¨"""
        self.tables[table.name] = table
    
    def add_relationship(self, from_table: str, from_column: str, 
                        to_table: str, to_column: str, relationship_type: str = "many_to_one"):
        """æ·»åŠ è¡¨å…³ç³»"""
        self.relationships.append({
            'from_table': from_table,
            'from_column': from_column,
            'to_table': to_table,
            'to_column': to_column,
            'type': relationship_type
        })
    
    def get_table(self, name: str) -> Optional[Table]:
        """è·å–è¡¨å®šä¹‰"""
        return self.tables.get(name)
    
    def generate_schema_sql(self) -> str:
        """ç”Ÿæˆå®Œæ•´çš„æ•°æ®åº“æ¨¡å¼SQL"""
        sql_statements = []
        
        # æ·»åŠ æ³¨é‡Š
        sql_statements.append(f"-- æ•°æ®åº“æ¨¡å¼: {self.name}")
        sql_statements.append(f"-- ç”Ÿæˆæ—¶é—´: {datetime.now().isoformat()}")
        sql_statements.append("")
        
        # ç”Ÿæˆè¡¨åˆ›å»ºè¯­å¥
        for table in self.tables.values():
            sql_statements.append(f"-- è¡¨: {table.name}")
            if table.description:
                sql_statements.append(f"-- æè¿°: {table.description}")
            sql_statements.append(table.to_create_sql())
            sql_statements.append("")
        
        return "\n".join(sql_statements)
    
    def validate_schema(self) -> List[str]:
        """éªŒè¯æ•°æ®åº“æ¨¡å¼"""
        errors = []
        
        # æ£€æŸ¥æ¯ä¸ªè¡¨æ˜¯å¦æœ‰ä¸»é”®
        for table_name, table in self.tables.items():
            if not table.get_primary_key():
                errors.append(f"è¡¨ {table_name} ç¼ºå°‘ä¸»é”®")
        
        # æ£€æŸ¥å¤–é”®å¼•ç”¨
        for relationship in self.relationships:
            from_table = relationship['from_table']
            to_table = relationship['to_table']
            
            if from_table not in self.tables:
                errors.append(f"å…³ç³»ä¸­çš„æºè¡¨ {from_table} ä¸å­˜åœ¨")
            if to_table not in self.tables:
                errors.append(f"å…³ç³»ä¸­çš„ç›®æ ‡è¡¨ {to_table} ä¸å­˜åœ¨")
        
        return errors

# åˆ›å»ºç¤ºä¾‹æ•°æ®åº“æ¨¡å¼ï¼šå›¾ä¹¦ç®¡ç†ç³»ç»Ÿ
def create_library_schema() -> DatabaseSchema:
    """åˆ›å»ºå›¾ä¹¦ç®¡ç†ç³»ç»Ÿæ•°æ®åº“æ¨¡å¼"""
    schema = DatabaseSchema("å›¾ä¹¦ç®¡ç†ç³»ç»Ÿ")
    
    # ä½œè€…è¡¨
    authors_table = Table(
        name="authors",
        description="ä½œè€…ä¿¡æ¯è¡¨",
        columns=[
            Column("id", DataType.INTEGER, primary_key=True),
            Column("name", DataType.TEXT, not_null=True),
            Column("birth_date", DataType.DATETIME),
            Column("nationality", DataType.TEXT),
            Column("biography", DataType.TEXT),
            Column("created_at", DataType.DATETIME, default="CURRENT_TIMESTAMP")
        ]
    )
    
    # åˆ†ç±»è¡¨
    categories_table = Table(
        name="categories",
        description="å›¾ä¹¦åˆ†ç±»è¡¨",
        columns=[
            Column("id", DataType.INTEGER, primary_key=True),
            Column("name", DataType.TEXT, not_null=True, unique=True),
            Column("description", DataType.TEXT),
            Column("parent_id", DataType.INTEGER, foreign_key="categories(id)")
        ]
    )
    
    # å›¾ä¹¦è¡¨
    books_table = Table(
        name="books",
        description="å›¾ä¹¦ä¿¡æ¯è¡¨",
        columns=[
            Column("id", DataType.INTEGER, primary_key=True),
            Column("isbn", DataType.TEXT, not_null=True, unique=True),
            Column("title", DataType.TEXT, not_null=True),
            Column("author_id", DataType.INTEGER, not_null=True, foreign_key="authors(id)"),
            Column("category_id", DataType.INTEGER, not_null=True, foreign_key="categories(id)"),
            Column("publication_date", DataType.DATETIME),
            Column("pages", DataType.INTEGER),
            Column("price", DataType.REAL),
            Column("stock_quantity", DataType.INTEGER, default=0),
            Column("description", DataType.TEXT),
            Column("created_at", DataType.DATETIME, default="CURRENT_TIMESTAMP"),
            Column("updated_at", DataType.DATETIME, default="CURRENT_TIMESTAMP")
        ]
    )
    
    # è¯»è€…è¡¨
    readers_table = Table(
        name="readers",
        description="è¯»è€…ä¿¡æ¯è¡¨",
        columns=[
            Column("id", DataType.INTEGER, primary_key=True),
            Column("card_number", DataType.TEXT, not_null=True, unique=True),
            Column("name", DataType.TEXT, not_null=True),
            Column("email", DataType.TEXT, unique=True),
            Column("phone", DataType.TEXT),
            Column("address", DataType.TEXT),
            Column("registration_date", DataType.DATETIME, default="CURRENT_TIMESTAMP"),
            Column("is_active", DataType.BOOLEAN, default=True)
        ]
    )
    
    # å€Ÿé˜…è®°å½•è¡¨
    borrowings_table = Table(
        name="borrowings",
        description="å€Ÿé˜…è®°å½•è¡¨",
        columns=[
            Column("id", DataType.INTEGER, primary_key=True),
            Column("reader_id", DataType.INTEGER, not_null=True, foreign_key="readers(id)"),
            Column("book_id", DataType.INTEGER, not_null=True, foreign_key="books(id)"),
            Column("borrow_date", DataType.DATETIME, not_null=True, default="CURRENT_TIMESTAMP"),
            Column("due_date", DataType.DATETIME, not_null=True),
            Column("return_date", DataType.DATETIME),
            Column("fine_amount", DataType.REAL, default=0),
            Column("status", DataType.TEXT, default="borrowed")  # borrowed, returned, overdue
        ]
    )
    
    # æ·»åŠ è¡¨åˆ°æ¨¡å¼
    schema.add_table(authors_table)
    schema.add_table(categories_table)
    schema.add_table(books_table)
    schema.add_table(readers_table)
    schema.add_table(borrowings_table)
    
    # æ·»åŠ å…³ç³»
    schema.add_relationship("books", "author_id", "authors", "id")
    schema.add_relationship("books", "category_id", "categories", "id")
    schema.add_relationship("borrowings", "reader_id", "readers", "id")
    schema.add_relationship("borrowings", "book_id", "books", "id")
    schema.add_relationship("categories", "parent_id", "categories", "id")
    
    return schema

# æ•°æ®åº“æ¦‚å¿µæ¼”ç¤º
def database_concepts_demo():
    """æ•°æ®åº“æ¦‚å¿µæ¼”ç¤º"""
    print("=== æ•°æ®åº“åŸºç¡€æ¦‚å¿µæ¼”ç¤º ===\n")
    
    # 1. åˆ›å»ºå›¾ä¹¦ç®¡ç†ç³»ç»Ÿæ¨¡å¼
    print("ğŸ“š åˆ›å»ºå›¾ä¹¦ç®¡ç†ç³»ç»Ÿæ•°æ®åº“æ¨¡å¼:")
    schema = create_library_schema()
    
    print(f"æ•°æ®åº“åç§°: {schema.name}")
    print(f"è¡¨æ•°é‡: {len(schema.tables)}")
    print(f"å…³ç³»æ•°é‡: {len(schema.relationships)}")
    
    # 2. æ˜¾ç¤ºè¡¨ç»“æ„
    print("\nğŸ“‹ æ•°æ®åº“è¡¨ç»“æ„:")
    for table_name, table in schema.tables.items():
        print(f"\nè¡¨å: {table_name}")
        print(f"æè¿°: {table.description}")
        print("åˆ—å®šä¹‰:")
        for column in table.columns:
            constraints = []
            if column.primary_key:
                constraints.append("PK")
            if column.not_null:
                constraints.append("NOT NULL")
            if column.unique:
                constraints.append("UNIQUE")
            if column.foreign_key:
                constraints.append(f"FKâ†’{column.foreign_key}")
            
            constraint_str = f" ({', '.join(constraints)})" if constraints else ""
            print(f"  - {column.name}: {column.data_type.value}{constraint_str}")
    
    # 3. ç”ŸæˆSQLè¯­å¥
    print("\nğŸ”§ ç”ŸæˆSQLåˆ›å»ºè¯­å¥:")
    sql_statements = schema.generate_schema_sql()
    print("SQLè¯­å¥å·²ç”Ÿæˆï¼ˆéƒ¨åˆ†ç¤ºä¾‹ï¼‰:")
    lines = sql_statements.split('\n')
    for line in lines[:20]:  # æ˜¾ç¤ºå‰20è¡Œ
        print(line)
    if len(lines) > 20:
        print("... (æ›´å¤šå†…å®¹)")
    
    # 4. éªŒè¯æ¨¡å¼
    print("\nâœ… æ•°æ®åº“æ¨¡å¼éªŒè¯:")
    errors = schema.validate_schema()
    if errors:
        print("å‘ç°é—®é¢˜:")
        for error in errors:
            print(f"  âŒ {error}")
    else:
        print("  âœ… æ•°æ®åº“æ¨¡å¼éªŒè¯é€šè¿‡")
    
    # 5. å…³ç³»åˆ†æ
    print("\nğŸ”— è¡¨å…³ç³»åˆ†æ:")
    for relationship in schema.relationships:
        print(f"  {relationship['from_table']}.{relationship['from_column']} "
              f"â†’ {relationship['to_table']}.{relationship['to_column']} "
              f"({relationship['type']})")
    
    print("\nğŸ“Š æ•°æ®åº“è®¾è®¡ç‰¹ç‚¹:")
    print("âœ… è§„èŒƒåŒ–è®¾è®¡: å‡å°‘æ•°æ®å†—ä½™")
    print("âœ… ä¸»é”®çº¦æŸ: ç¡®ä¿æ•°æ®å”¯ä¸€æ€§")
    print("âœ… å¤–é”®çº¦æŸ: ç»´æŠ¤æ•°æ®å®Œæ•´æ€§")
    print("âœ… ç´¢å¼•ä¼˜åŒ–: æé«˜æŸ¥è¯¢æ€§èƒ½")
    print("âœ… æ•°æ®ç±»å‹: åˆç†çš„å­˜å‚¨ç©ºé—´åˆ©ç”¨")

if __name__ == "__main__":
    database_concepts_demo()
```

---

### 9.1.2 SQLè¯­è¨€æ ¸å¿ƒ

> **æ¯”å–»ç†è§£**ï¼šSQLå°±åƒå›¾ä¹¦ç®¡ç†å‘˜çš„å·¥ä½œæ‰‹å†Œï¼Œå®šä¹‰äº†å¦‚ä½•æŸ¥æ‰¾ä¹¦ç±ï¼ˆSELECTï¼‰ã€æ·»åŠ æ–°ä¹¦ï¼ˆINSERTï¼‰ã€æ›´æ–°ä¹¦ç±ä¿¡æ¯ï¼ˆUPDATEï¼‰ã€ç§»é™¤ä¹¦ç±ï¼ˆDELETEï¼‰ï¼Œä»¥åŠå¦‚ä½•ç»„ç»‡å’Œç®¡ç†æ•´ä¸ªå›¾ä¹¦é¦†çš„æ“ä½œè§„èŒƒã€‚

#### ğŸ” SQLæŸ¥è¯¢æ„å»ºå™¨

```python
# database/sql_builder.py
from typing import List, Dict, Any, Optional, Union
from enum import Enum
import re

class JoinType(Enum):
    """è¿æ¥ç±»å‹"""
    INNER = "INNER JOIN"
    LEFT = "LEFT JOIN"
    RIGHT = "RIGHT JOIN"
    FULL = "FULL OUTER JOIN"

class OrderDirection(Enum):
    """æ’åºæ–¹å‘"""
    ASC = "ASC"
    DESC = "DESC"

class SQLBuilder:
    """
    SQLæŸ¥è¯¢æ„å»ºå™¨ - å›¾ä¹¦ç®¡ç†å‘˜çš„æŸ¥è¯¢åŠ©æ‰‹
    å¸®åŠ©æ„å»ºå¤æ‚çš„SQLæŸ¥è¯¢è¯­å¥
    """
    
    def __init__(self):
        self.reset()
    
    def reset(self):
        """é‡ç½®æŸ¥è¯¢æ„å»ºå™¨"""
        self._select_fields = []
        self._from_table = ""
        self._joins = []
        self._where_conditions = []
        self._group_by_fields = []
        self._having_conditions = []
        self._order_by_fields = []
        self._limit_count = None
        self._offset_count = None
        return self
    
    def select(self, *fields) -> 'SQLBuilder':
        """é€‰æ‹©å­—æ®µ"""
        if not fields:
            self._select_fields = ["*"]
        else:
            self._select_fields.extend(fields)
        return self
    
    def from_table(self, table_name: str) -> 'SQLBuilder':
        """æŒ‡å®šä¸»è¡¨"""
        self._from_table = table_name
        return self
    
    def join(self, table: str, on_condition: str, join_type: JoinType = JoinType.INNER) -> 'SQLBuilder':
        """æ·»åŠ è¿æ¥"""
        self._joins.append({
            'type': join_type.value,
            'table': table,
            'condition': on_condition
        })
        return self
    
    def where(self, condition: str) -> 'SQLBuilder':
        """æ·»åŠ WHEREæ¡ä»¶"""
        self._where_conditions.append(condition)
        return self
    
    def where_in(self, field: str, values: List[Any]) -> 'SQLBuilder':
        """æ·»åŠ INæ¡ä»¶"""
        if isinstance(values[0], str):
            value_list = "', '".join(str(v) for v in values)
            condition = f"{field} IN ('{value_list}')"
        else:
            value_list = ", ".join(str(v) for v in values)
            condition = f"{field} IN ({value_list})"
        return self.where(condition)
    
    def where_between(self, field: str, start: Any, end: Any) -> 'SQLBuilder':
        """æ·»åŠ BETWEENæ¡ä»¶"""
        condition = f"{field} BETWEEN {start} AND {end}"
        return self.where(condition)
    
    def where_like(self, field: str, pattern: str) -> 'SQLBuilder':
        """æ·»åŠ LIKEæ¡ä»¶"""
        condition = f"{field} LIKE '{pattern}'"
        return self.where(condition)
    
    def group_by(self, *fields) -> 'SQLBuilder':
        """æ·»åŠ GROUP BY"""
        self._group_by_fields.extend(fields)
        return self
    
    def having(self, condition: str) -> 'SQLBuilder':
        """æ·»åŠ HAVINGæ¡ä»¶"""
        self._having_conditions.append(condition)
        return self
    
    def order_by(self, field: str, direction: OrderDirection = OrderDirection.ASC) -> 'SQLBuilder':
        """æ·»åŠ ORDER BY"""
        self._order_by_fields.append(f"{field} {direction.value}")
        return self
    
    def limit(self, count: int) -> 'SQLBuilder':
        """è®¾ç½®LIMIT"""
        self._limit_count = count
        return self
    
    def offset(self, count: int) -> 'SQLBuilder':
        """è®¾ç½®OFFSET"""
        self._offset_count = count
        return self
    
    def build(self) -> str:
        """æ„å»ºSQLæŸ¥è¯¢"""
        if not self._from_table:
            raise ValueError("å¿…é¡»æŒ‡å®šFROMè¡¨")
        
        # æ„å»ºSELECTéƒ¨åˆ†
        select_part = "SELECT " + ", ".join(self._select_fields)
        
        # æ„å»ºFROMéƒ¨åˆ†
        from_part = f"FROM {self._from_table}"
        
        # æ„å»ºJOINéƒ¨åˆ†
        join_parts = []
        for join in self._joins:
            join_parts.append(f"{join['type']} {join['table']} ON {join['condition']}")
        
        # æ„å»ºWHEREéƒ¨åˆ†
        where_part = ""
        if self._where_conditions:
            where_part = "WHERE " + " AND ".join(f"({cond})" for cond in self._where_conditions)
        
        # æ„å»ºGROUP BYéƒ¨åˆ†
        group_by_part = ""
        if self._group_by_fields:
            group_by_part = "GROUP BY " + ", ".join(self._group_by_fields)
        
        # æ„å»ºHAVINGéƒ¨åˆ†
        having_part = ""
        if self._having_conditions:
            having_part = "HAVING " + " AND ".join(f"({cond})" for cond in self._having_conditions)
        
        # æ„å»ºORDER BYéƒ¨åˆ†
        order_by_part = ""
        if self._order_by_fields:
            order_by_part = "ORDER BY " + ", ".join(self._order_by_fields)
        
        # æ„å»ºLIMITéƒ¨åˆ†
        limit_part = ""
        if self._limit_count is not None:
            limit_part = f"LIMIT {self._limit_count}"
            if self._offset_count is not None:
                limit_part += f" OFFSET {self._offset_count}"
        
        # ç»„åˆæ‰€æœ‰éƒ¨åˆ†
        parts = [select_part, from_part] + join_parts
        if where_part:
            parts.append(where_part)
        if group_by_part:
            parts.append(group_by_part)
        if having_part:
            parts.append(having_part)
        if order_by_part:
            parts.append(order_by_part)
        if limit_part:
            parts.append(limit_part)
        
        return "\n".join(parts) + ";"

class QueryLibrary:
    """
    æŸ¥è¯¢åº“ - å›¾ä¹¦ç®¡ç†å‘˜çš„æŸ¥è¯¢æ‰‹å†Œ
    åŒ…å«å¸¸ç”¨çš„SQLæŸ¥è¯¢æ¨¡æ¿
    """
    
    @staticmethod
    def find_books_by_author(author_name: str) -> str:
        """æ ¹æ®ä½œè€…æŸ¥æ‰¾å›¾ä¹¦"""
        return (SQLBuilder()
                .select("b.title", "b.isbn", "a.name as author_name", "c.name as category")
                .from_table("books b")
                .join("authors a", "b.author_id = a.id")
                .join("categories c", "b.category_id = c.id")
                .where(f"a.name LIKE '%{author_name}%'")
                .order_by("b.title")
                .build())
    
    @staticmethod
    def find_overdue_books() -> str:
        """æŸ¥æ‰¾é€¾æœŸå›¾ä¹¦"""
        return (SQLBuilder()
                .select("r.name as reader_name", "b.title", "br.due_date", 
                       "julianday('now') - julianday(br.due_date) as days_overdue")
                .from_table("borrowings br")
                .join("readers r", "br.reader_id = r.id")
                .join("books b", "br.book_id = b.id")
                .where("br.status = 'borrowed'")
                .where("br.due_date < date('now')")
                .order_by("days_overdue", OrderDirection.DESC)
                .build())
    
    @staticmethod
    def get_popular_books(limit: int = 10) -> str:
        """è·å–çƒ­é—¨å›¾ä¹¦"""
        return (SQLBuilder()
                .select("b.title", "a.name as author", "COUNT(*) as borrow_count")
                .from_table("books b")
                .join("authors a", "b.author_id = a.id")
                .join("borrowings br", "b.id = br.book_id")
                .group_by("b.id", "b.title", "a.name")
                .order_by("borrow_count", OrderDirection.DESC)
                .limit(limit)
                .build())
    
    @staticmethod
    def get_reader_statistics() -> str:
        """è·å–è¯»è€…ç»Ÿè®¡ä¿¡æ¯"""
        return (SQLBuilder()
                .select("r.name", "COUNT(br.id) as total_borrowed", 
                       "SUM(CASE WHEN br.status = 'borrowed' THEN 1 ELSE 0 END) as currently_borrowed",
                       "SUM(br.fine_amount) as total_fines")
                .from_table("readers r")
                .join("borrowings br", "r.id = br.reader_id", JoinType.LEFT)
                .group_by("r.id", "r.name")
                .having("COUNT(br.id) > 0")
                .order_by("total_borrowed", OrderDirection.DESC)
                .build())
    
    @staticmethod
    def get_category_distribution() -> str:
        """è·å–å›¾ä¹¦åˆ†ç±»åˆ†å¸ƒ"""
        return (SQLBuilder()
                .select("c.name as category", "COUNT(b.id) as book_count",
                       "AVG(b.price) as avg_price")
                .from_table("categories c")
                .join("books b", "c.id = b.category_id", JoinType.LEFT)
                .group_by("c.id", "c.name")
                .order_by("book_count", OrderDirection.DESC)
                .build())

class SQLAnalyzer:
    """
    SQLåˆ†æå™¨ - æŸ¥è¯¢æ€§èƒ½é¡¾é—®
    åˆ†æSQLæŸ¥è¯¢çš„å¤æ‚åº¦å’Œæ€§èƒ½ç‰¹å¾
    """
    
    def __init__(self):
        self.query_patterns = {
            'SELECT': r'SELECT\s+(.+?)\s+FROM',
            'FROM': r'FROM\s+(\w+)',
            'JOIN': r'(INNER|LEFT|RIGHT|FULL)\s+JOIN\s+(\w+)',
            'WHERE': r'WHERE\s+(.+?)(?:\s+GROUP\s+BY|\s+ORDER\s+BY|\s+LIMIT|$)',
            'GROUP_BY': r'GROUP\s+BY\s+(.+?)(?:\s+HAVING|\s+ORDER\s+BY|\s+LIMIT|$)',
            'ORDER_BY': r'ORDER\s+BY\s+(.+?)(?:\s+LIMIT|$)',
            'LIMIT': r'LIMIT\s+(\d+)'
        }
    
    def analyze_query(self, sql: str) -> Dict[str, Any]:
        """åˆ†æSQLæŸ¥è¯¢"""
        sql_clean = re.sub(r'\s+', ' ', sql.strip())
        
        analysis = {
            'query_type': self._get_query_type(sql_clean),
            'complexity_score': 0,
            'tables_involved': [],
            'joins_count': 0,
            'has_subquery': 'SELECT' in sql_clean[sql_clean.find('FROM'):],
            'has_aggregation': any(func in sql_clean.upper() for func in ['COUNT', 'SUM', 'AVG', 'MAX', 'MIN']),
            'estimated_performance': 'unknown'
        }
        
        # åˆ†æå„ä¸ªéƒ¨åˆ†
        for pattern_name, pattern in self.query_patterns.items():
            matches = re.findall(pattern, sql_clean, re.IGNORECASE)
            if matches:
                if pattern_name == 'FROM':
                    analysis['tables_involved'].extend(matches)
                elif pattern_name == 'JOIN':
                    analysis['joins_count'] = len(matches)
                    analysis['tables_involved'].extend([match[1] for match in matches])
        
        # è®¡ç®—å¤æ‚åº¦å¾—åˆ†
        analysis['complexity_score'] = self._calculate_complexity(analysis, sql_clean)
        
        # ä¼°ç®—æ€§èƒ½
        analysis['estimated_performance'] = self._estimate_performance(analysis)
        
        return analysis
    
    def _get_query_type(self, sql: str) -> str:
        """è·å–æŸ¥è¯¢ç±»å‹"""
        sql_upper = sql.upper().strip()
        if sql_upper.startswith('SELECT'):
            return 'SELECT'
        elif sql_upper.startswith('INSERT'):
            return 'INSERT'
        elif sql_upper.startswith('UPDATE'):
            return 'UPDATE'
        elif sql_upper.startswith('DELETE'):
            return 'DELETE'
        else:
            return 'OTHER'
    
    def _calculate_complexity(self, analysis: Dict[str, Any], sql: str) -> int:
        """è®¡ç®—æŸ¥è¯¢å¤æ‚åº¦"""
        score = 1  # åŸºç¡€åˆ†æ•°
        
        # è¡¨æ•°é‡å½±å“
        score += len(set(analysis['tables_involved'])) * 2
        
        # JOINæ•°é‡å½±å“
        score += analysis['joins_count'] * 3
        
        # å­æŸ¥è¯¢å½±å“
        if analysis['has_subquery']:
            score += 5
        
        # èšåˆå‡½æ•°å½±å“
        if analysis['has_aggregation']:
            score += 2
        
        # WHEREæ¡ä»¶å¤æ‚åº¦
        where_conditions = len(re.findall(r'AND|OR', sql, re.IGNORECASE))
        score += where_conditions
        
        return score
    
    def _estimate_performance(self, analysis: Dict[str, Any]) -> str:
        """ä¼°ç®—æŸ¥è¯¢æ€§èƒ½"""
        score = analysis['complexity_score']
        
        if score <= 5:
            return 'excellent'
        elif score <= 10:
            return 'good'
        elif score <= 20:
            return 'moderate'
        else:
            return 'poor'

# SQLæ¼”ç¤º
def sql_demo():
    """SQLè¯­è¨€æ ¸å¿ƒæ¼”ç¤º"""
    print("=== SQLè¯­è¨€æ ¸å¿ƒæ¼”ç¤º ===\n")
    
    # 1. SQLæ„å»ºå™¨æ¼”ç¤º
    print("ğŸ”§ SQLæŸ¥è¯¢æ„å»ºå™¨æ¼”ç¤º:")
    
    # ç®€å•æŸ¥è¯¢
    simple_query = (SQLBuilder()
                   .select("title", "author", "price")
                   .from_table("books")
                   .where("price > 50")
                   .order_by("title")
                   .limit(10)
                   .build())
    
    print("ç®€å•æŸ¥è¯¢:")
    print(simple_query)
    
    # å¤æ‚æŸ¥è¯¢
    complex_query = (SQLBuilder()
                    .select("b.title", "a.name as author", "c.name as category", "COUNT(br.id) as borrow_count")
                    .from_table("books b")
                    .join("authors a", "b.author_id = a.id")
                    .join("categories c", "b.category_id = c.id")
                    .join("borrowings br", "b.id = br.book_id", JoinType.LEFT)
                    .where("b.publication_date >= '2020-01-01'")
                    .group_by("b.id", "b.title", "a.name", "c.name")
                    .having("COUNT(br.id) > 0")
                    .order_by("borrow_count", OrderDirection.DESC)
                    .limit(20)
                    .build())
    
    print("\nå¤æ‚æŸ¥è¯¢:")
    print(complex_query)
    
    # 2. æŸ¥è¯¢åº“æ¼”ç¤º
    print("\nğŸ“š å¸¸ç”¨æŸ¥è¯¢æ¨¡æ¿æ¼”ç¤º:")
    
    queries = {
        "æ ¹æ®ä½œè€…æŸ¥æ‰¾å›¾ä¹¦": QueryLibrary.find_books_by_author("å¼ ä¸‰"),
        "æŸ¥æ‰¾é€¾æœŸå›¾ä¹¦": QueryLibrary.find_overdue_books(),
        "è·å–çƒ­é—¨å›¾ä¹¦": QueryLibrary.get_popular_books(5),
        "è¯»è€…ç»Ÿè®¡ä¿¡æ¯": QueryLibrary.get_reader_statistics(),
        "å›¾ä¹¦åˆ†ç±»åˆ†å¸ƒ": QueryLibrary.get_category_distribution()
    }
    
    for query_name, query_sql in queries.items():
        print(f"\n{query_name}:")
        print(query_sql)
    
    # 3. SQLåˆ†æå™¨æ¼”ç¤º
    print("\nğŸ” SQLæŸ¥è¯¢åˆ†æ:")
    analyzer = SQLAnalyzer()
    
    test_queries = [
        simple_query,
        complex_query,
        QueryLibrary.find_overdue_books()
    ]
    
    for i, query in enumerate(test_queries, 1):
        print(f"\næŸ¥è¯¢ {i} åˆ†æç»“æœ:")
        analysis = analyzer.analyze_query(query)
        
        print(f"  æŸ¥è¯¢ç±»å‹: {analysis['query_type']}")
        print(f"  å¤æ‚åº¦å¾—åˆ†: {analysis['complexity_score']}")
        print(f"  æ¶‰åŠè¡¨æ•°: {len(set(analysis['tables_involved']))}")
        print(f"  è¿æ¥æ•°é‡: {analysis['joins_count']}")
        print(f"  åŒ…å«èšåˆ: {'æ˜¯' if analysis['has_aggregation'] else 'å¦'}")
        print(f"  æ€§èƒ½ä¼°ç®—: {analysis['estimated_performance']}")
    
    print("\nğŸ“Š SQLæ„å»ºå™¨ç‰¹æ€§:")
    print("âœ… é“¾å¼è°ƒç”¨: æµç•…çš„æŸ¥è¯¢æ„å»ºä½“éªŒ")
    print("âœ… ç±»å‹å®‰å…¨: æšä¸¾çº¦æŸé˜²æ­¢é”™è¯¯")
    print("âœ… æ¨¡æ¿åº“: å¸¸ç”¨æŸ¥è¯¢çš„æ ‡å‡†åŒ–")
    print("âœ… æ€§èƒ½åˆ†æ: è‡ªåŠ¨è¯„ä¼°æŸ¥è¯¢å¤æ‚åº¦")
    print("âœ… å¯è¯»æ€§: ç”Ÿæˆæ ¼å¼åŒ–çš„SQLè¯­å¥")

if __name__ == "__main__":
    sql_demo()
```

---

### 9.1.3 æ•°æ®åº“è®¾è®¡åŸåˆ™ä¸èŒƒå¼

> **æ¯”å–»ç†è§£**ï¼šæ•°æ®åº“èŒƒå¼å°±åƒå›¾ä¹¦é¦†çš„æ•´ç†è§„åˆ™ï¼Œç¬¬ä¸€èŒƒå¼è¦æ±‚æ¯æœ¬ä¹¦éƒ½æœ‰å”¯ä¸€çš„ä½ç½®æ ‡è¯†ï¼Œç¬¬äºŒèŒƒå¼è¦æ±‚ç›¸å…³çš„ä¹¦ç±æ”¾åœ¨åŒä¸€ä¸ªåŒºåŸŸï¼Œç¬¬ä¸‰èŒƒå¼è¦æ±‚æ¶ˆé™¤é‡å¤çš„åˆ†ç±»ä¿¡æ¯ï¼Œç¡®ä¿å›¾ä¹¦é¦†äº•ç„¶æœ‰åºã€ä¾¿äºç®¡ç†ã€‚

#### ğŸ“ æ•°æ®åº“èŒƒå¼ç†è®º

```python
# database/normalization.py
from dataclasses import dataclass
from typing import List, Dict, Any, Set, Tuple
from enum import Enum

class NormalForm(Enum):
    """èŒƒå¼ç±»å‹"""
    UNNORMALIZED = "éèŒƒå¼åŒ–"
    FIRST_NF = "ç¬¬ä¸€èŒƒå¼(1NF)"
    SECOND_NF = "ç¬¬äºŒèŒƒå¼(2NF)"
    THIRD_NF = "ç¬¬ä¸‰èŒƒå¼(3NF)"
    BCNF = "BCèŒƒå¼(BCNF)"

@dataclass
class FunctionalDependency:
    """å‡½æ•°ä¾èµ– - æ•°æ®ä¹‹é—´çš„é€»è¾‘å…³ç³»"""
    determinant: Set[str]  # å†³å®šå› å­
    dependent: Set[str]    # ä¾èµ–å› å­
    
    def __str__(self):
        det_str = ", ".join(sorted(self.determinant))
        dep_str = ", ".join(sorted(self.dependent))
        return f"{det_str} â†’ {dep_str}"

class NormalizationAnalyzer:
    """
    èŒƒå¼åŒ–åˆ†æå™¨ - å›¾ä¹¦é¦†æ•´ç†é¡¾é—®
    åˆ†æè¡¨ç»“æ„çš„èŒƒå¼åŒ–ç¨‹åº¦å¹¶æä¾›ä¼˜åŒ–å»ºè®®
    """
    
    def __init__(self):
        self.violations = []
        self.recommendations = []
    
    def analyze_table(self, table_name: str, columns: List[str], 
                     primary_key: List[str], 
                     functional_dependencies: List[FunctionalDependency]) -> Dict[str, Any]:
        """åˆ†æè¡¨çš„èŒƒå¼åŒ–ç¨‹åº¦"""
        
        analysis = {
            'table_name': table_name,
            'current_normal_form': NormalForm.UNNORMALIZED,
            'violations': [],
            'recommendations': [],
            'functional_dependencies': functional_dependencies
        }
        
        # æ£€æŸ¥ç¬¬ä¸€èŒƒå¼
        if self._check_first_normal_form(columns):
            analysis['current_normal_form'] = NormalForm.FIRST_NF
            
            # æ£€æŸ¥ç¬¬äºŒèŒƒå¼
            if self._check_second_normal_form(columns, primary_key, functional_dependencies):
                analysis['current_normal_form'] = NormalForm.SECOND_NF
                
                # æ£€æŸ¥ç¬¬ä¸‰èŒƒå¼
                if self._check_third_normal_form(columns, primary_key, functional_dependencies):
                    analysis['current_normal_form'] = NormalForm.THIRD_NF
                    
                    # æ£€æŸ¥BCèŒƒå¼
                    if self._check_bcnf(columns, primary_key, functional_dependencies):
                        analysis['current_normal_form'] = NormalForm.BCNF
        
        analysis['violations'] = self.violations.copy()
        analysis['recommendations'] = self.recommendations.copy()
        
        # æ¸…ç©ºè¿è§„è®°å½•
        self.violations.clear()
        self.recommendations.clear()
        
        return analysis
    
    def _check_first_normal_form(self, columns: List[str]) -> bool:
        """æ£€æŸ¥ç¬¬ä¸€èŒƒå¼ï¼šåŸå­æ€§"""
        # ç®€åŒ–æ£€æŸ¥ï¼šå‡è®¾æ‰€æœ‰åˆ—éƒ½æ˜¯åŸå­çš„
        return True
    
    def _check_second_normal_form(self, columns: List[str], primary_key: List[str], 
                                 functional_dependencies: List[FunctionalDependency]) -> bool:
        """æ£€æŸ¥ç¬¬äºŒèŒƒå¼ï¼šæ¶ˆé™¤éƒ¨åˆ†å‡½æ•°ä¾èµ–"""
        if len(primary_key) <= 1:
            return True  # å•ä¸€ä¸»é”®è‡ªåŠ¨æ»¡è¶³2NF
        
        pk_set = set(primary_key)
        non_key_columns = set(columns) - pk_set
        
        for fd in functional_dependencies:
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨éƒ¨åˆ†å‡½æ•°ä¾èµ–
            if (fd.determinant.issubset(pk_set) and 
                fd.determinant != pk_set and 
                fd.dependent.intersection(non_key_columns)):
                
                self.violations.append(
                    f"éƒ¨åˆ†å‡½æ•°ä¾èµ–: {fd} (è¿å2NF)"
                )
                self.recommendations.append(
                    f"å°† {', '.join(fd.dependent)} åˆ†ç¦»åˆ°æ–°è¡¨ä¸­"
                )
                return False
        
        return True
    
    def _check_third_normal_form(self, columns: List[str], primary_key: List[str], 
                                functional_dependencies: List[FunctionalDependency]) -> bool:
        """æ£€æŸ¥ç¬¬ä¸‰èŒƒå¼ï¼šæ¶ˆé™¤ä¼ é€’å‡½æ•°ä¾èµ–"""
        pk_set = set(primary_key)
        non_key_columns = set(columns) - pk_set
        
        for fd in functional_dependencies:
            # æ£€æŸ¥ä¼ é€’ä¾èµ–
            if (fd.determinant.intersection(non_key_columns) and 
                fd.dependent.intersection(non_key_columns) and
                not fd.determinant.intersection(pk_set)):
                
                self.violations.append(
                    f"ä¼ é€’å‡½æ•°ä¾èµ–: {fd} (è¿å3NF)"
                )
                self.recommendations.append(
                    f"å°† {', '.join(fd.determinant | fd.dependent)} åˆ†ç¦»åˆ°æ–°è¡¨ä¸­"
                )
                return False
        
        return True
    
    def _check_bcnf(self, columns: List[str], primary_key: List[str], 
                   functional_dependencies: List[FunctionalDependency]) -> bool:
        """æ£€æŸ¥BCèŒƒå¼ï¼šå†³å®šå› å­å¿…é¡»æ˜¯å€™é€‰é”®"""
        pk_set = set(primary_key)
        
        for fd in functional_dependencies:
            # ç®€åŒ–æ£€æŸ¥ï¼šå†³å®šå› å­åº”è¯¥åŒ…å«ä¸»é”®
            if not fd.determinant.issuperset(pk_set) and fd.determinant != pk_set:
                self.violations.append(
                    f"å†³å®šå› å­ä¸æ˜¯è¶…é”®: {fd} (è¿åBCNF)"
                )
                return False
        
        return True

# æ•°æ®åº“è®¾è®¡æ¼”ç¤º
def database_design_demo():
    """æ•°æ®åº“è®¾è®¡åŸåˆ™æ¼”ç¤º"""
    print("=== æ•°æ®åº“è®¾è®¡åŸåˆ™ä¸èŒƒå¼æ¼”ç¤º ===\n")
    
    # 1. èŒƒå¼åŒ–åˆ†ææ¼”ç¤º
    print("ğŸ“ æ•°æ®åº“èŒƒå¼åˆ†æ:")
    
    # ç¤ºä¾‹ï¼šå­¦ç”Ÿè¯¾ç¨‹è¡¨ï¼ˆè¿å2NFï¼‰
    student_course_data = {
        'name': 'student_courses',
        'columns': ['student_id', 'course_id', 'student_name', 'course_name', 'grade', 'instructor'],
        'primary_key': ['student_id', 'course_id'],
        'functional_dependencies': [
            FunctionalDependency({'student_id'}, {'student_name'}),
            FunctionalDependency({'course_id'}, {'course_name', 'instructor'}),
            FunctionalDependency({'student_id', 'course_id'}, {'grade'})
        ]
    }
    
    analyzer = NormalizationAnalyzer()
    analysis = analyzer.analyze_table(
        student_course_data['name'],
        student_course_data['columns'],
        student_course_data['primary_key'],
        student_course_data['functional_dependencies']
    )
    
    print(f"è¡¨å: {analysis['table_name']}")
    print(f"å½“å‰èŒƒå¼: {analysis['current_normal_form'].value}")
    
    if analysis['violations']:
        print("å‘ç°çš„è¿è§„:")
        for violation in analysis['violations']:
            print(f"  âŒ {violation}")
        
        print("å»ºè®®:")
        for recommendation in analysis['recommendations']:
            print(f"  ğŸ’¡ {recommendation}")
    else:
        print("  âœ… è¡¨ç»“æ„ç¬¦åˆèŒƒå¼è¦æ±‚")
    
    print("\nğŸ“‹ æ•°æ®åº“è®¾è®¡æœ€ä½³å®è·µ:")
    print("âœ… éµå¾ªé€‚å½“çš„èŒƒå¼ï¼šé€šå¸¸3NFè¶³å¤Ÿï¼Œç‰¹æ®Šæƒ…å†µè€ƒè™‘BCNF")
    print("âœ… åˆç†ä½¿ç”¨ç´¢å¼•ï¼šæé«˜æŸ¥è¯¢æ€§èƒ½ï¼Œä½†é¿å…è¿‡åº¦ç´¢å¼•")
    print("âœ… æ•°æ®ç±»å‹é€‰æ‹©ï¼šä½¿ç”¨æœ€åˆé€‚çš„æ•°æ®ç±»å‹èŠ‚çœç©ºé—´")
    print("âœ… çº¦æŸå®šä¹‰ï¼šä¸»é”®ã€å¤–é”®ã€å”¯ä¸€çº¦æŸä¿è¯æ•°æ®å®Œæ•´æ€§")
    print("âœ… å‘½åè§„èŒƒï¼šæ¸…æ™°ä¸€è‡´çš„å‘½åæé«˜å¯ç»´æŠ¤æ€§")
    print("âœ… æ€§èƒ½è€ƒè™‘ï¼šæ ¹æ®æŸ¥è¯¢æ¨¡å¼ä¼˜åŒ–è¡¨ç»“æ„å’Œç´¢å¼•")

if __name__ == "__main__":
    database_design_demo()
```

---

## 9.2 Pythonæ•°æ®åº“ç¼–ç¨‹ - è¿æ¥æ•°æ®ä¸–ç•Œçš„æ¡¥æ¢

> **æ¯”å–»ç†è§£**ï¼šPythonæ•°æ®åº“ç¼–ç¨‹å°±åƒå»ºç«‹å›¾ä¹¦é¦†å’Œè¯»è€…ä¹‹é—´çš„æœåŠ¡å°ï¼Œæä¾›æ ‡å‡†åŒ–çš„å€Ÿé˜…ã€æŸ¥è¯¢ã€å½’è¿˜æœåŠ¡ã€‚DB-APIå°±æ˜¯æœåŠ¡è§„èŒƒï¼Œç¡®ä¿ä¸åŒçš„å›¾ä¹¦é¦†ï¼ˆæ•°æ®åº“ï¼‰éƒ½èƒ½æä¾›ä¸€è‡´çš„æœåŠ¡ä½“éªŒã€‚

### 9.2.1 æ•°æ®åº“è¿æ¥ä¸åŸºç¡€æ“ä½œ

#### ğŸ”Œ Python DB-API 2.0 è§„èŒƒ

```python
# database/db_connection.py
import sqlite3
import threading
import time
import logging
from typing import List, Dict, Any, Optional, Union, Tuple
from contextlib import contextmanager
from dataclasses import dataclass
from datetime import datetime
import json

@dataclass
class ConnectionConfig:
    """æ•°æ®åº“è¿æ¥é…ç½®"""
    database: str
    host: str = "localhost"
    port: int = 5432
    username: str = ""
    password: str = ""
    charset: str = "utf8"
    autocommit: bool = False
    timeout: int = 30

class DatabaseConnection:
    """
    æ•°æ®åº“è¿æ¥ç®¡ç†å™¨ - å›¾ä¹¦é¦†æœåŠ¡å°
    æä¾›æ ‡å‡†åŒ–çš„æ•°æ®åº“è¿æ¥å’Œæ“ä½œæ¥å£
    """
    
    def __init__(self, config: ConnectionConfig):
        self.config = config
        self.connection = None
        self.cursor = None
        self.is_connected = False
        self.transaction_active = False
        self.logger = logging.getLogger(__name__)
        
    def connect(self) -> bool:
        """å»ºç«‹æ•°æ®åº“è¿æ¥"""
        try:
            # è¿™é‡Œä½¿ç”¨SQLiteä½œä¸ºç¤ºä¾‹ï¼Œå®é™…åº”ç”¨ä¸­æ ¹æ®æ•°æ®åº“ç±»å‹é€‰æ‹©é©±åŠ¨
            self.connection = sqlite3.connect(
                self.config.database,
                timeout=self.config.timeout,
                check_same_thread=False  # å…è®¸å¤šçº¿ç¨‹è®¿é—®
            )
            
            # è®¾ç½®è¡Œå·¥å‚ï¼Œè¿”å›å­—å…¸æ ¼å¼ç»“æœ
            self.connection.row_factory = sqlite3.Row
            
            # å¯ç”¨å¤–é”®çº¦æŸ
            self.connection.execute("PRAGMA foreign_keys = ON")
            
            self.cursor = self.connection.cursor()
            self.is_connected = True
            
            self.logger.info(f"æ•°æ®åº“è¿æ¥æˆåŠŸ: {self.config.database}")
            return True
            
        except Exception as e:
            self.logger.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            return False
    
    def disconnect(self):
        """æ–­å¼€æ•°æ®åº“è¿æ¥"""
        try:
            if self.cursor:
                self.cursor.close()
            if self.connection:
                self.connection.close()
            
            self.is_connected = False
            self.transaction_active = False
            self.logger.info("æ•°æ®åº“è¿æ¥å·²æ–­å¼€")
            
        except Exception as e:
            self.logger.error(f"æ–­å¼€è¿æ¥æ—¶å‡ºé”™: {e}")
    
    def execute(self, sql: str, parameters: Tuple = ()) -> int:
        """æ‰§è¡ŒSQLè¯­å¥"""
        if not self.is_connected:
            raise RuntimeError("æ•°æ®åº“æœªè¿æ¥")
        
        try:
            self.cursor.execute(sql, parameters)
            
            # å¦‚æœä¸åœ¨äº‹åŠ¡ä¸­ä¸”ä¸æ˜¯æŸ¥è¯¢è¯­å¥ï¼Œè‡ªåŠ¨æäº¤
            if not self.transaction_active and not sql.strip().upper().startswith('SELECT'):
                self.connection.commit()
            
            return self.cursor.rowcount
            
        except Exception as e:
            self.logger.error(f"SQLæ‰§è¡Œå¤±è´¥: {sql}, é”™è¯¯: {e}")
            if not self.transaction_active:
                self.connection.rollback()
            raise
    
    def execute_many(self, sql: str, parameters_list: List[Tuple]) -> int:
        """æ‰¹é‡æ‰§è¡ŒSQLè¯­å¥"""
        if not self.is_connected:
            raise RuntimeError("æ•°æ®åº“æœªè¿æ¥")
        
        try:
            self.cursor.executemany(sql, parameters_list)
            
            if not self.transaction_active:
                self.connection.commit()
            
            return self.cursor.rowcount
            
        except Exception as e:
            self.logger.error(f"æ‰¹é‡SQLæ‰§è¡Œå¤±è´¥: {sql}, é”™è¯¯: {e}")
            if not self.transaction_active:
                self.connection.rollback()
            raise
    
    def fetch_one(self, sql: str, parameters: Tuple = ()) -> Optional[Dict[str, Any]]:
        """æŸ¥è¯¢å•æ¡è®°å½•"""
        self.execute(sql, parameters)
        row = self.cursor.fetchone()
        return dict(row) if row else None
    
    def fetch_all(self, sql: str, parameters: Tuple = ()) -> List[Dict[str, Any]]:
        """æŸ¥è¯¢æ‰€æœ‰è®°å½•"""
        self.execute(sql, parameters)
        rows = self.cursor.fetchall()
        return [dict(row) for row in rows]
    
    def fetch_many(self, sql: str, size: int, parameters: Tuple = ()) -> List[Dict[str, Any]]:
        """æŸ¥è¯¢æŒ‡å®šæ•°é‡çš„è®°å½•"""
        self.execute(sql, parameters)
        rows = self.cursor.fetchmany(size)
        return [dict(row) for row in rows]
    
    def begin_transaction(self):
        """å¼€å§‹äº‹åŠ¡"""
        if not self.is_connected:
            raise RuntimeError("æ•°æ®åº“æœªè¿æ¥")
        
        if self.transaction_active:
            raise RuntimeError("äº‹åŠ¡å·²ç»å¼€å§‹")
        
        self.connection.execute("BEGIN")
        self.transaction_active = True
        self.logger.debug("äº‹åŠ¡å¼€å§‹")
    
    def commit_transaction(self):
        """æäº¤äº‹åŠ¡"""
        if not self.transaction_active:
            raise RuntimeError("æ²¡æœ‰æ´»åŠ¨çš„äº‹åŠ¡")
        
        try:
            self.connection.commit()
            self.transaction_active = False
            self.logger.debug("äº‹åŠ¡æäº¤æˆåŠŸ")
        except Exception as e:
            self.logger.error(f"äº‹åŠ¡æäº¤å¤±è´¥: {e}")
            self.rollback_transaction()
            raise
    
    def rollback_transaction(self):
        """å›æ»šäº‹åŠ¡"""
        if not self.transaction_active:
            raise RuntimeError("æ²¡æœ‰æ´»åŠ¨çš„äº‹åŠ¡")
        
        try:
            self.connection.rollback()
            self.transaction_active = False
            self.logger.debug("äº‹åŠ¡å›æ»šæˆåŠŸ")
        except Exception as e:
            self.logger.error(f"äº‹åŠ¡å›æ»šå¤±è´¥: {e}")
            raise
    
    @contextmanager
    def transaction(self):
        """äº‹åŠ¡ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        self.begin_transaction()
        try:
            yield self
            self.commit_transaction()
        except Exception as e:
            self.rollback_transaction()
            raise e
    
    def get_table_info(self, table_name: str) -> List[Dict[str, Any]]:
        """è·å–è¡¨ç»“æ„ä¿¡æ¯"""
        sql = f"PRAGMA table_info({table_name})"
        return self.fetch_all(sql)
    
    def get_table_list(self) -> List[str]:
        """è·å–æ‰€æœ‰è¡¨å"""
        sql = "SELECT name FROM sqlite_master WHERE type='table'"
        rows = self.fetch_all(sql)
        return [row['name'] for row in rows]

class DatabaseManager:
    """
    æ•°æ®åº“ç®¡ç†å™¨ - å›¾ä¹¦é¦†æ€»ç®¡ç†å‘˜
    æä¾›é«˜çº§æ•°æ®åº“æ“ä½œå’Œç®¡ç†åŠŸèƒ½
    """
    
    def __init__(self, config: ConnectionConfig):
        self.config = config
        self.connection = DatabaseConnection(config)
        self.schema_version = None
        
    def initialize_database(self, schema_sql: str = None):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        if not self.connection.connect():
            raise RuntimeError("æ— æ³•è¿æ¥åˆ°æ•°æ®åº“")
        
        # åˆ›å»ºç‰ˆæœ¬ç®¡ç†è¡¨
        self._create_version_table()
        
        # æ‰§è¡Œåˆå§‹åŒ–è„šæœ¬
        if schema_sql:
            self._execute_schema(schema_sql)
        
        # åˆ›å»ºç¤ºä¾‹æ•°æ®
        self._create_sample_data()
    
    def _create_version_table(self):
        """åˆ›å»ºæ•°æ®åº“ç‰ˆæœ¬ç®¡ç†è¡¨"""
        sql = """
        CREATE TABLE IF NOT EXISTS db_version (
            version INTEGER PRIMARY KEY,
            applied_at DATETIME DEFAULT CURRENT_TIMESTAMP,
            description TEXT
        )
        """
        self.connection.execute(sql)
    
    def _execute_schema(self, schema_sql: str):
        """æ‰§è¡Œæ•°æ®åº“æ¨¡å¼è„šæœ¬"""
        # åˆ†å‰²SQLè¯­å¥
        statements = [stmt.strip() for stmt in schema_sql.split(';') if stmt.strip()]
        
        with self.connection.transaction():
            for statement in statements:
                if statement:
                    self.connection.execute(statement)
    
    def _create_sample_data(self):
        """åˆ›å»ºç¤ºä¾‹æ•°æ®"""
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ•°æ®
        authors_count = self.connection.fetch_one("SELECT COUNT(*) as count FROM authors")
        if authors_count and authors_count['count'] > 0:
            return
        
        # æ’å…¥ç¤ºä¾‹æ•°æ®
        sample_data = {
            'authors': [
                (1, 'é‡‘åº¸', '1924-03-10', 'ä¸­å›½', 'æ­¦ä¾ å°è¯´å¤§å¸ˆ'),
                (2, 'æ‘ä¸Šæ˜¥æ ‘', '1949-01-12', 'æ—¥æœ¬', 'å½“ä»£æ–‡å­¦å®¶'),
                (3, 'é˜¿åŠ èÂ·å…‹é‡Œæ–¯è’‚', '1890-09-15', 'è‹±å›½', 'æ¨ç†å°è¯´å¥³ç‹')
            ],
            'categories': [
                (1, 'æ–‡å­¦', 'æ–‡å­¦ç±»å›¾ä¹¦'),
                (2, 'ç§‘æŠ€', 'ç§‘æŠ€ç±»å›¾ä¹¦'),
                (3, 'å†å²', 'å†å²ç±»å›¾ä¹¦'),
                (4, 'æ­¦ä¾ ', 'æ­¦ä¾ å°è¯´', 1),
                (5, 'æ¨ç†', 'æ¨ç†å°è¯´', 1)
            ],
            'books': [
                (1, '978-7-108-01234-5', 'å°„é›•è‹±é›„ä¼ ', 1, 4, '1957-01-01', 1200, 45.00, 10),
                (2, '978-7-108-01234-6', 'æŒªå¨çš„æ£®æ—', 2, 1, '1987-01-01', 380, 32.00, 15),
                (3, '978-7-108-01234-7', 'ä¸œæ–¹å¿«è½¦è°‹æ€æ¡ˆ', 3, 5, '1934-01-01', 280, 28.00, 8)
            ],
            'readers': [
                (1, 'R001', 'å¼ ä¸‰', 'zhangsan@email.com', '13800138001', 'åŒ—äº¬å¸‚æœé˜³åŒº'),
                (2, 'R002', 'æå››', 'lisi@email.com', '13800138002', 'ä¸Šæµ·å¸‚æµ¦ä¸œæ–°åŒº'),
                (3, 'R003', 'ç‹äº”', 'wangwu@email.com', '13800138003', 'å¹¿å·å¸‚å¤©æ²³åŒº')
            ]
        }
        
        with self.connection.transaction():
            # æ’å…¥ä½œè€…æ•°æ®
            self.connection.execute_many(
                "INSERT INTO authors (id, name, birth_date, nationality, biography) VALUES (?, ?, ?, ?, ?)",
                sample_data['authors']
            )
            
            # æ’å…¥åˆ†ç±»æ•°æ®
            self.connection.execute_many(
                "INSERT INTO categories (id, name, description, parent_id) VALUES (?, ?, ?, ?)",
                sample_data['categories']
            )
            
            # æ’å…¥å›¾ä¹¦æ•°æ®
            self.connection.execute_many(
                "INSERT INTO books (id, isbn, title, author_id, category_id, publication_date, pages, price, stock_quantity) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)",
                sample_data['books']
            )
            
            # æ’å…¥è¯»è€…æ•°æ®
            self.connection.execute_many(
                "INSERT INTO readers (id, card_number, name, email, phone, address) VALUES (?, ?, ?, ?, ?, ?)",
                sample_data['readers']
            )
    
    def get_database_stats(self) -> Dict[str, Any]:
        """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        stats = {}
        
        tables = self.connection.get_table_list()
        stats['total_tables'] = len(tables)
        stats['table_stats'] = {}
        
        for table in tables:
            if table != 'db_version':
                count_sql = f"SELECT COUNT(*) as count FROM {table}"
                result = self.connection.fetch_one(count_sql)
                stats['table_stats'][table] = result['count'] if result else 0
        
        return stats
    
    def backup_data(self, backup_file: str):
        """å¤‡ä»½æ•°æ®åº“æ•°æ®"""
        tables = self.connection.get_table_list()
        backup_data = {}
        
        for table in tables:
            if table != 'db_version':
                data = self.connection.fetch_all(f"SELECT * FROM {table}")
                backup_data[table] = data
        
        with open(backup_file, 'w', encoding='utf-8') as f:
            json.dump(backup_data, f, ensure_ascii=False, indent=2, default=str)
    
    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        self.connection.disconnect()

# æ•°æ®åº“æ“ä½œæ¼”ç¤º
def database_connection_demo():
    """æ•°æ®åº“è¿æ¥ä¸åŸºç¡€æ“ä½œæ¼”ç¤º"""
    print("=== Pythonæ•°æ®åº“ç¼–ç¨‹æ¼”ç¤º ===\n")
    
    # 1. åˆ›å»ºæ•°æ®åº“é…ç½®
    print("ğŸ”§ æ•°æ®åº“é…ç½®:")
    config = ConnectionConfig(
        database="library.db",
        autocommit=False,
        timeout=30
    )
    print(f"æ•°æ®åº“æ–‡ä»¶: {config.database}")
    print(f"è¶…æ—¶è®¾ç½®: {config.timeout}ç§’")
    
    # 2. åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
    print("\nğŸ—ï¸ åˆå§‹åŒ–æ•°æ®åº“:")
    db_manager = DatabaseManager(config)
    
    # ä½¿ç”¨ä¹‹å‰åˆ›å»ºçš„å›¾ä¹¦ç®¡ç†ç³»ç»Ÿæ¨¡å¼
    from database.db_concepts import create_library_schema
    schema = create_library_schema()
    schema_sql = schema.generate_schema_sql()
    
    try:
        db_manager.initialize_database(schema_sql)
        print("âœ… æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")
        
        # 3. åŸºç¡€æŸ¥è¯¢æ“ä½œ
        print("\nğŸ“Š åŸºç¡€æŸ¥è¯¢æ“ä½œ:")
        
        # æŸ¥è¯¢æ‰€æœ‰ä½œè€…
        authors = db_manager.connection.fetch_all("SELECT * FROM authors")
        print(f"ä½œè€…æ€»æ•°: {len(authors)}")
        for author in authors:
            print(f"  - {author['name']} ({author['nationality']})")
        
        # æŸ¥è¯¢å›¾ä¹¦ä¿¡æ¯ï¼ˆå¸¦è¿æ¥ï¼‰
        books_query = """
        SELECT b.title, a.name as author, c.name as category, b.price
        FROM books b
        JOIN authors a ON b.author_id = a.id
        JOIN categories c ON b.category_id = c.id
        ORDER BY b.title
        """
        books = db_manager.connection.fetch_all(books_query)
        print(f"\nå›¾ä¹¦æ€»æ•°: {len(books)}")
        for book in books:
            print(f"  - ã€Š{book['title']}ã€‹ - {book['author']} ({book['category']}) Â¥{book['price']}")
        
        # 4. äº‹åŠ¡æ“ä½œæ¼”ç¤º
        print("\nğŸ’³ äº‹åŠ¡æ“ä½œæ¼”ç¤º:")
        
        # æ¨¡æ‹Ÿå€Ÿä¹¦æ“ä½œ
        reader_id = 1
        book_id = 1
        
        with db_manager.connection.transaction():
            # æ£€æŸ¥åº“å­˜
            stock_query = "SELECT stock_quantity FROM books WHERE id = ?"
            stock_result = db_manager.connection.fetch_one(stock_query, (book_id,))
            
            if stock_result and stock_result['stock_quantity'] > 0:
                # å‡å°‘åº“å­˜
                db_manager.connection.execute(
                    "UPDATE books SET stock_quantity = stock_quantity - 1 WHERE id = ?",
                    (book_id,)
                )
                
                # åˆ›å»ºå€Ÿé˜…è®°å½•
                db_manager.connection.execute(
                    """INSERT INTO borrowings (reader_id, book_id, borrow_date, due_date, status)
                       VALUES (?, ?, datetime('now'), datetime('now', '+30 days'), 'borrowed')""",
                    (reader_id, book_id)
                )
                
                print("âœ… å€Ÿä¹¦æ“ä½œæˆåŠŸ")
            else:
                print("âŒ åº“å­˜ä¸è¶³ï¼Œå€Ÿä¹¦å¤±è´¥")
                raise Exception("åº“å­˜ä¸è¶³")
        
        # 5. æ•°æ®åº“ç»Ÿè®¡
        print("\nğŸ“ˆ æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯:")
        stats = db_manager.get_database_stats()
        print(f"æ€»è¡¨æ•°: {stats['total_tables']}")
        print("å„è¡¨è®°å½•æ•°:")
        for table, count in stats['table_stats'].items():
            print(f"  - {table}: {count} æ¡è®°å½•")
        
        # 6. æ•°æ®å¤‡ä»½
        print("\nğŸ’¾ æ•°æ®å¤‡ä»½:")
        backup_file = "library_backup.json"
        db_manager.backup_data(backup_file)
        print(f"âœ… æ•°æ®å·²å¤‡ä»½åˆ°: {backup_file}")
        
    except Exception as e:
        print(f"âŒ æ“ä½œå¤±è´¥: {e}")
    
    finally:
        db_manager.close()
        print("\nğŸ”’ æ•°æ®åº“è¿æ¥å·²å…³é—­")
    
    print("\nğŸ“‹ Pythonæ•°æ®åº“ç¼–ç¨‹ç‰¹æ€§:")
    print("âœ… DB-API 2.0æ ‡å‡†: ç»Ÿä¸€çš„æ•°æ®åº“æ¥å£")
    print("âœ… è¿æ¥ç®¡ç†: è‡ªåŠ¨è¿æ¥å’Œæ–­å¼€ç®¡ç†")
    print("âœ… äº‹åŠ¡æ”¯æŒ: å®Œæ•´çš„äº‹åŠ¡æ§åˆ¶æœºåˆ¶")
    print("âœ… å‚æ•°åŒ–æŸ¥è¯¢: é˜²æ­¢SQLæ³¨å…¥æ”»å‡»")
    print("âœ… ä¸Šä¸‹æ–‡ç®¡ç†: è‡ªåŠ¨èµ„æºæ¸…ç†")
    print("âœ… é”™è¯¯å¤„ç†: å®Œå–„çš„å¼‚å¸¸å¤„ç†æœºåˆ¶")

if __name__ == "__main__":
    database_connection_demo()
```

---

### 9.2.2 è¿æ¥æ± æŠ€æœ¯

> **æ¯”å–»ç†è§£**ï¼šè¿æ¥æ± å°±åƒå›¾ä¹¦é¦†çš„æœåŠ¡çª—å£ç®¡ç†ç³»ç»Ÿï¼Œé¢„å…ˆå‡†å¤‡å¤šä¸ªæœåŠ¡çª—å£ï¼ˆè¿æ¥ï¼‰ï¼Œè¯»è€…æ¥å€Ÿä¹¦æ—¶ç›´æ¥åˆ†é…ä¸€ä¸ªç©ºé—²çª—å£ï¼Œç”¨å®Œåå›æ”¶ç»™ä¸‹ä¸€ä½è¯»è€…ä½¿ç”¨ï¼Œé¿å…æ¯æ¬¡éƒ½é‡æ–°å¼€è®¾çª—å£çš„å¼€é”€ã€‚

#### ğŸŠâ€â™‚ï¸ æ•°æ®åº“è¿æ¥æ± å®ç°

```python
# database/connection_pool.py
import sqlite3
import threading
import time
import queue
from typing import Optional, Dict, Any, List
from contextlib import contextmanager
from dataclasses import dataclass
import logging

@dataclass
class PoolConfig:
    """è¿æ¥æ± é…ç½®"""
    min_connections: int = 5      # æœ€å°è¿æ¥æ•°
    max_connections: int = 20     # æœ€å¤§è¿æ¥æ•°
    connection_timeout: int = 30  # è¿æ¥è¶…æ—¶æ—¶é—´
    idle_timeout: int = 300      # ç©ºé—²è¶…æ—¶æ—¶é—´
    retry_attempts: int = 3       # é‡è¯•æ¬¡æ•°

class PooledConnection:
    """
    æ± åŒ–è¿æ¥ - æœåŠ¡çª—å£
    åŒ…è£…æ•°æ®åº“è¿æ¥ï¼Œæ·»åŠ æ± åŒ–ç®¡ç†åŠŸèƒ½
    """
    
    def __init__(self, connection, pool, connection_id: int):
        self.connection = connection
        self.pool = pool
        self.connection_id = connection_id
        self.created_at = time.time()
        self.last_used = time.time()
        self.in_use = False
        self.is_valid = True
    
    def execute(self, sql: str, parameters: tuple = ()):
        """æ‰§è¡ŒSQLè¯­å¥"""
        if not self.is_valid:
            raise RuntimeError("è¿æ¥å·²å¤±æ•ˆ")
        
        self.last_used = time.time()
        cursor = self.connection.cursor()
        cursor.execute(sql, parameters)
        return cursor
    
    def commit(self):
        """æäº¤äº‹åŠ¡"""
        self.connection.commit()
    
    def rollback(self):
        """å›æ»šäº‹åŠ¡"""
        self.connection.rollback()
    
    def close(self):
        """å…³é—­è¿æ¥"""
        if self.connection:
            self.connection.close()
        self.is_valid = False
    
    def is_expired(self, idle_timeout: int) -> bool:
        """æ£€æŸ¥è¿æ¥æ˜¯å¦è¿‡æœŸ"""
        return (time.time() - self.last_used) > idle_timeout
    
    def ping(self) -> bool:
        """æ£€æŸ¥è¿æ¥æ˜¯å¦æœ‰æ•ˆ"""
        try:
            cursor = self.connection.cursor()
            cursor.execute("SELECT 1")
            return True
        except:
            self.is_valid = False
            return False

class ConnectionPool:
    """
    æ•°æ®åº“è¿æ¥æ±  - å›¾ä¹¦é¦†æœåŠ¡çª—å£ç®¡ç†ç³»ç»Ÿ
    ç®¡ç†æ•°æ®åº“è¿æ¥çš„åˆ›å»ºã€åˆ†é…ã€å›æ”¶å’Œæ¸…ç†
    """
    
    def __init__(self, database_path: str, config: PoolConfig = None):
        self.database_path = database_path
        self.config = config or PoolConfig()
        
        # è¿æ¥æ± é˜Ÿåˆ—
        self.available_connections = queue.Queue(maxsize=self.config.max_connections)
        self.all_connections: Dict[int, PooledConnection] = {}
        self.connection_counter = 0
        
        # çº¿ç¨‹é”
        self.lock = threading.RLock()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'created_connections': 0,
            'active_connections': 0,
            'total_requests': 0,
            'failed_requests': 0
        }
        
        # æ—¥å¿—
        self.logger = logging.getLogger(__name__)
        
        # åˆå§‹åŒ–æœ€å°è¿æ¥æ•°
        self._initialize_pool()
        
        # å¯åŠ¨æ¸…ç†çº¿ç¨‹
        self.cleanup_thread = threading.Thread(target=self._cleanup_expired_connections, daemon=True)
        self.cleanup_thread.start()
    
    def _initialize_pool(self):
        """åˆå§‹åŒ–è¿æ¥æ± """
        for _ in range(self.config.min_connections):
            conn = self._create_connection()
            if conn:
                self.available_connections.put(conn)
    
    def _create_connection(self) -> Optional[PooledConnection]:
        """åˆ›å»ºæ–°çš„æ•°æ®åº“è¿æ¥"""
        try:
            with self.lock:
                self.connection_counter += 1
                connection_id = self.connection_counter
            
            # åˆ›å»ºSQLiteè¿æ¥
            raw_connection = sqlite3.connect(
                self.database_path,
                timeout=self.config.connection_timeout,
                check_same_thread=False
            )
            raw_connection.row_factory = sqlite3.Row
            raw_connection.execute("PRAGMA foreign_keys = ON")
            
            # åˆ›å»ºæ± åŒ–è¿æ¥
            pooled_conn = PooledConnection(raw_connection, self, connection_id)
            
            with self.lock:
                self.all_connections[connection_id] = pooled_conn
                self.stats['created_connections'] += 1
            
            self.logger.debug(f"åˆ›å»ºæ–°è¿æ¥: {connection_id}")
            return pooled_conn
            
        except Exception as e:
            self.logger.error(f"åˆ›å»ºè¿æ¥å¤±è´¥: {e}")
            return None
    
    def get_connection(self, timeout: int = 10) -> Optional[PooledConnection]:
        """ä»è¿æ¥æ± è·å–è¿æ¥"""
        with self.lock:
            self.stats['total_requests'] += 1
        
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            try:
                # å°è¯•ä»é˜Ÿåˆ—è·å–è¿æ¥
                conn = self.available_connections.get(timeout=1)
                
                # æ£€æŸ¥è¿æ¥æ˜¯å¦æœ‰æ•ˆ
                if conn.ping():
                    conn.in_use = True
                    with self.lock:
                        self.stats['active_connections'] += 1
                    
                    self.logger.debug(f"åˆ†é…è¿æ¥: {conn.connection_id}")
                    return conn
                else:
                    # è¿æ¥æ— æ•ˆï¼Œç§»é™¤å¹¶åˆ›å»ºæ–°è¿æ¥
                    self._remove_connection(conn)
                    
            except queue.Empty:
                # é˜Ÿåˆ—ä¸ºç©ºï¼Œå°è¯•åˆ›å»ºæ–°è¿æ¥
                if len(self.all_connections) < self.config.max_connections:
                    new_conn = self._create_connection()
                    if new_conn:
                        new_conn.in_use = True
                        with self.lock:
                            self.stats['active_connections'] += 1
                        return new_conn
                
                # ç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•
                time.sleep(0.1)
        
        # è·å–è¿æ¥è¶…æ—¶
        with self.lock:
            self.stats['failed_requests'] += 1
        
        self.logger.warning("è·å–è¿æ¥è¶…æ—¶")
        return None
    
    def return_connection(self, connection: PooledConnection):
        """å½’è¿˜è¿æ¥åˆ°è¿æ¥æ± """
        if not connection or not connection.is_valid:
            return
        
        connection.in_use = False
        connection.last_used = time.time()
        
        with self.lock:
            self.stats['active_connections'] -= 1
        
        # æ£€æŸ¥è¿æ¥æ˜¯å¦ä»ç„¶æœ‰æ•ˆ
        if connection.ping():
            self.available_connections.put(connection)
            self.logger.debug(f"å½’è¿˜è¿æ¥: {connection.connection_id}")
        else:
            self._remove_connection(connection)
    
    def _remove_connection(self, connection: PooledConnection):
        """ä»è¿æ¥æ± ç§»é™¤è¿æ¥"""
        with self.lock:
            if connection.connection_id in self.all_connections:
                del self.all_connections[connection.connection_id]
                if connection.in_use:
                    self.stats['active_connections'] -= 1
        
        connection.close()
        self.logger.debug(f"ç§»é™¤è¿æ¥: {connection.connection_id}")
    
    def _cleanup_expired_connections(self):
        """æ¸…ç†è¿‡æœŸè¿æ¥"""
        while True:
            try:
                time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
                
                expired_connections = []
                with self.lock:
                    for conn in self.all_connections.values():
                        if not conn.in_use and conn.is_expired(self.config.idle_timeout):
                            expired_connections.append(conn)
                
                # æ¸…ç†è¿‡æœŸè¿æ¥ï¼ˆä¿ç•™æœ€å°è¿æ¥æ•°ï¼‰
                current_count = len(self.all_connections)
                for conn in expired_connections:
                    if current_count > self.config.min_connections:
                        self._remove_connection(conn)
                        current_count -= 1
                
            except Exception as e:
                self.logger.error(f"æ¸…ç†è¿‡æœŸè¿æ¥æ—¶å‡ºé”™: {e}")
    
    @contextmanager
    def get_connection_context(self):
        """è¿æ¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        connection = self.get_connection()
        if not connection:
            raise RuntimeError("æ— æ³•è·å–æ•°æ®åº“è¿æ¥")
        
        try:
            yield connection
        finally:
            self.return_connection(connection)
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–è¿æ¥æ± ç»Ÿè®¡ä¿¡æ¯"""
        with self.lock:
            return {
                **self.stats,
                'total_connections': len(self.all_connections),
                'available_connections': self.available_connections.qsize(),
                'pool_config': {
                    'min_connections': self.config.min_connections,
                    'max_connections': self.config.max_connections,
                    'connection_timeout': self.config.connection_timeout,
                    'idle_timeout': self.config.idle_timeout
                }
            }
    
    def close_all(self):
        """å…³é—­æ‰€æœ‰è¿æ¥"""
        with self.lock:
            for conn in self.all_connections.values():
                conn.close()
            self.all_connections.clear()
            
            # æ¸…ç©ºé˜Ÿåˆ—
            while not self.available_connections.empty():
                try:
                    self.available_connections.get_nowait()
                except queue.Empty:
                    break

class DatabaseService:
    """
    æ•°æ®åº“æœåŠ¡ - å›¾ä¹¦é¦†ç®¡ç†æœåŠ¡
    åŸºäºè¿æ¥æ± çš„é«˜çº§æ•°æ®åº“æ“ä½œæ¥å£
    """
    
    def __init__(self, database_path: str, pool_config: PoolConfig = None):
        self.pool = ConnectionPool(database_path, pool_config)
        self.logger = logging.getLogger(__name__)
    
    def execute_query(self, sql: str, parameters: tuple = ()) -> List[Dict[str, Any]]:
        """æ‰§è¡ŒæŸ¥è¯¢è¯­å¥"""
        with self.pool.get_connection_context() as conn:
            cursor = conn.execute(sql, parameters)
            rows = cursor.fetchall()
            return [dict(row) for row in rows]
    
    def execute_update(self, sql: str, parameters: tuple = ()) -> int:
        """æ‰§è¡Œæ›´æ–°è¯­å¥"""
        with self.pool.get_connection_context() as conn:
            cursor = conn.execute(sql, parameters)
            conn.commit()
            return cursor.rowcount
    
    def execute_batch(self, sql: str, parameters_list: List[tuple]) -> int:
        """æ‰¹é‡æ‰§è¡Œè¯­å¥"""
        with self.pool.get_connection_context() as conn:
            cursor = conn.connection.cursor()
            cursor.executemany(sql, parameters_list)
            conn.commit()
            return cursor.rowcount
    
    @contextmanager
    def transaction(self):
        """äº‹åŠ¡ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        with self.pool.get_connection_context() as conn:
            try:
                conn.execute("BEGIN")
                yield conn
                conn.commit()
            except Exception as e:
                conn.rollback()
                raise e
    
    def get_pool_stats(self) -> Dict[str, Any]:
        """è·å–è¿æ¥æ± ç»Ÿè®¡ä¿¡æ¯"""
        return self.pool.get_stats()
    
    def close(self):
        """å…³é—­æ•°æ®åº“æœåŠ¡"""
        self.pool.close_all()

# è¿æ¥æ± æ¼”ç¤º
def connection_pool_demo():
    """è¿æ¥æ± æŠ€æœ¯æ¼”ç¤º"""
    print("=== æ•°æ®åº“è¿æ¥æ± æŠ€æœ¯æ¼”ç¤º ===\n")
    
    # 1. åˆ›å»ºè¿æ¥æ± é…ç½®
    print("ğŸŠâ€â™‚ï¸ è¿æ¥æ± é…ç½®:")
    pool_config = PoolConfig(
        min_connections=3,
        max_connections=10,
        connection_timeout=30,
        idle_timeout=300
    )
    
    print(f"æœ€å°è¿æ¥æ•°: {pool_config.min_connections}")
    print(f"æœ€å¤§è¿æ¥æ•°: {pool_config.max_connections}")
    print(f"è¿æ¥è¶…æ—¶: {pool_config.connection_timeout}ç§’")
    print(f"ç©ºé—²è¶…æ—¶: {pool_config.idle_timeout}ç§’")
    
    # 2. åˆ›å»ºæ•°æ®åº“æœåŠ¡
    print("\nğŸ”§ åˆå§‹åŒ–æ•°æ®åº“æœåŠ¡:")
    db_service = DatabaseService("library_pool.db", pool_config)
    
    # åˆ›å»ºç¤ºä¾‹è¡¨
    db_service.execute_update("""
    CREATE TABLE IF NOT EXISTS books (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        title TEXT NOT NULL,
        author TEXT NOT NULL,
        price REAL,
        created_at DATETIME DEFAULT CURRENT_TIMESTAMP
    )
    """)
    
    print("âœ… æ•°æ®åº“æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
    
    # 3. è¿æ¥æ± åŸºç¡€æ“ä½œ
    print("\nğŸ“Š è¿æ¥æ± åŸºç¡€æ“ä½œ:")
    
    # æ’å…¥ç¤ºä¾‹æ•°æ®
    books_data = [
        ("Pythonç¼–ç¨‹ä»å…¥é—¨åˆ°å®è·µ", "åŸƒé‡Œå…‹Â·é©¬ç‘Ÿæ–¯", 89.0),
        ("æµç•…çš„Python", "å¢è¥¿äºšè¯ºÂ·æ‹‰é©¬ç•¥", 139.0),
        ("Python Cookbook", "å¤§å«Â·æ¯”æ–¯åˆ©", 108.0),
        ("Effective Python", "å¸ƒé›·ç‰¹Â·æ–¯æ‹‰ç‰¹é‡‘", 79.0)
    ]
    
    affected_rows = db_service.execute_batch(
        "INSERT INTO books (title, author, price) VALUES (?, ?, ?)",
        books_data
    )
    print(f"âœ… æ‰¹é‡æ’å…¥ {affected_rows} æ¡è®°å½•")
    
    # æŸ¥è¯¢æ•°æ®
    books = db_service.execute_query("SELECT * FROM books ORDER BY price DESC")
    print(f"ğŸ“š æŸ¥è¯¢åˆ° {len(books)} æœ¬å›¾ä¹¦:")
    for book in books[:3]:  # æ˜¾ç¤ºå‰3æœ¬
        print(f"  - ã€Š{book['title']}ã€‹ - {book['author']} Â¥{book['price']}")
    
    # 4. äº‹åŠ¡æ“ä½œæ¼”ç¤º
    print("\nğŸ’³ äº‹åŠ¡æ“ä½œæ¼”ç¤º:")
    
    try:
        with db_service.transaction() as conn:
            # æ›´æ–°å›¾ä¹¦ä»·æ ¼
            conn.execute("UPDATE books SET price = price * 0.9 WHERE price > 100", ())
            
            # æ’å…¥æ–°è®°å½•
            conn.execute("INSERT INTO books (title, author, price) VALUES (?, ?, ?)",
                        ("æ•°æ®åº“ç³»ç»Ÿæ¦‚å¿µ", "è¥¿å°”ä¼¯æ²™èŒ¨", 158.0))
            
            print("âœ… äº‹åŠ¡æ‰§è¡ŒæˆåŠŸ")
            
    except Exception as e:
        print(f"âŒ äº‹åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
    
    # 5. è¿æ¥æ± ç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“ˆ è¿æ¥æ± ç»Ÿè®¡ä¿¡æ¯:")
    stats = db_service.get_pool_stats()
    
    print(f"æ€»è¿æ¥æ•°: {stats['total_connections']}")
    print(f"å¯ç”¨è¿æ¥æ•°: {stats['available_connections']}")
    print(f"æ´»è·ƒè¿æ¥æ•°: {stats['active_connections']}")
    print(f"å·²åˆ›å»ºè¿æ¥æ•°: {stats['created_connections']}")
    print(f"æ€»è¯·æ±‚æ•°: {stats['total_requests']}")
    print(f"å¤±è´¥è¯·æ±‚æ•°: {stats['failed_requests']}")
    
    # 6. å¹¶å‘æµ‹è¯•
    print("\nğŸ”„ å¹¶å‘æ“ä½œæµ‹è¯•:")
    
    import concurrent.futures
    
    def query_books(thread_id):
        """æ¨¡æ‹Ÿå¹¶å‘æŸ¥è¯¢æ“ä½œ"""
        try:
            books = db_service.execute_query(
                "SELECT COUNT(*) as count FROM books WHERE price > ?", (50.0,)
            )
            return f"çº¿ç¨‹{thread_id}: æŸ¥è¯¢åˆ°{books[0]['count']}æœ¬å›¾ä¹¦"
        except Exception as e:
            return f"çº¿ç¨‹{thread_id}: æŸ¥è¯¢å¤±è´¥ - {e}"
    
    # ä½¿ç”¨çº¿ç¨‹æ± è¿›è¡Œå¹¶å‘æµ‹è¯•
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(query_books, i) for i in range(10)]
        
        for future in concurrent.futures.as_completed(futures):
            result = future.result()
            print(f"  {result}")
    
    # 7. æœ€ç»ˆç»Ÿè®¡
    print("\nğŸ“Š æœ€ç»ˆè¿æ¥æ± çŠ¶æ€:")
    final_stats = db_service.get_pool_stats()
    print(f"æ€»è¯·æ±‚æ•°: {final_stats['total_requests']}")
    print(f"æˆåŠŸç‡: {((final_stats['total_requests'] - final_stats['failed_requests']) / final_stats['total_requests'] * 100):.1f}%")
    
    # æ¸…ç†èµ„æº
    db_service.close()
    print("\nğŸ”’ æ•°æ®åº“æœåŠ¡å·²å…³é—­")
    
    print("\nğŸŠâ€â™‚ï¸ è¿æ¥æ± æŠ€æœ¯ä¼˜åŠ¿:")
    print("âœ… æ€§èƒ½æå‡: é¿å…é¢‘ç¹åˆ›å»ºå’Œé”€æ¯è¿æ¥")
    print("âœ… èµ„æºç®¡ç†: æ§åˆ¶æ•°æ®åº“è¿æ¥æ•°é‡")
    print("âœ… å¹¶å‘æ”¯æŒ: å®‰å…¨çš„å¤šçº¿ç¨‹è®¿é—®")
    print("âœ… è‡ªåŠ¨æ¸…ç†: æ¸…ç†è¿‡æœŸå’Œæ— æ•ˆè¿æ¥")
    print("âœ… ç»Ÿè®¡ç›‘æ§: è¯¦ç»†çš„ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯")

if __name__ == "__main__":
    connection_pool_demo() 