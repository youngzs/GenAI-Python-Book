# ç¬¬22ç«  å·ç§¯ç¥ç»ç½‘ç»œä¸å›¾åƒè¯†åˆ«

## ğŸ¯ å­¦ä¹ ç›®æ ‡

å®Œæˆæœ¬ç« å­¦ä¹ åï¼Œä½ å°†èƒ½å¤Ÿï¼š

### ğŸ“š çŸ¥è¯†ç›®æ ‡
- **ç†è§£è®¡ç®—æœºè§†è§‰æ ¸å¿ƒæ¦‚å¿µ**ï¼šæŒæ¡å›¾åƒæ•°æ®çš„ç‰¹ç‚¹å’Œå¤„ç†æ–¹æ³•
- **æŒæ¡CNNç½‘ç»œæ¶æ„**ï¼šæ·±å…¥ç†è§£å·ç§¯ã€æ± åŒ–ã€å…¨è¿æ¥å±‚çš„å·¥ä½œåŸç†
- **ç†è§£ç‰¹å¾å­¦ä¹ æœºåˆ¶**ï¼šäº†è§£CNNå¦‚ä½•è‡ªåŠ¨å­¦ä¹ å›¾åƒç‰¹å¾çš„å±‚æ¬¡ç»“æ„
- **æŒæ¡å›¾åƒåˆ†ç±»æµç¨‹**ï¼šä»æ•°æ®é¢„å¤„ç†åˆ°æ¨¡å‹éƒ¨ç½²çš„å®Œæ•´pipeline

### ğŸ› ï¸ æŠ€èƒ½ç›®æ ‡
- **æ„å»ºCNNæ¨¡å‹**ï¼šèƒ½å¤Ÿè®¾è®¡å’Œå®ç°å„ç§å·ç§¯ç¥ç»ç½‘ç»œæ¶æ„
- **å¤„ç†å›¾åƒæ•°æ®**ï¼šç†Ÿç»ƒè¿›è¡Œå›¾åƒé¢„å¤„ç†ã€æ•°æ®å¢å¼ºå’Œæ‰¹å¤„ç†
- **è°ƒä¼˜è§†è§‰æ¨¡å‹**ï¼šæŒæ¡CNNæ¨¡å‹çš„è®­ç»ƒæŠ€å·§å’Œæ€§èƒ½ä¼˜åŒ–æ–¹æ³•
- **å¼€å‘è§†è§‰åº”ç”¨**ï¼šå…·å¤‡æ„å»ºå®ç”¨å›¾åƒè¯†åˆ«ç³»ç»Ÿçš„èƒ½åŠ›

### ğŸ§  ç´ å…»ç›®æ ‡
- **åŸ¹å…»è§†è§‰AIæ€ç»´**ï¼šå»ºç«‹å¯¹è®¡ç®—æœºè§†è§‰é—®é¢˜çš„ç³»ç»Ÿæ€§è®¤çŸ¥
- **å¼ºåŒ–å·¥ç¨‹å®è·µæ„è¯†**ï¼šæ³¨é‡æ¨¡å‹çš„å®ç”¨æ€§å’Œéƒ¨ç½²å¯è¡Œæ€§
- **å»ºç«‹åˆ›æ–°åº”ç”¨æ€ç»´**ï¼šèƒ½å¤Ÿå°†CNNæŠ€æœ¯åº”ç”¨åˆ°æ–°çš„è§†è§‰ä»»åŠ¡ä¸­

---

## ğŸ¨ 22.1 æ¬¢è¿æ¥åˆ°è®¡ç®—æœºè§†è§‰å·¥ä½œå®¤ï¼

### ğŸšª ä»å¤§è„‘ç ”ç©¶é™¢åˆ°è§†è§‰å·¥ä½œå®¤çš„å‡çº§

å¦‚æœè¯´ç¬¬21ç« çš„æ·±åº¦å­¦ä¹ æ˜¯**"AIå¤§è„‘ç ”ç©¶é™¢"**ï¼Œé‚£ä¹ˆç¬¬22ç« çš„è®¡ç®—æœºè§†è§‰å°±æ˜¯**"AIè§†è§‰å·¥ä½œå®¤"**ï¼

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä¸å†åªæ˜¯å¤„ç†æ•°å­—å’Œè¡¨æ ¼ï¼Œè€Œæ˜¯è®©AIæ‹¥æœ‰"çœ¼ç›"ï¼Œèƒ½å¤Ÿç†è§£å’Œåˆ†æè§†è§‰ä¸–ç•Œã€‚å°±åƒäººç±»çš„è§†è§‰ç³»ç»Ÿä¸€æ ·ï¼Œæˆ‘ä»¬çš„AIå°†å­¦ä¼šä»åƒç´ ä¸­è¯†åˆ«ç‰©ä½“ã€ç†è§£åœºæ™¯ã€æ„ŸçŸ¥ä¸–ç•Œã€‚

### ğŸ‘ï¸ è®¡ç®—æœºè§†è§‰ vs äººç±»è§†è§‰

```mermaid
graph LR
    subgraph "ğŸ‘ï¸ äººç±»è§†è§‰ç³»ç»Ÿ"
        A1["å…‰çº¿åˆºæ¿€"] --> B1["è§†ç½‘è†œæ¥æ”¶"]
        B1 --> C1["ç¥ç»ä¿¡å·ä¼ é€’"]
        C1 --> D1["å¤§è„‘çš®å±‚å¤„ç†"]
        D1 --> E1["å½¢æˆè§†è§‰è®¤çŸ¥"]
    end
    
    subgraph "ğŸ¤– è®¡ç®—æœºè§†è§‰ç³»ç»Ÿ"
        A2["åƒç´ æ•°æ®"] --> B2["å·ç§¯å±‚æå–ç‰¹å¾"]
        B2 --> C2["æ± åŒ–å±‚é™ç»´"]
        C2 --> D2["å…¨è¿æ¥å±‚åˆ†ç±»"]
        D2 --> E2["è¾“å‡ºè¯†åˆ«ç»“æœ"]
    end
    
    style A1 fill:#e8f5e8
    style A2 fill:#e3f2fd
    style E1 fill:#fff3e0
    style E2 fill:#f3e5f5
```

### ğŸŒŸ è®¡ç®—æœºè§†è§‰çš„æ ¸å¿ƒä¼˜åŠ¿

```python
# ğŸ¨ è®¡ç®—æœºè§†è§‰å·¥ä½œå®¤æ¬¢è¿ä»£ç 
print("ğŸ¨ æ¬¢è¿æ¥åˆ°è®¡ç®—æœºè§†è§‰å·¥ä½œå®¤ï¼")
print("=" * 60)
print("ğŸ‘ï¸ åœ¨è¿™ä¸ªå·¥ä½œå®¤é‡Œï¼Œæˆ‘ä»¬å°†æ¢ç´¢ï¼š")
print("   ğŸ–¼ï¸ å›¾åƒè¯†åˆ«çš„å¥¥ç§˜ - è®©AIå­¦ä¼š'çœ‹'ä¸–ç•Œ")
print("   ğŸ§  CNNç½‘ç»œæ¶æ„ - ä¸“ä¸ºè§†è§‰è®¾è®¡çš„ç¥ç»ç½‘ç»œ")
print("   ğŸ¯ ç‰¹å¾å­¦ä¹ æœºåˆ¶ - ä»è¾¹ç¼˜åˆ°ç‰©ä½“çš„å±‚æ¬¡è®¤çŸ¥")
print("   ğŸš€ å®æ—¶è§†è§‰åº”ç”¨ - æ„å»ºæ™ºèƒ½å›¾åƒè¯†åˆ«ç³»ç»Ÿ")
print()
print("ğŸŒŸ è®¡ç®—æœºè§†è§‰çš„è¶…èƒ½åŠ›ï¼š")
print("   ğŸ‘€ åƒç´ çº§ç†è§£ - ä»åŸå§‹åƒç´ ä¸­æå–é«˜çº§è¯­ä¹‰")
print("   ğŸ” ç»†èŠ‚æ•æ‰èƒ½åŠ› - å‘ç°äººçœ¼éš¾ä»¥å¯Ÿè§‰çš„ç‰¹å¾")
print("   âš¡ è¶…å¿«å¤„ç†é€Ÿåº¦ - æ¯«ç§’çº§å®Œæˆå¤æ‚å›¾åƒåˆ†æ")
print("   ğŸ¨ åˆ›é€ æ€§ç”Ÿæˆ - ç”Ÿæˆé€¼çœŸçš„å›¾åƒå’Œè‰ºæœ¯ä½œå“")
print()
print("ğŸš€ å‡†å¤‡å¥½è®©AIæ‹¥æœ‰è§†è§‰èƒ½åŠ›äº†å—ï¼Ÿ")
```

### ğŸ—ï¸ è®¡ç®—æœºè§†è§‰å·¥ä½œå®¤æ¶æ„

æˆ‘ä»¬çš„è®¡ç®—æœºè§†è§‰å·¥ä½œå®¤åŒ…å«äº†ä»åŸºç¡€åˆ°é«˜çº§çš„å®Œæ•´è§†è§‰å¤„ç†æµæ°´çº¿ï¼š

```mermaid
graph TD
    A["ğŸ¨ è®¡ç®—æœºè§†è§‰å·¥ä½œå®¤"] --> B["ğŸ“· å›¾åƒè¾“å…¥åŒº"]
    A --> C["ğŸ”¬ ç‰¹å¾æå–åŒº"]
    A --> D["ğŸ§  æ¨¡å¼è¯†åˆ«åŒº"]
    A --> E["ğŸ¯ åº”ç”¨è¾“å‡ºåŒº"]
    
    B --> B1["å›¾åƒé¢„å¤„ç†"]
    B --> B2["æ•°æ®å¢å¼º"]
    B --> B3["æ‰¹å¤„ç†ç®¡é“"]
    
    C --> C1["å·ç§¯å±‚"]
    C --> C2["æ± åŒ–å±‚"]
    C --> C3["æ¿€æ´»å‡½æ•°"]
    
    D --> D1["ç‰¹å¾æ˜ å°„"]
    D --> D2["åˆ†ç±»å™¨"]
    D --> D3["å›å½’å™¨"]
    
    E --> E1["å›¾åƒåˆ†ç±»"]
    E --> E2["ç›®æ ‡æ£€æµ‹"]
    E --> E3["å›¾åƒç”Ÿæˆ"]
    
    style A fill:#e1f5fe
    style B fill:#e8f5e8
    style C fill:#f3e5f5
    style D fill:#fff3e0
    style E fill:#e3f2fd
```

---

## ğŸ“· 22.2 å›¾åƒæ•°æ®åŸºç¡€ä¸é¢„å¤„ç†

### ğŸ–¼ï¸ å›¾åƒæ•°æ®çš„æœ¬è´¨

åœ¨å¼€å§‹æ„å»ºCNNä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦æ·±å…¥ç†è§£å›¾åƒæ•°æ®çš„ç‰¹ç‚¹ï¼š

### ğŸ“Š å›¾åƒæ•°æ®ç»“æ„è§£æ

```mermaid
graph TB
    A["ğŸ–¼ï¸ æ•°å­—å›¾åƒ"] --> B["åƒç´ çŸ©é˜µ"]
    
    B --> C["ç°åº¦å›¾åƒ<br/>(H Ã— W)"]
    B --> D["å½©è‰²å›¾åƒ<br/>(H Ã— W Ã— 3)"]
    
    C --> C1["å•é€šé“<br/>0-255ç°åº¦å€¼"]
    D --> D1["RGBä¸‰é€šé“<br/>Red-Green-Blue"]
    
    D1 --> D2["Ré€šé“ (çº¢è‰²)"]
    D1 --> D3["Gé€šé“ (ç»¿è‰²)"]
    D1 --> D4["Bé€šé“ (è“è‰²)"]
    
    style A fill:#e1f5fe
    style C fill:#e8f5e8
    style D fill:#f3e5f5
```

### ğŸ”¬ å›¾åƒæ•°æ®æ¢ç´¢ä¸å¯è§†åŒ–

```python
# ğŸ”¬ å›¾åƒæ•°æ®æ¢ç´¢å®éªŒå®¤
import numpy as np
import matplotlib.pyplot as plt
import cv2
from tensorflow import keras
from tensorflow.keras import datasets
import seaborn as sns

class ImageDataExplorer:
    """å›¾åƒæ•°æ®æ¢ç´¢å·¥å…·"""
    
    def __init__(self):
        self.data_loaded = False
        
    def load_sample_datasets(self):
        """åŠ è½½ç¤ºä¾‹æ•°æ®é›†"""
        print("ğŸ“Š åŠ è½½å›¾åƒæ•°æ®é›†...")
        
        # åŠ è½½CIFAR-10æ•°æ®é›†
        (self.X_train, self.y_train), (self.X_test, self.y_test) = datasets.cifar10.load_data()
        
        # CIFAR-10ç±»åˆ«åç§°
        self.class_names = [
            'airplane', 'automobile', 'bird', 'cat', 'deer',
            'dog', 'frog', 'horse', 'ship', 'truck'
        ]
        
        self.data_loaded = True
        
        print(f"   âœ… æ•°æ®åŠ è½½å®Œæˆ!")
        print(f"   ğŸ“‹ è®­ç»ƒé›†: {self.X_train.shape}")
        print(f"   ğŸ“‹ æµ‹è¯•é›†: {self.X_test.shape}")
        print(f"   ğŸ¯ ç±»åˆ«æ•°: {len(self.class_names)}")
        
        return True
    
    def analyze_image_properties(self):
        """åˆ†æå›¾åƒå±æ€§"""
        if not self.data_loaded:
            print("âŒ è¯·å…ˆåŠ è½½æ•°æ®é›†!")
            return
            
        print("\nğŸ” å›¾åƒæ•°æ®å±æ€§åˆ†æ")
        print("=" * 50)
        
        # åŸºç¡€å±æ€§
        height, width, channels = self.X_train.shape[1:]
        print(f"ğŸ“ å›¾åƒå°ºå¯¸: {height} Ã— {width} Ã— {channels}")
        print(f"ğŸ“Š åƒç´ å€¼èŒƒå›´: {self.X_train.min()} - {self.X_train.max()}")
        print(f"ğŸ“ˆ æ•°æ®ç±»å‹: {self.X_train.dtype}")
        
        # ç»Ÿè®¡ä¿¡æ¯
        mean_pixel = self.X_train.mean()
        std_pixel = self.X_train.std()
        print(f"ğŸ“Š åƒç´ å‡å€¼: {mean_pixel:.2f}")
        print(f"ğŸ“Š åƒç´ æ ‡å‡†å·®: {std_pixel:.2f}")
        
        # ç±»åˆ«åˆ†å¸ƒ
        unique, counts = np.unique(self.y_train, return_counts=True)
        print(f"\nğŸ¯ ç±»åˆ«åˆ†å¸ƒ:")
        for i, (class_id, count) in enumerate(zip(unique, counts)):
            print(f"   {self.class_names[i]}: {count} å¼ å›¾åƒ")
    
    def visualize_sample_images(self, num_samples=12):
        """å¯è§†åŒ–æ ·æœ¬å›¾åƒ"""
        if not self.data_loaded:
            print("âŒ è¯·å…ˆåŠ è½½æ•°æ®é›†!")
            return
            
        print(f"\nğŸ‘€ å±•ç¤º{num_samples}ä¸ªæ ·æœ¬å›¾åƒ...")
        
        # åˆ›å»ºå­å›¾
        fig, axes = plt.subplots(3, 4, figsize=(15, 12))
        axes = axes.ravel()
        
        # éšæœºé€‰æ‹©æ ·æœ¬
        indices = np.random.choice(len(self.X_train), num_samples, replace=False)
        
        for i, idx in enumerate(indices):
            image = self.X_train[idx]
            label = self.y_train[idx][0]
            class_name = self.class_names[label]
            
            # æ˜¾ç¤ºå›¾åƒ
            axes[i].imshow(image)
            axes[i].set_title(f'{class_name}\n({image.shape})', fontsize=12)
            axes[i].axis('off')
        
        plt.suptitle('ğŸ–¼ï¸ CIFAR-10 æ ·æœ¬å›¾åƒå±•ç¤º', fontsize=16)
        plt.tight_layout()
        plt.show()
        
        print("   âœ… æ ·æœ¬å±•ç¤ºå®Œæˆ!")

# ğŸ¨ å›¾åƒæ•°æ®æ¢ç´¢å®éªŒ
def image_data_exploration_experiment():
    """å›¾åƒæ•°æ®æ¢ç´¢å®éªŒ"""
    print("ğŸ”¬ å›¾åƒæ•°æ®æ¢ç´¢å®éªŒå¼€å§‹ï¼")
    print("=" * 60)
    
    # åˆ›å»ºæ¢ç´¢å™¨
    explorer = ImageDataExplorer()
    
    # 1. åŠ è½½æ•°æ®
    explorer.load_sample_datasets()
    
    # 2. åˆ†æå›¾åƒå±æ€§
    explorer.analyze_image_properties()
    
    # 3. å¯è§†åŒ–æ ·æœ¬
    explorer.visualize_sample_images()
    
    print("\nğŸ‰ å›¾åƒæ•°æ®æ¢ç´¢å®éªŒå®Œæˆ!")
    return explorer

# è¿è¡Œå›¾åƒæ•°æ®æ¢ç´¢å®éªŒ
image_explorer = image_data_exploration_experiment()
```

---

## ğŸ§  22.3 å·ç§¯ç¥ç»ç½‘ç»œæ ¸å¿ƒåŸç†

### ğŸ”¬ å·ç§¯æ“ä½œçš„æœ¬è´¨

å·ç§¯æ˜¯CNNçš„æ ¸å¿ƒæ“ä½œï¼Œå°±åƒäººç±»è§†è§‰ç³»ç»Ÿä¸­çš„ç‰¹å¾æ£€æµ‹å™¨ä¸€æ ·ï¼š

### ğŸ” å·ç§¯æ“ä½œå¯è§†åŒ–

```mermaid
graph LR
    subgraph "ğŸ–¼ï¸ è¾“å…¥å›¾åƒ"
        A["åƒç´ çŸ©é˜µ<br/>5Ã—5"]
    end
    
    subgraph "ğŸ” å·ç§¯æ ¸"
        B["ç‰¹å¾æ£€æµ‹å™¨<br/>3Ã—3"]
    end
    
    subgraph "âš¡ å·ç§¯æ“ä½œ"
        C["æ»‘åŠ¨çª—å£<br/>é€ç‚¹ç›¸ä¹˜æ±‚å’Œ"]
    end
    
    subgraph "ğŸ“Š ç‰¹å¾å›¾"
        D["æ£€æµ‹ç»“æœ<br/>3Ã—3"]
    end
    
    A --> C
    B --> C
    C --> D
    
    style A fill:#e1f5fe
    style B fill:#e8f5e8
    style C fill:#fff3e0
    style D fill:#f3e5f5
```

### ğŸ§® å·ç§¯æ“ä½œè¯¦è§£ä¸å®ç°

```python
# ğŸ§® å·ç§¯æ“ä½œåŸç†æ¼”ç¤º
import numpy as np
import matplotlib.pyplot as plt

class ConvolutionDemonstrator:
    """å·ç§¯æ“ä½œæ¼”ç¤ºå™¨"""
    
    def __init__(self):
        self.demo_image = None
        self.demo_kernel = None
        
    def create_demo_data(self):
        """åˆ›å»ºæ¼”ç¤ºæ•°æ®"""
        print("ğŸ¨ åˆ›å»ºå·ç§¯æ¼”ç¤ºæ•°æ®...")
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„5x5å›¾åƒ
        self.demo_image = np.array([
            [0, 0, 1, 0, 0],
            [0, 0, 1, 0, 0],
            [0, 0, 1, 0, 0],
            [0, 0, 1, 0, 0],
            [0, 0, 1, 0, 0]
        ], dtype=np.float32)
        
        # åˆ›å»ºè¾¹ç¼˜æ£€æµ‹å·ç§¯æ ¸
        self.demo_kernel = np.array([
            [-1, -1, -1],
            [ 0,  0,  0],
            [ 1,  1,  1]
        ], dtype=np.float32)
        
        print("   âœ… æ¼”ç¤ºæ•°æ®åˆ›å»ºå®Œæˆ!")
        
    def manual_convolution(self, image, kernel):
        """æ‰‹åŠ¨å®ç°å·ç§¯æ“ä½œ"""
        print("\nğŸ”§ æ‰§è¡Œæ‰‹åŠ¨å·ç§¯æ“ä½œ...")
        
        # è·å–å°ºå¯¸
        img_h, img_w = image.shape
        ker_h, ker_w = kernel.shape
        
        # è®¡ç®—è¾“å‡ºå°ºå¯¸
        out_h = img_h - ker_h + 1
        out_w = img_w - ker_w + 1
        
        # åˆå§‹åŒ–è¾“å‡º
        output = np.zeros((out_h, out_w))
        
        # æ‰§è¡Œå·ç§¯
        for i in range(out_h):
            for j in range(out_w):
                # æå–å¯¹åº”åŒºåŸŸ
                region = image[i:i+ker_h, j:j+ker_w]
                # è®¡ç®—å·ç§¯
                output[i, j] = np.sum(region * kernel)
        
        print(f"   ğŸ“Š è¾“å…¥å°ºå¯¸: {image.shape}")
        print(f"   ğŸ” å·ç§¯æ ¸å°ºå¯¸: {kernel.shape}")
        print(f"   ğŸ“ˆ è¾“å‡ºå°ºå¯¸: {output.shape}")
        
        return output
    
    def visualize_convolution_process(self):
        """å¯è§†åŒ–å·ç§¯è¿‡ç¨‹"""
        print("\nğŸ‘€ å¯è§†åŒ–å·ç§¯è¿‡ç¨‹...")
        
        # æ‰§è¡Œå·ç§¯
        result = self.manual_convolution(self.demo_image, self.demo_kernel)
        
        # åˆ›å»ºå¯è§†åŒ–
        fig, axes = plt.subplots(1, 4, figsize=(20, 5))
        
        # è¾“å…¥å›¾åƒ
        axes[0].imshow(self.demo_image, cmap='Blues', vmin=0, vmax=1)
        axes[0].set_title('ğŸ–¼ï¸ è¾“å…¥å›¾åƒ (5Ã—5)', fontsize=14)
        axes[0].grid(True, alpha=0.3)
        
        # å·ç§¯æ ¸
        axes[1].imshow(self.demo_kernel, cmap='RdBu', vmin=-1, vmax=1)
        axes[1].set_title('ğŸ” å·ç§¯æ ¸ (3Ã—3)\nè¾¹ç¼˜æ£€æµ‹å™¨', fontsize=14)
        axes[1].grid(True, alpha=0.3)
        
        # å·ç§¯ç»“æœ
        axes[2].imshow(result, cmap='RdYlBu')
        axes[2].set_title('ğŸ“Š ç‰¹å¾å›¾ (3Ã—3)\nå·ç§¯ç»“æœ', fontsize=14)
        axes[2].grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡æ³¨
        for i in range(result.shape[0]):
            for j in range(result.shape[1]):
                axes[2].text(j, i, f'{result[i,j]:.1f}', 
                           ha='center', va='center', fontsize=12, color='black')
        
        # æ­¥éª¤è¯´æ˜
        axes[3].text(0.1, 0.8, 'ğŸ”§ å·ç§¯æ“ä½œæ­¥éª¤:', fontsize=14, weight='bold')
        axes[3].text(0.1, 0.7, '1. å·ç§¯æ ¸æ»‘åŠ¨éå†å›¾åƒ', fontsize=12)
        axes[3].text(0.1, 0.6, '2. å¯¹åº”å…ƒç´ ç›¸ä¹˜', fontsize=12)
        axes[3].text(0.1, 0.5, '3. æ±‚å’Œå¾—åˆ°ç‰¹å¾å€¼', fontsize=12)
        axes[3].text(0.1, 0.4, '4. ç§»åŠ¨åˆ°ä¸‹ä¸€ä½ç½®', fontsize=12)
        axes[3].text(0.1, 0.2, 'âœ¨ ç»“æœè§£é‡Š:', fontsize=14, weight='bold', color='blue')
        axes[3].text(0.1, 0.1, 'æ£€æµ‹åˆ°å‚ç›´è¾¹ç¼˜ï¼', fontsize=12, color='red')
        axes[3].set_xlim(0, 1)
        axes[3].set_ylim(0, 1)
        axes[3].axis('off')
        
        plt.tight_layout()
        plt.show()
        
        print("   âœ… å·ç§¯è¿‡ç¨‹å¯è§†åŒ–å®Œæˆ!")
        return result

# ğŸ§® å·ç§¯æ“ä½œæ¼”ç¤ºå®éªŒ
def convolution_demonstration_experiment():
    """å·ç§¯æ“ä½œæ¼”ç¤ºå®éªŒ"""
    print("ğŸ§® å·ç§¯æ“ä½œåŸç†æ¼”ç¤ºå®éªŒå¼€å§‹ï¼")
    print("=" * 60)
    
    # åˆ›å»ºæ¼”ç¤ºå™¨
    demonstrator = ConvolutionDemonstrator()
    
    # 1. åˆ›å»ºæ¼”ç¤ºæ•°æ®
    demonstrator.create_demo_data()
    
    # 2. å¯è§†åŒ–å·ç§¯è¿‡ç¨‹
    demonstrator.visualize_convolution_process()
    
    print("\nğŸ‰ å·ç§¯æ“ä½œæ¼”ç¤ºå®éªŒå®Œæˆ!")
    return demonstrator

# è¿è¡Œå·ç§¯æ¼”ç¤ºå®éªŒ
conv_demonstrator = convolution_demonstration_experiment()
```

---

## ğŸ—ï¸ 22.4 CNNç½‘ç»œæ¶æ„è®¾è®¡

### ğŸ“ ç»å…¸CNNæ¶æ„è§£æ

è®©æˆ‘ä»¬æ·±å…¥äº†è§£å‡ ç§ç»å…¸çš„CNNæ¶æ„ï¼Œä»ç®€å•åˆ°å¤æ‚ï¼š

### ğŸŒŸ CNNæ¶æ„è¿›åŒ–å²

```mermaid
graph LR
    A["LeNet-5<br/>(1998)"] --> B["AlexNet<br/>(2012)"]
    B --> C["VGGNet<br/>(2014)"]
    C --> D["ResNet<br/>(2015)"]
    D --> E["ç°ä»£æ¶æ„<br/>(2020+)"]
    
    A --> A1["7å±‚ç½‘ç»œ<br/>æ‰‹å†™æ•°å­—è¯†åˆ«"]
    B --> B1["8å±‚ç½‘ç»œ<br/>ImageNetçªç ´"]
    C --> C1["19å±‚ç½‘ç»œ<br/>æ·±åº¦ç½‘ç»œæ¢ç´¢"]
    D --> D1["152å±‚ç½‘ç»œ<br/>æ®‹å·®è¿æ¥"]
    E --> E1["æ•ˆç‡ä¼˜åŒ–<br/>ç§»åŠ¨ç«¯éƒ¨ç½²"]
    
    style A fill:#e8f5e8
    style B fill:#e3f2fd
    style C fill:#f3e5f5
    style D fill:#fff3e0
    style E fill:#fce4ec
```

### ğŸ—ï¸ æ„å»ºç°ä»£CNNæ¶æ„

```python
# ğŸ—ï¸ CNNæ¶æ„è®¾è®¡å·¥å‚
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models
import matplotlib.pyplot as plt
import numpy as np

class CNNArchitectureFactory:
    """CNNæ¶æ„è®¾è®¡å·¥å‚"""
    
    def __init__(self):
        self.architectures = {}
        
    def create_simple_cnn(self, input_shape=(32, 32, 3), num_classes=10):
        """åˆ›å»ºç®€å•CNNæ¶æ„"""
        print("ğŸ”¨ æ„å»ºç®€å•CNNæ¶æ„...")
        
        model = models.Sequential([
            # ç¬¬ä¸€ä¸ªå·ç§¯å—
            layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
            layers.MaxPooling2D((2, 2)),
            
            # ç¬¬äºŒä¸ªå·ç§¯å—
            layers.Conv2D(64, (3, 3), activation='relu'),
            layers.MaxPooling2D((2, 2)),
            
            # ç¬¬ä¸‰ä¸ªå·ç§¯å—
            layers.Conv2D(64, (3, 3), activation='relu'),
            
            # å…¨è¿æ¥å±‚
            layers.Flatten(),
            layers.Dense(64, activation='relu'),
            layers.Dropout(0.5),
            layers.Dense(num_classes, activation='softmax')
        ])
        
        # ç¼–è¯‘æ¨¡å‹
        model.compile(
            optimizer='adam',
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )
        
        self.architectures['simple_cnn'] = model
        print("   âœ… ç®€å•CNNæ¶æ„åˆ›å»ºå®Œæˆ!")
        
        return model
    
    def create_vgg_style_cnn(self, input_shape=(32, 32, 3), num_classes=10):
        """åˆ›å»ºVGGé£æ ¼çš„CNNæ¶æ„"""
        print("ğŸ”¨ æ„å»ºVGGé£æ ¼CNNæ¶æ„...")
        
        model = models.Sequential([
            # ç¬¬ä¸€ä¸ªVGGå— (64ä¸ªæ»¤æ³¢å™¨)
            layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape),
            layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
            layers.MaxPooling2D((2, 2)),
            
            # ç¬¬äºŒä¸ªVGGå— (128ä¸ªæ»¤æ³¢å™¨)
            layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
            layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
            layers.MaxPooling2D((2, 2)),
            
            # ç¬¬ä¸‰ä¸ªVGGå— (256ä¸ªæ»¤æ³¢å™¨)
            layers.Conv2D(256, (3, 3), activation='relu', padding='same'),
            layers.Conv2D(256, (3, 3), activation='relu', padding='same'),
            layers.MaxPooling2D((2, 2)),
            
            # å…¨è¿æ¥å±‚
            layers.Flatten(),
            layers.Dense(512, activation='relu'),
            layers.Dropout(0.5),
            layers.Dense(256, activation='relu'),
            layers.Dropout(0.5),
            layers.Dense(num_classes, activation='softmax')
        ])
        
        # ç¼–è¯‘æ¨¡å‹
        model.compile(
            optimizer='adam',
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )
        
        self.architectures['vgg_style_cnn'] = model
        print("   âœ… VGGé£æ ¼CNNæ¶æ„åˆ›å»ºå®Œæˆ!")
        
        return model
    
    def create_residual_block(self, inputs, filters, kernel_size=3, stride=1):
        """åˆ›å»ºæ®‹å·®å—"""
        # ä¸»è·¯å¾„
        x = layers.Conv2D(filters, kernel_size, strides=stride, padding='same')(inputs)
        x = layers.BatchNormalization()(x)
        x = layers.ReLU()(x)
        
        x = layers.Conv2D(filters, kernel_size, padding='same')(x)
        x = layers.BatchNormalization()(x)
        
        # å¿«æ·è¿æ¥
        if stride != 1 or inputs.shape[-1] != filters:
            shortcut = layers.Conv2D(filters, 1, strides=stride, padding='same')(inputs)
            shortcut = layers.BatchNormalization()(shortcut)
        else:
            shortcut = inputs
        
        # æ®‹å·®è¿æ¥
        x = layers.Add()([x, shortcut])
        x = layers.ReLU()(x)
        
        return x
    
    def create_resnet_style_cnn(self, input_shape=(32, 32, 3), num_classes=10):
        """åˆ›å»ºResNeté£æ ¼çš„CNNæ¶æ„"""
        print("ğŸ”¨ æ„å»ºResNeté£æ ¼CNNæ¶æ„...")
        
        inputs = layers.Input(shape=input_shape)
        
        # åˆå§‹å·ç§¯å±‚
        x = layers.Conv2D(64, 7, strides=2, padding='same')(inputs)
        x = layers.BatchNormalization()(x)
        x = layers.ReLU()(x)
        x = layers.MaxPooling2D(3, strides=2, padding='same')(x)
        
        # æ®‹å·®å—ç»„
        x = self.create_residual_block(x, 64)
        x = self.create_residual_block(x, 64)
        
        x = self.create_residual_block(x, 128, stride=2)
        x = self.create_residual_block(x, 128)
        
        x = self.create_residual_block(x, 256, stride=2)
        x = self.create_residual_block(x, 256)
        
        # å…¨å±€å¹³å‡æ± åŒ–å’Œåˆ†ç±»å±‚
        x = layers.GlobalAveragePooling2D()(x)
        x = layers.Dense(512, activation='relu')(x)
        x = layers.Dropout(0.5)(x)
        outputs = layers.Dense(num_classes, activation='softmax')(x)
        
        model = models.Model(inputs, outputs)
        
        # ç¼–è¯‘æ¨¡å‹
        model.compile(
            optimizer='adam',
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )
        
        self.architectures['resnet_style_cnn'] = model
        print("   âœ… ResNeté£æ ¼CNNæ¶æ„åˆ›å»ºå®Œæˆ!")
        
        return model
    
    def visualize_architecture(self, model_name):
        """å¯è§†åŒ–ç½‘ç»œæ¶æ„"""
        if model_name not in self.architectures:
            print(f"âŒ æ¨¡å‹ {model_name} ä¸å­˜åœ¨!")
            return
            
        model = self.architectures[model_name]
        
        print(f"\nğŸ“Š {model_name} æ¶æ„è¯¦æƒ…:")
        print("=" * 60)
        model.summary()
        
        # å¯è§†åŒ–æ¨¡å‹ç»“æ„
        try:
            keras.utils.plot_model(
                model,
                to_file=f'{model_name}_architecture.png',
                show_shapes=True,
                show_layer_names=True,
                rankdir='TB'
            )
            print(f"   ğŸ’¾ æ¶æ„å›¾å·²ä¿å­˜ä¸º {model_name}_architecture.png")
        except:
            print("   âš ï¸ æ— æ³•ç”Ÿæˆæ¶æ„å›¾ (éœ€è¦å®‰è£…graphviz)")
    
    def compare_architectures(self):
        """æ¯”è¾ƒä¸åŒæ¶æ„"""
        print("\nğŸ† CNNæ¶æ„å¯¹æ¯”åˆ†æ")
        print("=" * 80)
        
        comparison_data = []
        
        for name, model in self.architectures.items():
            total_params = model.count_params()
            trainable_params = sum([tf.size(p) for p in model.trainable_weights])
            
            comparison_data.append({
                'Architecture': name,
                'Total Layers': len(model.layers),
                'Total Parameters': total_params,
                'Trainable Parameters': trainable_params,
                'Model Size (MB)': total_params * 4 / (1024**2),  # ä¼°ç®—
            })
        
        # æ‰“å°å¯¹æ¯”è¡¨æ ¼
        print(f"{'Architecture':<20} {'Layers':<8} {'Total Params':<15} {'Size(MB)':<10}")
        print("-" * 60)
        
        for data in comparison_data:
            print(f"{data['Architecture']:<20} {data['Total Layers']:<8} {data['Total Parameters']:<15,} {data['Model Size (MB)']:<10.2f}")
    
    def create_custom_cnn_block(self, inputs, filters, block_name="custom"):
        """åˆ›å»ºè‡ªå®šä¹‰CNNå—"""
        print(f"ğŸ§© åˆ›å»ºè‡ªå®šä¹‰CNNå—: {block_name}")
        
        # ç¬¬ä¸€ä¸ªå·ç§¯å±‚
        x = layers.Conv2D(filters, 3, padding='same', name=f'{block_name}_conv1')(inputs)
        x = layers.BatchNormalization(name=f'{block_name}_bn1')(x)
        x = layers.ReLU(name=f'{block_name}_relu1')(x)
        
        # ç¬¬äºŒä¸ªå·ç§¯å±‚
        x = layers.Conv2D(filters, 3, padding='same', name=f'{block_name}_conv2')(x)
        x = layers.BatchNormalization(name=f'{block_name}_bn2')(x)
        x = layers.ReLU(name=f'{block_name}_relu2')(x)
        
        # æ³¨æ„åŠ›æœºåˆ¶ (ç®€åŒ–ç‰ˆ)
        attention = layers.GlobalAveragePooling2D(name=f'{block_name}_gap')(x)
        attention = layers.Dense(filters//4, activation='relu', name=f'{block_name}_att1')(attention)
        attention = layers.Dense(filters, activation='sigmoid', name=f'{block_name}_att2')(attention)
        attention = layers.Reshape((1, 1, filters), name=f'{block_name}_reshape')(attention)
        
        # åº”ç”¨æ³¨æ„åŠ›
        x = layers.Multiply(name=f'{block_name}_multiply')([x, attention])
        
        return x

# ğŸ—ï¸ CNNæ¶æ„è®¾è®¡å®éªŒ
def cnn_architecture_design_experiment():
    """CNNæ¶æ„è®¾è®¡å®éªŒ"""
    print("ğŸ—ï¸ CNNæ¶æ„è®¾è®¡å®éªŒå¼€å§‹ï¼")
    print("=" * 60)
    
    # åˆ›å»ºæ¶æ„å·¥å‚
    factory = CNNArchitectureFactory()
    
    # 1. åˆ›å»ºä¸åŒçš„CNNæ¶æ„
    print("\nğŸ”¨ åˆ›å»ºå¤šç§CNNæ¶æ„...")
    simple_model = factory.create_simple_cnn()
    vgg_model = factory.create_vgg_style_cnn()
    resnet_model = factory.create_resnet_style_cnn()
    
    # 2. å¯è§†åŒ–æ¶æ„
    print("\nğŸ‘€ å¯è§†åŒ–ç½‘ç»œæ¶æ„...")
    factory.visualize_architecture('simple_cnn')
    
    # 3. æ¯”è¾ƒä¸åŒæ¶æ„
    factory.compare_architectures()
    
    print("\nğŸ‰ CNNæ¶æ„è®¾è®¡å®éªŒå®Œæˆ!")
    return factory

# è¿è¡ŒCNNæ¶æ„è®¾è®¡å®éªŒ
cnn_factory = cnn_architecture_design_experiment()
```

---

## ğŸ¯ 22.5 æ ¸å¿ƒé¡¹ç›®ï¼šæ™ºèƒ½å›¾åƒåˆ†ç±»ç³»ç»Ÿ

### ğŸš€ é¡¹ç›®æ¦‚è¿°

æˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªå®Œæ•´çš„**æ™ºèƒ½å›¾åƒåˆ†ç±»ç³»ç»Ÿ**ï¼Œå®ç°ä»æ•°æ®é¢„å¤„ç†åˆ°æ¨¡å‹éƒ¨ç½²çš„å…¨æµç¨‹å¼€å‘ã€‚

### ğŸ“‹ é¡¹ç›®æ¶æ„è®¾è®¡

```mermaid
graph TD
    A["ğŸ¯ æ™ºèƒ½å›¾åƒåˆ†ç±»ç³»ç»Ÿ"] --> B["ğŸ“· æ•°æ®å¤„ç†æ¨¡å—"]
    A --> C["ğŸ§  æ¨¡å‹è®­ç»ƒæ¨¡å—"]
    A --> D["ğŸ”§ æ¨¡å‹ä¼˜åŒ–æ¨¡å—"]
    A --> E["ğŸ“Š è¯„ä¼°åˆ†ææ¨¡å—"]
    A --> F["ğŸš€ éƒ¨ç½²åº”ç”¨æ¨¡å—"]
    
    B --> B1["æ•°æ®åŠ è½½"]
    B --> B2["é¢„å¤„ç†"]
    B --> B3["æ•°æ®å¢å¼º"]
    
    C --> C1["æ¨¡å‹æ„å»º"]
    C --> C2["è®­ç»ƒç›‘æ§"]
    C --> C3["æ£€æŸ¥ç‚¹ä¿å­˜"]
    
    D --> D1["è¶…å‚æ•°è°ƒä¼˜"]
    D --> D2["æ¨¡å‹é›†æˆ"]
    D --> D3["æ€§èƒ½ä¼˜åŒ–"]
    
    E --> E1["æ··æ·†çŸ©é˜µ"]
    E --> E2["åˆ†ç±»æŠ¥å‘Š"]
    E --> E3["å¯è§†åŒ–åˆ†æ"]
    
    F --> F1["æ¨¡å‹ä¿å­˜"]
    F --> F2["æ¨ç†æ¥å£"]
    F --> F3["Webåº”ç”¨"]
    
    style A fill:#e1f5fe
    style B fill:#e8f5e8
    style C fill:#f3e5f5
    style D fill:#fff3e0
    style E fill:#fce4ec
    style F fill:#e3f2fd
```

### ğŸ¨ å®Œæ•´çš„å›¾åƒåˆ†ç±»ç³»ç»Ÿå®ç°

```python
# ğŸ¯ æ™ºèƒ½å›¾åƒåˆ†ç±»ç³»ç»Ÿ
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, optimizers, callbacks
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix
import os
import json
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

class SmartImageClassificationSystem:
    """æ™ºèƒ½å›¾åƒåˆ†ç±»ç³»ç»Ÿ"""
    
    def __init__(self, project_name="smart_classifier"):
        self.project_name = project_name
        self.model = None
        self.history = None
        self.class_names = None
        self.X_train = None
        self.y_train = None
        self.X_test = None
        self.y_test = None
        self.X_val = None
        self.y_val = None
        
        # åˆ›å»ºé¡¹ç›®ç›®å½•
        self.project_dir = f"./projects/{project_name}"
        os.makedirs(self.project_dir, exist_ok=True)
        os.makedirs(f"{self.project_dir}/models", exist_ok=True)
        os.makedirs(f"{self.project_dir}/logs", exist_ok=True)
        os.makedirs(f"{self.project_dir}/results", exist_ok=True)
        
        print(f"ğŸ¯ æ™ºèƒ½å›¾åƒåˆ†ç±»ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")
        print(f"   ğŸ“ é¡¹ç›®ç›®å½•: {self.project_dir}")
    
    def load_and_prepare_data(self, dataset_name="cifar10"):
        """åŠ è½½å’Œå‡†å¤‡æ•°æ®"""
        print(f"ğŸ“Š åŠ è½½{dataset_name}æ•°æ®é›†...")
        
        if dataset_name == "cifar10":
            # åŠ è½½CIFAR-10æ•°æ®é›†
            (X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()
            
            self.class_names = [
                'airplane', 'automobile', 'bird', 'cat', 'deer',
                'dog', 'frog', 'horse', 'ship', 'truck'
            ]
            
        elif dataset_name == "cifar100":
            # åŠ è½½CIFAR-100æ•°æ®é›†
            (X_train, y_train), (X_test, y_test) = keras.datasets.cifar100.load_data()
            self.class_names = [f'class_{i}' for i in range(100)]
            
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®é›†: {dataset_name}")
        
        # æ•°æ®é¢„å¤„ç†
        print("ğŸ”§ æ‰§è¡Œæ•°æ®é¢„å¤„ç†...")
        
        # å½’ä¸€åŒ–åˆ°[0,1]
        X_train = X_train.astype('float32') / 255.0
        X_test = X_test.astype('float32') / 255.0
        
        # æ ‡ç­¾å¤„ç†
        y_train = y_train.flatten()
        y_test = y_test.flatten()
        
        # åˆ›å»ºéªŒè¯é›†
        val_split = 0.2
        split_idx = int(len(X_train) * (1 - val_split))
        
        self.X_train = X_train[:split_idx]
        self.y_train = y_train[:split_idx]
        self.X_val = X_train[split_idx:]
        self.y_val = y_train[split_idx:]
        self.X_test = X_test
        self.y_test = y_test
        
        print(f"   âœ… æ•°æ®åŠ è½½å®Œæˆ!")
        print(f"   ğŸ“‹ è®­ç»ƒé›†: {self.X_train.shape}")
        print(f"   ğŸ“‹ éªŒè¯é›†: {self.X_val.shape}")
        print(f"   ğŸ“‹ æµ‹è¯•é›†: {self.X_test.shape}")
        print(f"   ğŸ¯ ç±»åˆ«æ•°: {len(self.class_names)}")
        
        return self
    
    def create_data_augmentation(self):
        """åˆ›å»ºæ•°æ®å¢å¼ºå™¨"""
        print("ğŸ¨ åˆ›å»ºæ•°æ®å¢å¼ºå™¨...")
        
        data_augmentation = keras.Sequential([
            layers.RandomFlip("horizontal"),
            layers.RandomRotation(0.1),
            layers.RandomZoom(0.1),
            layers.RandomContrast(0.1),
            layers.RandomBrightness(0.1),
        ])
        
        print("   âœ… æ•°æ®å¢å¼ºå™¨åˆ›å»ºå®Œæˆ!")
        return data_augmentation
    
    def build_advanced_cnn_model(self, input_shape=(32, 32, 3), num_classes=10):
        """æ„å»ºé«˜çº§CNNæ¨¡å‹"""
        print("ğŸ—ï¸ æ„å»ºé«˜çº§CNNæ¨¡å‹...")
        
        # æ•°æ®å¢å¼º
        data_augmentation = self.create_data_augmentation()
        
        # æ¨¡å‹æ¶æ„
        inputs = layers.Input(shape=input_shape)
        
        # æ•°æ®å¢å¼ºå±‚
        x = data_augmentation(inputs)
        
        # ç¬¬ä¸€ä¸ªCNNå—
        x = layers.Conv2D(64, 3, padding='same')(x)
        x = layers.BatchNormalization()(x)
        x = layers.ReLU()(x)
        x = layers.Conv2D(64, 3, padding='same')(x)
        x = layers.BatchNormalization()(x)
        x = layers.ReLU()(x)
        x = layers.MaxPooling2D(2)(x)
        x = layers.Dropout(0.25)(x)
        
        # ç¬¬äºŒä¸ªCNNå—
        x = layers.Conv2D(128, 3, padding='same')(x)
        x = layers.BatchNormalization()(x)
        x = layers.ReLU()(x)
        x = layers.Conv2D(128, 3, padding='same')(x)
        x = layers.BatchNormalization()(x)
        x = layers.ReLU()(x)
        x = layers.MaxPooling2D(2)(x)
        x = layers.Dropout(0.25)(x)
        
        # ç¬¬ä¸‰ä¸ªCNNå—
        x = layers.Conv2D(256, 3, padding='same')(x)
        x = layers.BatchNormalization()(x)
        x = layers.ReLU()(x)
        x = layers.Conv2D(256, 3, padding='same')(x)
        x = layers.BatchNormalization()(x)
        x = layers.ReLU()(x)
        x = layers.MaxPooling2D(2)(x)
        x = layers.Dropout(0.25)(x)
        
        # å…¨å±€å¹³å‡æ± åŒ–
        x = layers.GlobalAveragePooling2D()(x)
        
        # åˆ†ç±»å¤´
        x = layers.Dense(512)(x)
        x = layers.BatchNormalization()(x)
        x = layers.ReLU()(x)
        x = layers.Dropout(0.5)(x)
        
        outputs = layers.Dense(num_classes, activation='softmax')(x)
        
        # åˆ›å»ºæ¨¡å‹
        model = keras.Model(inputs, outputs)
        
        # ç¼–è¯‘æ¨¡å‹
        model.compile(
            optimizer=optimizers.Adam(learning_rate=0.001),
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy', 'top_k_categorical_accuracy']
        )
        
        self.model = model
        
        print("   âœ… é«˜çº§CNNæ¨¡å‹æ„å»ºå®Œæˆ!")
        print(f"   ğŸ“Š æ¨¡å‹å‚æ•°é‡: {model.count_params():,}")
        
        return self
    
    def setup_training_callbacks(self):
        """è®¾ç½®è®­ç»ƒå›è°ƒ"""
        print("âš™ï¸ è®¾ç½®è®­ç»ƒå›è°ƒ...")
        
        # æ¨¡å‹æ£€æŸ¥ç‚¹
        checkpoint_path = f"{self.project_dir}/models/best_model.h5"
        checkpoint_callback = callbacks.ModelCheckpoint(
            checkpoint_path,
            monitor='val_accuracy',
            save_best_only=True,
            save_weights_only=False,
            mode='max',
            verbose=1
        )
        
        # æ—©åœ
        early_stopping_callback = callbacks.EarlyStopping(
            monitor='val_loss',
            patience=10,
            restore_best_weights=True,
            verbose=1
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦
        lr_scheduler_callback = callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=5,
            min_lr=1e-7,
            verbose=1
        )
        
        # TensorBoardæ—¥å¿—
        log_dir = f"{self.project_dir}/logs/{datetime.now().strftime('%Y%m%d-%H%M%S')}"
        tensorboard_callback = callbacks.TensorBoard(
            log_dir=log_dir,
            histogram_freq=1,
            write_graph=True,
            write_images=True
        )
        
        callback_list = [
            checkpoint_callback,
            early_stopping_callback,
            lr_scheduler_callback,
            tensorboard_callback
        ]
        
        print("   âœ… è®­ç»ƒå›è°ƒè®¾ç½®å®Œæˆ!")
        return callback_list
    
    def train_model(self, epochs=50, batch_size=32):
        """è®­ç»ƒæ¨¡å‹"""
        if self.model is None:
            print("âŒ è¯·å…ˆæ„å»ºæ¨¡å‹!")
            return
            
        print(f"ğŸš€ å¼€å§‹æ¨¡å‹è®­ç»ƒ (epochs={epochs}, batch_size={batch_size})...")
        
        # è®¾ç½®å›è°ƒ
        callbacks_list = self.setup_training_callbacks()
        
        # è®­ç»ƒæ¨¡å‹
        self.history = self.model.fit(
            self.X_train, self.y_train,
            batch_size=batch_size,
            epochs=epochs,
            validation_data=(self.X_val, self.y_val),
            callbacks=callbacks_list,
            verbose=1
        )
        
        print("   âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ!")
        
        # ä¿å­˜è®­ç»ƒå†å²
        history_path = f"{self.project_dir}/results/training_history.json"
        with open(history_path, 'w') as f:
            json.dump(self.history.history, f)
        
        return self
    
    def evaluate_model(self):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        if self.model is None:
            print("âŒ è¯·å…ˆè®­ç»ƒæ¨¡å‹!")
            return
            
        print("ğŸ“Š è¯„ä¼°æ¨¡å‹æ€§èƒ½...")
        
        # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
        test_loss, test_accuracy, test_top5_acc = self.model.evaluate(
            self.X_test, self.y_test, verbose=0
        )
        
        print(f"   ğŸ“ˆ æµ‹è¯•é›†å‡†ç¡®ç‡: {test_accuracy:.4f}")
        print(f"   ğŸ“ˆ æµ‹è¯•é›†Top-5å‡†ç¡®ç‡: {test_top5_acc:.4f}")
        print(f"   ğŸ“ˆ æµ‹è¯•é›†æŸå¤±: {test_loss:.4f}")
        
        # ç”Ÿæˆé¢„æµ‹
        y_pred_proba = self.model.predict(self.X_test, verbose=0)
        y_pred = np.argmax(y_pred_proba, axis=1)
        
        # åˆ†ç±»æŠ¥å‘Š
        print("\nğŸ“‹ åˆ†ç±»æŠ¥å‘Š:")
        print("=" * 60)
        report = classification_report(
            self.y_test, y_pred,
            target_names=self.class_names,
            output_dict=True
        )
        print(classification_report(self.y_test, y_pred, target_names=self.class_names))
        
        # ä¿å­˜åˆ†ç±»æŠ¥å‘Š
        report_path = f"{self.project_dir}/results/classification_report.json"
        with open(report_path, 'w') as f:
            json.dump(report, f, indent=2)
        
        return {
            'test_accuracy': test_accuracy,
            'test_top5_accuracy': test_top5_acc,
            'test_loss': test_loss,
            'classification_report': report
        }
    
    def visualize_training_history(self):
        """å¯è§†åŒ–è®­ç»ƒå†å²"""
        if self.history is None:
            print("âŒ è¯·å…ˆè®­ç»ƒæ¨¡å‹!")
            return
            
        print("ğŸ“ˆ å¯è§†åŒ–è®­ç»ƒå†å²...")
        
        # åˆ›å»ºå­å›¾
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # å‡†ç¡®ç‡æ›²çº¿
        axes[0, 0].plot(self.history.history['accuracy'], label='Training Accuracy', linewidth=2)
        axes[0, 0].plot(self.history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)
        axes[0, 0].set_title('ğŸ¯ æ¨¡å‹å‡†ç¡®ç‡å˜åŒ–', fontsize=14)
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('Accuracy')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # æŸå¤±æ›²çº¿
        axes[0, 1].plot(self.history.history['loss'], label='Training Loss', linewidth=2)
        axes[0, 1].plot(self.history.history['val_loss'], label='Validation Loss', linewidth=2)
        axes[0, 1].set_title('ğŸ“‰ æ¨¡å‹æŸå¤±å˜åŒ–', fontsize=14)
        axes[0, 1].set_xlabel('Epoch')
        axes[0, 1].set_ylabel('Loss')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        
        # Top-5å‡†ç¡®ç‡æ›²çº¿
        if 'top_k_categorical_accuracy' in self.history.history:
            axes[1, 0].plot(self.history.history['top_k_categorical_accuracy'], 
                          label='Training Top-5 Acc', linewidth=2)
            axes[1, 0].plot(self.history.history['val_top_k_categorical_accuracy'], 
                          label='Validation Top-5 Acc', linewidth=2)
            axes[1, 0].set_title('ğŸ† Top-5å‡†ç¡®ç‡å˜åŒ–', fontsize=14)
            axes[1, 0].set_xlabel('Epoch')
            axes[1, 0].set_ylabel('Top-5 Accuracy')
            axes[1, 0].legend()
            axes[1, 0].grid(True, alpha=0.3)
        
        # å­¦ä¹ ç‡å˜åŒ–(å¦‚æœæœ‰è®°å½•)
        if 'lr' in self.history.history:
            axes[1, 1].plot(self.history.history['lr'], linewidth=2, color='red')
            axes[1, 1].set_title('ğŸ“Š å­¦ä¹ ç‡å˜åŒ–', fontsize=14)
            axes[1, 1].set_xlabel('Epoch')
            axes[1, 1].set_ylabel('Learning Rate')
            axes[1, 1].set_yscale('log')
            axes[1, 1].grid(True, alpha=0.3)
        else:
            axes[1, 1].text(0.5, 0.5, 'å­¦ä¹ ç‡æ•°æ®ä¸å¯ç”¨', 
                          ha='center', va='center', fontsize=12)
            axes[1, 1].set_xlim(0, 1)
            axes[1, 1].set_ylim(0, 1)
        
        plt.tight_layout()
        plt.savefig(f"{self.project_dir}/results/training_history.png", dpi=300, bbox_inches='tight')
        plt.show()
        
        print("   âœ… è®­ç»ƒå†å²å¯è§†åŒ–å®Œæˆ!")
    
    def visualize_confusion_matrix(self):
        """å¯è§†åŒ–æ··æ·†çŸ©é˜µ"""
        if self.model is None:
            print("âŒ è¯·å…ˆè®­ç»ƒæ¨¡å‹!")
            return
            
        print("ğŸ” ç”Ÿæˆæ··æ·†çŸ©é˜µ...")
        
        # ç”Ÿæˆé¢„æµ‹
        y_pred = self.model.predict(self.X_test, verbose=0)
        y_pred_classes = np.argmax(y_pred, axis=1)
        
        # è®¡ç®—æ··æ·†çŸ©é˜µ
        cm = confusion_matrix(self.y_test, y_pred_classes)
        
        # å¯è§†åŒ–
        plt.figure(figsize=(12, 10))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                   xticklabels=self.class_names,
                   yticklabels=self.class_names,
                   cbar_kws={'label': 'Count'})
        plt.title('ğŸ” æ··æ·†çŸ©é˜µ - æ¨¡å‹é¢„æµ‹æ€§èƒ½åˆ†æ', fontsize=16)
        plt.xlabel('é¢„æµ‹ç±»åˆ«')
        plt.ylabel('çœŸå®ç±»åˆ«')
        plt.xticks(rotation=45)
        plt.yticks(rotation=0)
        plt.tight_layout()
        plt.savefig(f"{self.project_dir}/results/confusion_matrix.png", dpi=300, bbox_inches='tight')
        plt.show()
        
        print("   âœ… æ··æ·†çŸ©é˜µå¯è§†åŒ–å®Œæˆ!")
    
    def predict_sample_images(self, num_samples=12):
        """é¢„æµ‹æ ·æœ¬å›¾åƒ"""
        if self.model is None:
            print("âŒ è¯·å…ˆè®­ç»ƒæ¨¡å‹!")
            return
            
        print(f"ğŸ”® é¢„æµ‹{num_samples}ä¸ªæ ·æœ¬å›¾åƒ...")
        
        # éšæœºé€‰æ‹©æ ·æœ¬
        indices = np.random.choice(len(self.X_test), num_samples, replace=False)
        sample_images = self.X_test[indices]
        sample_labels = self.y_test[indices]
        
        # ç”Ÿæˆé¢„æµ‹
        predictions = self.model.predict(sample_images, verbose=0)
        predicted_classes = np.argmax(predictions, axis=1)
        predicted_probs = np.max(predictions, axis=1)
        
        # å¯è§†åŒ–ç»“æœ
        fig, axes = plt.subplots(3, 4, figsize=(16, 12))
        axes = axes.ravel()
        
        for i in range(num_samples):
            # æ˜¾ç¤ºå›¾åƒ
            axes[i].imshow(sample_images[i])
            
            # å‡†å¤‡æ ‡é¢˜
            true_class = self.class_names[sample_labels[i]]
            pred_class = self.class_names[predicted_classes[i]]
            confidence = predicted_probs[i]
            
            # åˆ¤æ–­é¢„æµ‹æ˜¯å¦æ­£ç¡®
            is_correct = sample_labels[i] == predicted_classes[i]
            color = 'green' if is_correct else 'red'
            status = 'âœ“' if is_correct else 'âœ—'
            
            title = f'{status} True: {true_class}\nPred: {pred_class}\nConf: {confidence:.2f}'
            axes[i].set_title(title, fontsize=10, color=color)
            axes[i].axis('off')
        
        plt.suptitle('ğŸ”® æ™ºèƒ½å›¾åƒåˆ†ç±»é¢„æµ‹ç»“æœå±•ç¤º', fontsize=16)
        plt.tight_layout()
        plt.savefig(f"{self.project_dir}/results/prediction_samples.png", dpi=300, bbox_inches='tight')
        plt.show()
        
        print("   âœ… æ ·æœ¬é¢„æµ‹å®Œæˆ!")
    
    def save_model(self):
        """ä¿å­˜å®Œæ•´æ¨¡å‹"""
        if self.model is None:
            print("âŒ è¯·å…ˆè®­ç»ƒæ¨¡å‹!")
            return
            
        print("ğŸ’¾ ä¿å­˜å®Œæ•´æ¨¡å‹...")
        
        # ä¿å­˜å®Œæ•´æ¨¡å‹
        model_path = f"{self.project_dir}/models/complete_model"
        self.model.save(model_path)
        
        # ä¿å­˜æ¨¡å‹é…ç½®
        config = {
            'model_architecture': 'Advanced CNN',
            'input_shape': self.X_train.shape[1:],
            'num_classes': len(self.class_names),
            'class_names': self.class_names,
            'total_parameters': self.model.count_params(),
            'save_time': datetime.now().isoformat()
        }
        
        config_path = f"{self.project_dir}/models/model_config.json"
        with open(config_path, 'w') as f:
            json.dump(config, f, indent=2)
        
        print(f"   âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
        print(f"   âœ… é…ç½®å·²ä¿å­˜åˆ°: {config_path}")
    
    def load_model(self, model_path=None):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        if model_path is None:
            model_path = f"{self.project_dir}/models/complete_model"
            
        print(f"ğŸ“¥ åŠ è½½æ¨¡å‹: {model_path}")
        
        try:
            self.model = keras.models.load_model(model_path)
            print("   âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
        except Exception as e:
            print(f"   âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    
    def create_prediction_interface(self):
        """åˆ›å»ºé¢„æµ‹æ¥å£"""
        print("ğŸŒ åˆ›å»ºé¢„æµ‹æ¥å£...")
        
        def predict_image(image_array):
            """é¢„æµ‹å•å¼ å›¾åƒ"""
            if self.model is None:
                return {"error": "æ¨¡å‹æœªè®­ç»ƒ"}
                
            # ç¡®ä¿å›¾åƒæ ¼å¼æ­£ç¡®
            if len(image_array.shape) == 3:
                image_array = np.expand_dims(image_array, axis=0)
                
            # å½’ä¸€åŒ–
            image_array = image_array.astype('float32') / 255.0
            
            # é¢„æµ‹
            predictions = self.model.predict(image_array, verbose=0)
            predicted_class = np.argmax(predictions[0])
            confidence = float(predictions[0][predicted_class])
            
            result = {
                "predicted_class": self.class_names[predicted_class],
                "confidence": confidence,
                "all_probabilities": {
                    self.class_names[i]: float(predictions[0][i]) 
                    for i in range(len(self.class_names))
                }
            }
            
            return result
        
        print("   âœ… é¢„æµ‹æ¥å£åˆ›å»ºæˆåŠŸ!")
        return predict_image

# ğŸ¯ æ™ºèƒ½å›¾åƒåˆ†ç±»ç³»ç»Ÿä½¿ç”¨ç¤ºä¾‹
def smart_image_classification_project():
    """æ™ºèƒ½å›¾åƒåˆ†ç±»ç³»ç»Ÿå®Œæ•´é¡¹ç›®"""
    print("ğŸ¯ æ™ºèƒ½å›¾åƒåˆ†ç±»ç³»ç»Ÿé¡¹ç›®å¯åŠ¨ï¼")
    print("=" * 80)
    
    # 1. åˆ›å»ºç³»ç»Ÿå®ä¾‹
    classifier = SmartImageClassificationSystem("cifar10_classifier")
    
    # 2. åŠ è½½å’Œå‡†å¤‡æ•°æ®
    classifier.load_and_prepare_data("cifar10")
    
    # 3. æ„å»ºæ¨¡å‹
    classifier.build_advanced_cnn_model(
        input_shape=(32, 32, 3),
        num_classes=10
    )
    
    # 4. è®­ç»ƒæ¨¡å‹
    classifier.train_model(epochs=30, batch_size=64)
    
    # 5. è¯„ä¼°æ¨¡å‹
    results = classifier.evaluate_model()
    
    # 6. å¯è§†åŒ–ç»“æœ
    classifier.visualize_training_history()
    classifier.visualize_confusion_matrix()
    classifier.predict_sample_images()
    
    # 7. ä¿å­˜æ¨¡å‹
    classifier.save_model()
    
    # 8. åˆ›å»ºé¢„æµ‹æ¥å£
    predict_fn = classifier.create_prediction_interface()
    
    print("\nğŸ‰ æ™ºèƒ½å›¾åƒåˆ†ç±»ç³»ç»Ÿé¡¹ç›®å®Œæˆ!")
    print(f"   ğŸ“Š æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {results['test_accuracy']:.4f}")
    print(f"   ğŸ“ é¡¹ç›®æ–‡ä»¶ä¿å­˜åœ¨: {classifier.project_dir}")
    
    return classifier, predict_fn

# è¿è¡Œå®Œæ•´é¡¹ç›® (å¯é€‰ï¼Œéœ€è¦è¾ƒé•¿è®­ç»ƒæ—¶é—´)
# classifier, predict_fn = smart_image_classification_project()
```

---

## ğŸ”§ 22.6 æ¨¡å‹ä¼˜åŒ–ä¸è°ƒä¼˜æŠ€å·§

### âš¡ é«˜çº§ä¼˜åŒ–ç­–ç•¥

æŒæ¡æ¨¡å‹ä¼˜åŒ–æŠ€å·§æ˜¯æå‡CNNæ€§èƒ½çš„å…³é”®ï¼š

### ğŸ›ï¸ è¶…å‚æ•°è°ƒä¼˜å·¥å…·

```python
# ğŸ›ï¸ CNNè¶…å‚æ•°è°ƒä¼˜å·¥å…·
import optuna
from tensorflow.keras.callbacks import EarlyStopping
import tensorflow as tf

class CNNHyperparameterTuner:
    """CNNè¶…å‚æ•°è°ƒä¼˜å™¨"""
    
    def __init__(self, X_train, y_train, X_val, y_val, num_classes):
        self.X_train = X_train
        self.y_train = y_train
        self.X_val = X_val
        self.y_val = y_val
        self.num_classes = num_classes
        self.best_params = None
        self.study = None
        
    def create_model(self, trial):
        """åˆ›å»ºå¾…è°ƒä¼˜çš„æ¨¡å‹"""
        # è¶…å‚æ•°æœç´¢ç©ºé—´
        n_layers = trial.suggest_int('n_layers', 2, 4)
        dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5)
        learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)
        
        # æ„å»ºæ¨¡å‹
        model = models.Sequential()
        model.add(layers.Input(shape=self.X_train.shape[1:]))
        
        # å·ç§¯å±‚
        filters = 32
        for i in range(n_layers):
            model.add(layers.Conv2D(filters, 3, padding='same', activation='relu'))
            model.add(layers.BatchNormalization())
            model.add(layers.Conv2D(filters, 3, padding='same', activation='relu'))
            model.add(layers.BatchNormalization())
            model.add(layers.MaxPooling2D(2))
            model.add(layers.Dropout(dropout_rate))
            filters *= 2
        
        # åˆ†ç±»å¤´
        model.add(layers.GlobalAveragePooling2D())
        model.add(layers.Dense(128, activation='relu'))
        model.add(layers.Dropout(dropout_rate))
        model.add(layers.Dense(self.num_classes, activation='softmax'))
        
        # ç¼–è¯‘æ¨¡å‹
        optimizer = optimizers.Adam(learning_rate=learning_rate)
        model.compile(
            optimizer=optimizer,
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )
        
        return model
    
    def objective(self, trial):
        """ä¼˜åŒ–ç›®æ ‡å‡½æ•°"""
        # åˆ›å»ºæ¨¡å‹
        model = self.create_model(trial)
        
        # æ—©åœå›è°ƒ
        early_stopping = EarlyStopping(
            monitor='val_accuracy',
            patience=3,
            restore_best_weights=True
        )
        
        # è®­ç»ƒæ¨¡å‹
        history = model.fit(
            self.X_train, self.y_train,
            validation_data=(self.X_val, self.y_val),
            epochs=20,
            batch_size=64,
            callbacks=[early_stopping],
            verbose=0
        )
        
        # è¿”å›éªŒè¯å‡†ç¡®ç‡
        return max(history.history['val_accuracy'])
    
    def optimize(self, n_trials=20):
        """æ‰§è¡Œè¶…å‚æ•°ä¼˜åŒ–"""
        print(f"ğŸ›ï¸ å¼€å§‹è¶…å‚æ•°ä¼˜åŒ– (trials={n_trials})...")
        
        # åˆ›å»ºç ”ç©¶å¯¹è±¡
        self.study = optuna.create_study(direction='maximize')
        
        # ä¼˜åŒ–
        self.study.optimize(self.objective, n_trials=n_trials)
        
        # æœ€ä½³å‚æ•°
        self.best_params = self.study.best_params
        
        print("   âœ… è¶…å‚æ•°ä¼˜åŒ–å®Œæˆ!")
        print(f"   ğŸ† æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {self.study.best_value:.4f}")
        print(f"   âš™ï¸ æœ€ä½³å‚æ•°: {self.best_params}")
        
        return self.best_params
    
    def plot_optimization_history(self):
        """ç»˜åˆ¶ä¼˜åŒ–å†å²"""
        if self.study is None:
            print("âŒ è¯·å…ˆè¿è¡Œä¼˜åŒ–!")
            return
            
        # ä¼˜åŒ–å›¾è¡¨
        fig = optuna.visualization.plot_optimization_history(self.study)
        fig.show()
        
        # å‚æ•°é‡è¦æ€§
        fig = optuna.visualization.plot_param_importances(self.study)
        fig.show()

# ä½¿ç”¨ç¤ºä¾‹ (éœ€è¦è¾ƒé•¿è®¡ç®—æ—¶é—´)
# tuner = CNNHyperparameterTuner(X_train, y_train, X_val, y_val, num_classes=10)
# best_params = tuner.optimize(n_trials=10)
```

---

## ğŸ† 22.7 ç« èŠ‚æ€»ç»“ä¸æˆæœå±•ç¤º

### ğŸ¯ æœ¬ç« æ ¸å¿ƒæ”¶è·

é€šè¿‡æœ¬ç« å­¦ä¹ ï¼Œä½ å·²ç»æŒæ¡äº†è®¡ç®—æœºè§†è§‰çš„æ ¸å¿ƒæŠ€èƒ½ï¼š

### ğŸ“Š çŸ¥è¯†æŠ€èƒ½æ ‘

```mermaid
graph TB
    A["ğŸ¨ è®¡ç®—æœºè§†è§‰å·¥ä½œå®¤"] --> B["ğŸ“· å›¾åƒæ•°æ®å¤„ç†"]
    A --> C["ğŸ§  CNNæ ¸å¿ƒåŸç†"]
    A --> D["ğŸ—ï¸ ç½‘ç»œæ¶æ„è®¾è®¡"]
    A --> E["ğŸ¯ å®æˆ˜é¡¹ç›®å¼€å‘"]
    A --> F["ğŸ”§ æ¨¡å‹ä¼˜åŒ–è°ƒä¼˜"]
    
    B --> B1["æ•°æ®åŠ è½½ä¸é¢„å¤„ç†"]
    B --> B2["æ•°æ®å¢å¼ºæŠ€æœ¯"]
    B --> B3["å›¾åƒç‰¹å¾åˆ†æ"]
    
    C --> C1["å·ç§¯æ“ä½œåŸç†"]
    C --> C2["æ± åŒ–å±‚æœºåˆ¶"]
    C --> C3["ç‰¹å¾å›¾ç†è§£"]
    
    D --> D1["ç»å…¸æ¶æ„è§£æ"]
    D --> D2["ç°ä»£ç½‘ç»œè®¾è®¡"]
    D --> D3["è‡ªå®šä¹‰æ¶æ„"]
    
    E --> E1["å®Œæ•´é¡¹ç›®æµç¨‹"]
    E --> E2["æ€§èƒ½è¯„ä¼°åˆ†æ"]
    E --> E3["å¯è§†åŒ–å±•ç¤º"]
    
    F --> F1["è¶…å‚æ•°è°ƒä¼˜"]
    F --> F2["æ¨¡å‹é›†æˆ"]
    F --> F3["éƒ¨ç½²ä¼˜åŒ–"]
    
    style A fill:#e1f5fe
    style B fill:#e8f5e8
    style C fill:#f3e5f5
    style D fill:#fff3e0
    style E fill:#fce4ec
    style F fill:#e3f2fd
```

### ğŸ… æŠ€æœ¯æˆå°±æ¸…å•

- âœ… **æŒæ¡CNNæ ¸å¿ƒåŸç†** - æ·±å…¥ç†è§£å·ç§¯ã€æ± åŒ–ã€ç‰¹å¾å­¦ä¹ æœºåˆ¶
- âœ… **ç†Ÿç»ƒå›¾åƒæ•°æ®å¤„ç†** - é¢„å¤„ç†ã€å¢å¼ºã€æ‰¹å¤„ç†æŠ€æœ¯
- âœ… **è®¾è®¡ç°ä»£CNNæ¶æ„** - ä»ç®€å•åˆ°å¤æ‚çš„ç½‘ç»œè®¾è®¡èƒ½åŠ›
- âœ… **å®Œæˆä¼ä¸šçº§é¡¹ç›®** - æ™ºèƒ½å›¾åƒåˆ†ç±»ç³»ç»Ÿå…¨æµç¨‹å¼€å‘
- âœ… **æŒæ¡æ¨¡å‹ä¼˜åŒ–æŠ€å·§** - è¶…å‚æ•°è°ƒä¼˜ã€æ€§èƒ½æå‡æ–¹æ³•
- âœ… **å…·å¤‡è§†è§‰AIæ€ç»´** - ä»åƒç´ åˆ°è¯­ä¹‰çš„ç³»ç»Ÿæ€§è®¤çŸ¥

### ğŸš€ å®é™…åº”ç”¨åœºæ™¯

ä½ ç°åœ¨å¯ä»¥å°†æ‰€å­¦æŠ€èƒ½åº”ç”¨åˆ°ä»¥ä¸‹åœºæ™¯ï¼š

| åº”ç”¨é¢†åŸŸ | æŠ€æœ¯è¦ç‚¹ | å•†ä¸šä»·å€¼ |
|---------|----------|----------|
| **åŒ»ç–—å½±åƒè¯Šæ–­** | ç—…ç¶æ£€æµ‹ã€åˆ†ç±» | è¾…åŠ©åŒ»ç”Ÿè¯Šæ–­ï¼Œæé«˜å‡†ç¡®ç‡ |
| **æ™ºèƒ½å®‰é˜²ç›‘æ§** | äººè„¸è¯†åˆ«ã€è¡Œä¸ºåˆ†æ | æå‡å®‰å…¨é˜²æŠ¤æ°´å¹³ |
| **å·¥ä¸šè´¨é‡æ£€æµ‹** | ç¼ºé™·è¯†åˆ«ã€è‡ªåŠ¨åˆ†æ‹£ | é™ä½äººå·¥æˆæœ¬ï¼Œæé«˜æ•ˆç‡ |
| **è‡ªåŠ¨é©¾é©¶è§†è§‰** | ç‰©ä½“æ£€æµ‹ã€åœºæ™¯ç†è§£ | æ™ºèƒ½äº¤é€šç³»ç»Ÿæ ¸å¿ƒæŠ€æœ¯ |
| **é›¶å”®å•†å“è¯†åˆ«** | å•†å“åˆ†ç±»ã€åº“å­˜ç®¡ç† | ä¼˜åŒ–è´­ç‰©ä½“éªŒï¼Œè‡ªåŠ¨åŒ–ç®¡ç† |
| **å†œä¸šæ™ºèƒ½ç›‘æµ‹** | ä½œç‰©ç—…å®³è¯†åˆ«ã€ç”Ÿé•¿ç›‘æ§ | ç²¾å‡†å†œä¸šï¼Œæé«˜äº§é‡ |

### ğŸ¤” æ·±åº¦æ€è€ƒé¢˜

1. **æŠ€æœ¯ç†è§£æ·±åŒ–**ï¼š
   - ä¸ºä»€ä¹ˆCNNç‰¹åˆ«é€‚åˆå¤„ç†å›¾åƒæ•°æ®ï¼Ÿä¸ä¼ ç»Ÿå…¨è¿æ¥ç½‘ç»œç›¸æ¯”æœ‰ä»€ä¹ˆæœ¬è´¨åŒºåˆ«ï¼Ÿ
   - å·ç§¯æ ¸æ˜¯å¦‚ä½•"å­¦ä¹ "åˆ°è¾¹ç¼˜ã€çº¹ç†ç­‰ç‰¹å¾çš„ï¼Ÿè¿™ä¸ªè¿‡ç¨‹èƒ½å¦å¯è§†åŒ–ï¼Ÿ

2. **æ¶æ„è®¾è®¡æ€è€ƒ**ï¼š
   - åœ¨è®¾è®¡CNNæ¶æ„æ—¶ï¼Œå¦‚ä½•å¹³è¡¡æ¨¡å‹å¤æ‚åº¦ä¸æ€§èƒ½ï¼Ÿ
   - æ®‹å·®è¿æ¥ã€æ³¨æ„åŠ›æœºåˆ¶ç­‰ç°ä»£æŠ€æœ¯å¦‚ä½•æ”¹å–„ä¼ ç»ŸCNNçš„å±€é™æ€§ï¼Ÿ

3. **åº”ç”¨åœºæ™¯åˆ†æ**ï¼š
   - é’ˆå¯¹åŒ»ç–—å½±åƒè¯Šæ–­ä»»åŠ¡ï¼Œéœ€è¦å¯¹æ ‡å‡†CNNæ¶æ„åšå“ªäº›ç‰¹æ®Šè®¾è®¡ï¼Ÿ
   - å¦‚ä½•å¤„ç†å°æ ·æœ¬å›¾åƒåˆ†ç±»é—®é¢˜ï¼Ÿè¿ç§»å­¦ä¹ çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ

4. **å·¥ç¨‹å®è·µè€ƒè™‘**ï¼š
   - åœ¨ç”Ÿäº§ç¯å¢ƒä¸­éƒ¨ç½²CNNæ¨¡å‹éœ€è¦è€ƒè™‘å“ªäº›å› ç´ ï¼Ÿ
   - å¦‚ä½•å¹³è¡¡æ¨¡å‹å‡†ç¡®ç‡å’Œæ¨ç†é€Ÿåº¦ï¼Œç‰¹åˆ«æ˜¯åœ¨ç§»åŠ¨ç«¯éƒ¨ç½²æ—¶ï¼Ÿ

### ğŸ¬ ä¸‹ç« é¢„å‘Šï¼šå¾ªç¯ç¥ç»ç½‘ç»œä¸åºåˆ—å»ºæ¨¡

åœ¨ä¸‹ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å°†è¿›å…¥**"æ—¶é—´åºåˆ—å®éªŒå®¤"**ï¼Œæ¢ç´¢å¤„ç†åºåˆ—æ•°æ®çš„å¼ºå¤§å·¥å…·ï¼š

- ğŸ”„ **RNN/LSTM/GRUåŸç†** - æŒæ¡åºåˆ—å»ºæ¨¡æ ¸å¿ƒç®—æ³•
- ğŸ“ˆ **æ—¶é—´åºåˆ—é¢„æµ‹** - è‚¡ç¥¨ä»·æ ¼ã€æ°”å€™æ•°æ®é¢„æµ‹é¡¹ç›®
- ğŸ“ **è‡ªç„¶è¯­è¨€å¤„ç†** - æ–‡æœ¬åˆ†ç±»ã€æƒ…æ„Ÿåˆ†æåº”ç”¨
- ğŸ¤– **æ™ºèƒ½å¯¹è¯ç³»ç»Ÿ** - æ„å»ºä¼šè¯AIåŠ©æ‰‹
- ğŸµ **åºåˆ—ç”Ÿæˆæ¨¡å‹** - éŸ³ä¹ã€æ–‡æœ¬åˆ›ä½œåº”ç”¨

---

*"ä»åƒç´ åˆ°æ™ºèƒ½ï¼Œä»æ•°æ®åˆ°æ´å¯Ÿã€‚è®¡ç®—æœºè§†è§‰è®©æœºå™¨æ‹¥æœ‰äº†'çœ¼ç›'ï¼Œè€Œä½ å·²ç»æŒæ¡äº†èµ‹äºˆæœºå™¨è§†è§‰èƒ½åŠ›çš„æŠ€èƒ½ï¼"* ğŸ¨ğŸ‘ï¸âœ¨