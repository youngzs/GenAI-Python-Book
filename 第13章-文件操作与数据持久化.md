# ç¬¬13ç«  - æ–‡ä»¶æ“ä½œä¸æ•°æ®æŒä¹…åŒ–

> ğŸ¯ **æœ¬ç« ç›®æ ‡**: æŒæ¡Pythonä¸­çš„æ–‡ä»¶æ“ä½œã€æ•°æ®åºåˆ—åŒ–å’Œæ•°æ®åº“æ“ä½œï¼Œå»ºç«‹å®Œæ•´çš„æ•°æ®æŒä¹…åŒ–æŠ€èƒ½ä½“ç³»

## ğŸ  ç”Ÿæ´»åŒ–å¼•å…¥

æƒ³è±¡ä¸€ä¸‹ï¼Œä½ æ˜¯ä¸€ä¸ªå›¾ä¹¦é¦†ç®¡ç†å‘˜ï¼š
- **æ–‡ä»¶æ“ä½œ** å°±åƒç®¡ç†å›¾ä¹¦é¦†çš„è—ä¹¦ï¼šåˆ†ç±»ã€æ•´ç†ã€æŸ¥æ‰¾ã€å€Ÿé˜…
- **æ•°æ®åºåˆ—åŒ–** å°±åƒæŠŠä¹¦ç±ä¿¡æ¯è®°å½•åœ¨å¡ç‰‡ä¸Šï¼šä¿å­˜å’Œè¯»å–ä¹¦ç±è¯¦æƒ…
- **æ•°æ®åº“** å°±åƒå›¾ä¹¦é¦†çš„ç”µå­ç®¡ç†ç³»ç»Ÿï¼šé«˜æ•ˆå­˜å‚¨å’Œæ£€ç´¢å¤§é‡ä¿¡æ¯

æœ¬ç« å°†æ•™ä½ æˆä¸ºä¸€ä¸ªä¼˜ç§€çš„"æ•°æ®ç®¡ç†å‘˜"ï¼

---

## ğŸ“š çŸ¥è¯†åœ°å›¾

```mermaid
mindmap
  root((æ–‡ä»¶æ“ä½œä¸æ•°æ®æŒä¹…åŒ–))
    æ–‡ä»¶ç³»ç»Ÿæ“ä½œ
      è·¯å¾„æ“ä½œ
        pathlibæ¨¡å—
        ç»å¯¹è·¯å¾„ç›¸å¯¹è·¯å¾„
      æ–‡ä»¶å±æ€§
        å¤§å°æ—¶é—´æƒé™
        æ–‡ä»¶ç±»å‹æ£€æµ‹
      ç›®å½•ç®¡ç†
        åˆ›å»ºåˆ é™¤éå†
        æ–‡ä»¶æœç´¢è¿‡æ»¤
    æ–‡ä»¶è¯»å†™å¤„ç†
      è¯»å†™æ¨¡å¼
        æ–‡æœ¬æ¨¡å¼äºŒè¿›åˆ¶æ¨¡å¼
        ç¼–ç å¤„ç†UTF8GBK
      æ€§èƒ½ä¼˜åŒ–
        ç¼“å†²æœºåˆ¶
        æµå¼å¤„ç†
      ä¸Šä¸‹æ–‡ç®¡ç†
        withè¯­å¥
        èµ„æºè‡ªåŠ¨é‡Šæ”¾
    æ•°æ®åºåˆ—åŒ–
      JSONæ ¼å¼
        è½»é‡çº§äº¤æ¢
        è·¨è¯­è¨€å…¼å®¹
      Pickleåºåˆ—åŒ–
        Pythonå¯¹è±¡
        å®Œæ•´çŠ¶æ€ä¿å­˜
      CSVè¡¨æ ¼
        ç»“æ„åŒ–æ•°æ®
        Excelå…¼å®¹
    æ•°æ®åº“æ“ä½œ
      SQLiteæ•°æ®åº“
        åµŒå…¥å¼è½»é‡
        SQLè¯­å¥æ“ä½œ
      ORMæ¡†æ¶
        å¯¹è±¡å…³ç³»æ˜ å°„
        ç®€åŒ–æ•°æ®æ“ä½œ
      äº‹åŠ¡å¤„ç†
        æ•°æ®ä¸€è‡´æ€§
        é”™è¯¯å›æ»š
```

---

## 13.1 æ–‡ä»¶ç³»ç»Ÿæ“ä½œè¯¦è§£

### ğŸ“ æ ¸å¿ƒæ¦‚å¿µï¼šå›¾ä¹¦é¦†ç®¡ç†ç³»ç»Ÿ

æ–‡ä»¶ç³»ç»Ÿå°±åƒä¸€ä¸ªå·¨å¤§çš„å›¾ä¹¦é¦†ï¼š
- **æ–‡ä»¶** = å›¾ä¹¦é¦†ä¸­çš„æ¯ä¸€æœ¬ä¹¦
- **ç›®å½•** = å›¾ä¹¦é¦†çš„ä¹¦æ¶å’Œåˆ†ç±»åŒºåŸŸ
- **è·¯å¾„** = æ‰¾åˆ°ç‰¹å®šä¹¦ç±çš„åœ°å€ï¼ˆå‡ æ¥¼å‡ æ’å‡ å·ä¹¦æ¶ï¼‰
- **æ–‡ä»¶å±æ€§** = ä¹¦ç±çš„åŸºæœ¬ä¿¡æ¯ï¼ˆä½œè€…ã€å‡ºç‰ˆæ—¥æœŸã€é¡µæ•°ç­‰ï¼‰

### ğŸ“ ç°ä»£åŒ–è·¯å¾„æ“ä½œï¼špathlibæ¨¡å—

```python
from pathlib import Path
import os
import shutil
import time
from datetime import datetime
from typing import List, Optional

class SmartFileManager:
    """æ™ºèƒ½æ–‡ä»¶ç®¡ç†å™¨ - åƒå›¾ä¹¦é¦†ç®¡ç†å‘˜ä¸€æ ·ç®¡ç†æ–‡ä»¶"""
    
    def __init__(self, base_path: str = "."):
        """åˆå§‹åŒ–æ–‡ä»¶ç®¡ç†å™¨
        
        Args:
            base_path: åŸºç¡€å·¥ä½œç›®å½•ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•
        """
        self.base_path = Path(base_path).resolve()
        print(f"ğŸ“ æ–‡ä»¶ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œå·¥ä½œç›®å½•: {self.base_path}")
    
    def get_file_info(self, file_path: str) -> dict:
        """è·å–æ–‡ä»¶è¯¦ç»†ä¿¡æ¯ - å°±åƒæŸ¥çœ‹å›¾ä¹¦çš„åŸºæœ¬ä¿¡æ¯å¡ç‰‡
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            åŒ…å«æ–‡ä»¶ä¿¡æ¯çš„å­—å…¸
        """
        path = Path(file_path)
        
        if not path.exists():
            return {"error": "æ–‡ä»¶ä¸å­˜åœ¨"}
        
        stat = path.stat()
        
        info = {
            "name": path.name,                    # æ–‡ä»¶å
            "parent": str(path.parent),           # çˆ¶ç›®å½•
            "size": stat.st_size,                 # æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
            "size_human": self._format_size(stat.st_size),  # äººç±»å¯è¯»çš„å¤§å°
            "created": datetime.fromtimestamp(stat.st_ctime),  # åˆ›å»ºæ—¶é—´
            "modified": datetime.fromtimestamp(stat.st_mtime), # ä¿®æ”¹æ—¶é—´
            "is_file": path.is_file(),            # æ˜¯å¦ä¸ºæ–‡ä»¶
            "is_dir": path.is_dir(),              # æ˜¯å¦ä¸ºç›®å½•
            "suffix": path.suffix,                # æ–‡ä»¶æ‰©å±•å
            "absolute_path": str(path.absolute()) # ç»å¯¹è·¯å¾„
        }
        
        return info
    
    def _format_size(self, size_bytes: int) -> str:
        """å°†å­—èŠ‚æ•°è½¬æ¢ä¸ºäººç±»å¯è¯»çš„æ ¼å¼"""
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size_bytes < 1024:
                return f"{size_bytes:.1f} {unit}"
            size_bytes /= 1024
        return f"{size_bytes:.1f} TB"
    
    def create_directory_structure(self, structure: dict, base_path: Optional[str] = None):
        """åˆ›å»ºç›®å½•ç»“æ„ - å°±åƒåœ¨å›¾ä¹¦é¦†ä¸­è®¾ç½®æ–°çš„ä¹¦æ¶åˆ†ç±»
        
        Args:
            structure: ç›®å½•ç»“æ„å­—å…¸
            base_path: åŸºç¡€è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨å·¥ä½œç›®å½•
        """
        if base_path is None:
            base_path = self.base_path
        else:
            base_path = Path(base_path)
        
        def create_recursive(struct: dict, current_path: Path):
            for name, content in struct.items():
                new_path = current_path / name
                
                if isinstance(content, dict):
                    # åˆ›å»ºç›®å½•
                    new_path.mkdir(parents=True, exist_ok=True)
                    print(f"ğŸ“ åˆ›å»ºç›®å½•: {new_path}")
                    create_recursive(content, new_path)
                else:
                    # åˆ›å»ºæ–‡ä»¶
                    new_path.parent.mkdir(parents=True, exist_ok=True)
                    with open(new_path, 'w', encoding='utf-8') as f:
                        f.write(str(content))
                    print(f"ğŸ“„ åˆ›å»ºæ–‡ä»¶: {new_path}")
        
        create_recursive(structure, base_path)
    
    def find_files(self, pattern: str, search_path: Optional[str] = None) -> List[Path]:
        """æŸ¥æ‰¾æ–‡ä»¶ - å°±åƒåœ¨å›¾ä¹¦é¦†ä¸­æŒ‰å…³é”®è¯æœç´¢ä¹¦ç±
        
        Args:
            pattern: æœç´¢æ¨¡å¼ï¼ˆæ”¯æŒé€šé…ç¬¦ï¼‰
            search_path: æœç´¢è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨å·¥ä½œç›®å½•
            
        Returns:
            åŒ¹é…çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        if search_path is None:
            search_path = self.base_path
        else:
            search_path = Path(search_path)
        
        # ä½¿ç”¨globæ¨¡å¼åŒ¹é…
        matches = list(search_path.rglob(pattern))
        
        print(f"ğŸ” æœç´¢æ¨¡å¼ '{pattern}' æ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…é¡¹")
        return matches
    
    def organize_files_by_type(self, source_dir: str, target_dir: str):
        """æŒ‰æ–‡ä»¶ç±»å‹æ•´ç†æ–‡ä»¶ - å°±åƒæŒ‰ä¸»é¢˜åˆ†ç±»å›¾ä¹¦
        
        Args:
            source_dir: æºç›®å½•
            target_dir: ç›®æ ‡ç›®å½•
        """
        source_path = Path(source_dir)
        target_path = Path(target_dir)
        
        # å®šä¹‰æ–‡ä»¶ç±»å‹åˆ†ç±»
        file_categories = {
            'images': ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.svg'],
            'documents': ['.pdf', '.doc', '.docx', '.txt', '.rtf', '.odt'],
            'spreadsheets': ['.xls', '.xlsx', '.csv', '.ods'],
            'presentations': ['.ppt', '.pptx', '.odp'],
            'code': ['.py', '.js', '.html', '.css', '.java', '.cpp', '.c'],
            'archives': ['.zip', '.rar', '.7z', '.tar', '.gz'],
            'audio': ['.mp3', '.wav', '.flac', '.aac', '.ogg'],
            'video': ['.mp4', '.avi', '.mkv', '.mov', '.wmv']
        }
        
        # åˆ›å»ºåˆ†ç±»ç›®å½•
        for category in file_categories:
            category_path = target_path / category
            category_path.mkdir(parents=True, exist_ok=True)
        
        # æ•´ç†æ–‡ä»¶
        moved_count = 0
        for file_path in source_path.rglob('*'):
            if file_path.is_file():
                file_extension = file_path.suffix.lower()
                
                # æŸ¥æ‰¾æ–‡ä»¶æ‰€å±åˆ†ç±»
                target_category = 'others'  # é»˜è®¤åˆ†ç±»
                for category, extensions in file_categories.items():
                    if file_extension in extensions:
                        target_category = category
                        break
                
                # ç§»åŠ¨æ–‡ä»¶
                target_file_path = target_path / target_category / file_path.name
                
                # å¤„ç†æ–‡ä»¶åå†²çª
                counter = 1
                original_name = target_file_path.stem
                while target_file_path.exists():
                    target_file_path = target_file_path.parent / f"{original_name}_{counter}{file_path.suffix}"
                    counter += 1
                
                shutil.move(str(file_path), str(target_file_path))
                print(f"ğŸ“¦ ç§»åŠ¨æ–‡ä»¶: {file_path.name} â†’ {target_category}/")
                moved_count += 1
        
        print(f"âœ… æ–‡ä»¶æ•´ç†å®Œæˆï¼Œå…±ç§»åŠ¨ {moved_count} ä¸ªæ–‡ä»¶")
    
    def clean_empty_directories(self, path: str):
        """æ¸…ç†ç©ºç›®å½• - å°±åƒç§»é™¤å›¾ä¹¦é¦†ä¸­çš„ç©ºä¹¦æ¶
        
        Args:
            path: è¦æ¸…ç†çš„è·¯å¾„
        """
        path = Path(path)
        removed_count = 0
        
        # ä»æœ€æ·±å±‚å¼€å§‹æ¸…ç†ï¼ˆè‡ªåº•å‘ä¸Šï¼‰
        for dir_path in sorted(path.rglob('*'), key=lambda p: len(p.parts), reverse=True):
            if dir_path.is_dir():
                try:
                    # å°è¯•åˆ é™¤ç©ºç›®å½•
                    dir_path.rmdir()
                    print(f"ğŸ—‘ï¸ åˆ é™¤ç©ºç›®å½•: {dir_path}")
                    removed_count += 1
                except OSError:
                    # ç›®å½•ä¸ä¸ºç©ºï¼Œè·³è¿‡
                    pass
        
        print(f"âœ… æ¸…ç†å®Œæˆï¼Œå…±åˆ é™¤ {removed_count} ä¸ªç©ºç›®å½•")


# ä½¿ç”¨ç¤ºä¾‹
def demo_file_manager():
    """æ–‡ä»¶ç®¡ç†å™¨æ¼”ç¤º"""
    print("=== æ™ºèƒ½æ–‡ä»¶ç®¡ç†å™¨æ¼”ç¤º ===\n")
    
    # åˆ›å»ºæ–‡ä»¶ç®¡ç†å™¨
    manager = SmartFileManager("./demo_files")
    
    # 1. åˆ›å»ºæ¼”ç¤ºç›®å½•ç»“æ„
    print("1. åˆ›å»ºæ¼”ç¤ºç›®å½•ç»“æ„")
    demo_structure = {
        "documents": {
            "reports": {
                "2024_report.txt": "è¿™æ˜¯2024å¹´çš„æŠ¥å‘Šå†…å®¹",
                "2023_report.txt": "è¿™æ˜¯2023å¹´çš„æŠ¥å‘Šå†…å®¹"
            },
            "manuals": {
                "user_manual.txt": "ç”¨æˆ·æ‰‹å†Œå†…å®¹",
                "admin_manual.txt": "ç®¡ç†å‘˜æ‰‹å†Œå†…å®¹"
            }
        },
        "images": {
            "photos": {},
            "icons": {}
        },
        "temp_files": {
            "temp1.tmp": "ä¸´æ—¶æ–‡ä»¶1",
            "temp2.tmp": "ä¸´æ—¶æ–‡ä»¶2"
        }
    }
    
    manager.create_directory_structure(demo_structure)
    print()
    
    # 2. è·å–æ–‡ä»¶ä¿¡æ¯
    print("2. è·å–æ–‡ä»¶ä¿¡æ¯")
    file_info = manager.get_file_info("./demo_files/documents/reports/2024_report.txt")
    for key, value in file_info.items():
        print(f"   {key}: {value}")
    print()
    
    # 3. æŸ¥æ‰¾æ–‡ä»¶
    print("3. æŸ¥æ‰¾æ‰€æœ‰.txtæ–‡ä»¶")
    txt_files = manager.find_files("*.txt", "./demo_files")
    for file_path in txt_files:
        print(f"   ğŸ“„ {file_path}")
    print()
    
    # 4. æ¸…ç†ç©ºç›®å½•
    print("4. æ¸…ç†ç©ºç›®å½•")
    manager.clean_empty_directories("./demo_files")
    print()


if __name__ == "__main__":
    demo_file_manager()
```

### ğŸ› ï¸ å®æˆ˜é¡¹ç›®ï¼šæ™ºèƒ½æ–‡ä»¶æ•´ç†å·¥å…·

```python
import os
import hashlib
from collections import defaultdict
from typing import Dict, Set

class DuplicateFileFinder:
    """é‡å¤æ–‡ä»¶æŸ¥æ‰¾å™¨ - æ‰¾å‡ºå›¾ä¹¦é¦†ä¸­çš„é‡å¤è—ä¹¦"""
    
    def __init__(self):
        self.file_hashes: Dict[str, List[str]] = defaultdict(list)
        self.processed_count = 0
    
    def calculate_file_hash(self, file_path: str) -> str:
        """è®¡ç®—æ–‡ä»¶çš„MD5å“ˆå¸Œå€¼ - å°±åƒç»™æ¯æœ¬ä¹¦ä¸€ä¸ªå”¯ä¸€çš„èº«ä»½è¯å·"""
        hash_md5 = hashlib.md5()
        try:
            with open(file_path, "rb") as f:
                # åˆ†å—è¯»å–ï¼Œé¿å…å¤§æ–‡ä»¶å ç”¨è¿‡å¤šå†…å­˜
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            return hash_md5.hexdigest()
        except (IOError, OSError) as e:
            print(f"âš ï¸ æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")
            return ""
    
    def scan_directory(self, directory: str) -> Dict[str, List[str]]:
        """æ‰«æç›®å½•æŸ¥æ‰¾é‡å¤æ–‡ä»¶
        
        Args:
            directory: è¦æ‰«æçš„ç›®å½•è·¯å¾„
            
        Returns:
            é‡å¤æ–‡ä»¶å­—å…¸ï¼Œé”®ä¸ºå“ˆå¸Œå€¼ï¼Œå€¼ä¸ºæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        print(f"ğŸ” å¼€å§‹æ‰«æç›®å½•: {directory}")
        
        for root, dirs, files in os.walk(directory):
            for file in files:
                file_path = os.path.join(root, file)
                file_hash = self.calculate_file_hash(file_path)
                
                if file_hash:
                    self.file_hashes[file_hash].append(file_path)
                    self.processed_count += 1
                    
                    if self.processed_count % 100 == 0:
                        print(f"   å·²å¤„ç† {self.processed_count} ä¸ªæ–‡ä»¶...")
        
        # åªè¿”å›æœ‰é‡å¤çš„æ–‡ä»¶
        duplicates = {hash_val: paths for hash_val, paths in self.file_hashes.items() 
                     if len(paths) > 1}
        
        print(f"âœ… æ‰«æå®Œæˆï¼Œå…±å¤„ç† {self.processed_count} ä¸ªæ–‡ä»¶")
        print(f"ğŸ” å‘ç° {len(duplicates)} ç»„é‡å¤æ–‡ä»¶")
        
        return duplicates
    
    def generate_report(self, duplicates: Dict[str, List[str]]) -> str:
        """ç”Ÿæˆé‡å¤æ–‡ä»¶æŠ¥å‘Š"""
        report_lines = ["# é‡å¤æ–‡ä»¶æŠ¥å‘Š\n"]
        total_duplicates = 0
        total_wasted_space = 0
        
        for i, (file_hash, file_paths) in enumerate(duplicates.items(), 1):
            report_lines.append(f"## é‡å¤ç»„ {i}")
            report_lines.append(f"**æ–‡ä»¶å“ˆå¸Œ**: `{file_hash}`")
            report_lines.append(f"**é‡å¤æ•°é‡**: {len(file_paths)}")
            
            # è·å–æ–‡ä»¶å¤§å°
            try:
                file_size = os.path.getsize(file_paths[0])
                wasted_space = file_size * (len(file_paths) - 1)
                total_wasted_space += wasted_space
                
                report_lines.append(f"**æ–‡ä»¶å¤§å°**: {self._format_size(file_size)}")
                report_lines.append(f"**æµªè´¹ç©ºé—´**: {self._format_size(wasted_space)}")
            except OSError:
                pass
            
            report_lines.append("**æ–‡ä»¶è·¯å¾„**:")
            for path in file_paths:
                report_lines.append(f"- `{path}`")
            
            report_lines.append("")
            total_duplicates += len(file_paths) - 1
        
        # æ·»åŠ æ€»ç»“
        summary = f"""
## ğŸ“Š æ€»ç»“æŠ¥å‘Š

- **é‡å¤æ–‡ä»¶ç»„æ•°**: {len(duplicates)}
- **é‡å¤æ–‡ä»¶æ€»æ•°**: {total_duplicates}
- **æµªè´¹å­˜å‚¨ç©ºé—´**: {self._format_size(total_wasted_space)}
- **å»ºè®®**: ä¿ç•™æ¯ç»„ä¸­çš„ä¸€ä¸ªæ–‡ä»¶ï¼Œåˆ é™¤å…¶ä½™é‡å¤æ–‡ä»¶

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        
        report_lines.append(summary)
        return "\n".join(report_lines)
    
    def _format_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size_bytes < 1024:
                return f"{size_bytes:.1f} {unit}"
            size_bytes /= 1024
        return f"{size_bytes:.1f} TB"


# ä½¿ç”¨ç¤ºä¾‹
def demo_duplicate_finder():
    """é‡å¤æ–‡ä»¶æŸ¥æ‰¾å™¨æ¼”ç¤º"""
    print("=== é‡å¤æ–‡ä»¶æŸ¥æ‰¾å™¨æ¼”ç¤º ===\n")
    
    finder = DuplicateFileFinder()
    
    # æ‰«æå½“å‰ç›®å½•
    duplicates = finder.scan_directory(".")
    
    if duplicates:
        # ç”ŸæˆæŠ¥å‘Š
        report = finder.generate_report(duplicates)
        
        # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
        with open("duplicate_files_report.md", "w", encoding="utf-8") as f:
            f.write(report)
        
        print("ğŸ“„ é‡å¤æ–‡ä»¶æŠ¥å‘Šå·²ä¿å­˜åˆ° duplicate_files_report.md")
        
        # æ˜¾ç¤ºå‰å‡ ç»„é‡å¤æ–‡ä»¶
        print("\nğŸ” å‘ç°çš„é‡å¤æ–‡ä»¶ï¼ˆå‰3ç»„ï¼‰ï¼š")
        for i, (file_hash, file_paths) in enumerate(list(duplicates.items())[:3], 1):
            print(f"\né‡å¤ç»„ {i}:")
            for path in file_paths:
                print(f"  ğŸ“„ {path}")
    else:
        print("âœ… æœªå‘ç°é‡å¤æ–‡ä»¶")


if __name__ == "__main__":
    demo_duplicate_finder()
```

---

## 13.2 æ–‡ä»¶è¯»å†™ä¸ç¼–ç å¤„ç†

### ğŸ“ æ ¸å¿ƒæ¦‚å¿µï¼šå€Ÿä¹¦è¿˜ä¹¦ç³»ç»Ÿ

æ–‡ä»¶è¯»å†™å°±åƒå›¾ä¹¦é¦†çš„å€Ÿä¹¦è¿˜ä¹¦è¿‡ç¨‹ï¼š
- **æ‰“å¼€æ–‡ä»¶** = ä»ä¹¦æ¶ä¸Šå–ä¸‹ä¸€æœ¬ä¹¦
- **è¯»å–å†…å®¹** = ç¿»é˜…ä¹¦ç±å†…å®¹
- **å†™å…¥å†…å®¹** = åœ¨ç¬”è®°æœ¬ä¸Šè®°å½•å†…å®¹
- **å…³é—­æ–‡ä»¶** = æŠŠä¹¦æ”¾å›ä¹¦æ¶

### ğŸ“ é«˜æ•ˆæ–‡ä»¶å¤„ç†ç³»ç»Ÿ

```python
import csv
import json
import tempfile
import gzip
from contextlib import contextmanager
from typing import Iterator, Any, Optional

class AdvancedFileProcessor:
    """é«˜çº§æ–‡ä»¶å¤„ç†å™¨ - åƒä¸“ä¸šå›¾ä¹¦ç®¡ç†å‘˜ä¸€æ ·å¤„ç†å„ç§æ–‡ä»¶"""
    
    def __init__(self):
        self.encoding = 'utf-8'
        self.buffer_size = 8192  # 8KBç¼“å†²åŒº
    
    @contextmanager
    def safe_file_operation(self, file_path: str, mode: str, **kwargs):
        """å®‰å…¨çš„æ–‡ä»¶æ“ä½œä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        file_handle = None
        try:
            file_handle = open(file_path, mode, encoding=self.encoding, **kwargs)
            yield file_handle
        except IOError as e:
            print(f"âŒ æ–‡ä»¶æ“ä½œå¤±è´¥: {e}")
            raise
        finally:
            if file_handle:
                file_handle.close()
    
    def read_large_file_in_chunks(self, file_path: str, chunk_size: int = None) -> Iterator[str]:
        """åˆ†å—è¯»å–å¤§æ–‡ä»¶ - å°±åƒä¸€é¡µä¸€é¡µåœ°ç¿»é˜…åšé‡çš„ç™¾ç§‘å…¨ä¹¦
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            chunk_size: å—å¤§å°ï¼Œé»˜è®¤ä½¿ç”¨ç¼“å†²åŒºå¤§å°
            
        Yields:
            æ–‡ä»¶å†…å®¹å—
        """
        if chunk_size is None:
            chunk_size = self.buffer_size
        
        with self.safe_file_operation(file_path, 'r') as file:
            while True:
                chunk = file.read(chunk_size)
                if not chunk:
                    break
                yield chunk
    
    def read_lines_efficiently(self, file_path: str) -> Iterator[str]:
        """é«˜æ•ˆé€è¡Œè¯»å– - å°±åƒé€æ¡é˜…è¯»å›¾ä¹¦ç›®å½•
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Yields:
            æ–‡ä»¶çš„æ¯ä¸€è¡Œ
        """
        with self.safe_file_operation(file_path, 'r') as file:
            for line_number, line in enumerate(file, 1):
                yield line.rstrip('\n\r')  # ç§»é™¤è¡Œå°¾æ¢è¡Œç¬¦
    
    def write_with_backup(self, file_path: str, content: str, backup: bool = True):
        """å®‰å…¨å†™å…¥æ–‡ä»¶ï¼ˆå¸¦å¤‡ä»½ï¼‰- å°±åƒä¿®æ”¹é‡è¦æ–‡æ¡£æ—¶å…ˆåšå¤‡ä»½
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            content: è¦å†™å…¥çš„å†…å®¹
            backup: æ˜¯å¦åˆ›å»ºå¤‡ä»½
        """
        file_path = Path(file_path)
        
        # åˆ›å»ºå¤‡ä»½
        if backup and file_path.exists():
            backup_path = file_path.with_suffix(file_path.suffix + '.backup')
            shutil.copy2(file_path, backup_path)
            print(f"ğŸ“‹ åˆ›å»ºå¤‡ä»½: {backup_path}")
        
        # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ç¡®ä¿åŸå­æ€§å†™å…¥
        with tempfile.NamedTemporaryFile(
            mode='w', 
            encoding=self.encoding, 
            dir=file_path.parent, 
            delete=False
        ) as temp_file:
            temp_file.write(content)
            temp_path = temp_file.name
        
        # åŸå­æ€§æ›¿æ¢
        shutil.move(temp_path, file_path)
        print(f"âœ… æ–‡ä»¶å†™å…¥å®Œæˆ: {file_path}")
    
    def detect_encoding(self, file_path: str) -> str:
        """æ£€æµ‹æ–‡ä»¶ç¼–ç  - å°±åƒè¯†åˆ«ä¸åŒè¯­è¨€çš„ä¹¦ç±
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ£€æµ‹åˆ°çš„ç¼–ç æ ¼å¼
        """
        # å¸¸è§ç¼–ç åˆ—è¡¨
        encodings = ['utf-8', 'gbk', 'gb2312', 'utf-16', 'ascii', 'latin-1']
        
        for encoding in encodings:
            try:
                with open(file_path, 'r', encoding=encoding) as file:
                    file.read(1024)  # è¯»å–å‰1KBè¿›è¡Œæµ‹è¯•
                return encoding
            except UnicodeDecodeError:
                continue
        
        return 'utf-8'  # é»˜è®¤è¿”å›UTF-8
    
    def convert_encoding(self, input_path: str, output_path: str, 
                        source_encoding: str, target_encoding: str = 'utf-8'):
        """è½¬æ¢æ–‡ä»¶ç¼–ç  - å°±åƒç¿»è¯‘ä¸åŒè¯­è¨€çš„ä¹¦ç±
        
        Args:
            input_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            source_encoding: æºç¼–ç 
            target_encoding: ç›®æ ‡ç¼–ç 
        """
        try:
            with open(input_path, 'r', encoding=source_encoding) as source_file:
                content = source_file.read()
            
            with open(output_path, 'w', encoding=target_encoding) as target_file:
                target_file.write(content)
            
            print(f"âœ… ç¼–ç è½¬æ¢å®Œæˆ: {source_encoding} â†’ {target_encoding}")
            
        except UnicodeDecodeError as e:
            print(f"âŒ ç¼–ç è½¬æ¢å¤±è´¥: {e}")
            raise
    
    def compress_text_file(self, input_path: str, output_path: str):
        """å‹ç¼©æ–‡æœ¬æ–‡ä»¶ - å°±åƒæŠŠä¹¦ç±è£…è¿›å‹ç¼©è¢‹èŠ‚çœç©ºé—´
        
        Args:
            input_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºå‹ç¼©æ–‡ä»¶è·¯å¾„
        """
        with open(input_path, 'rb') as input_file:
            with gzip.open(output_path, 'wb') as output_file:
                shutil.copyfileobj(input_file, output_file)
        
        # è®¡ç®—å‹ç¼©ç‡
        original_size = os.path.getsize(input_path)
        compressed_size = os.path.getsize(output_path)
        ratio = (1 - compressed_size / original_size) * 100
        
        print(f"âœ… æ–‡ä»¶å‹ç¼©å®Œæˆ")
        print(f"   åŸå§‹å¤§å°: {self._format_size(original_size)}")
        print(f"   å‹ç¼©å¤§å°: {self._format_size(compressed_size)}")
        print(f"   å‹ç¼©ç‡: {ratio:.1f}%")
    
    def _format_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size_bytes < 1024:
                return f"{size_bytes:.1f} {unit}"
            size_bytes /= 1024
        return f"{size_bytes:.1f} TB"


class LogAnalyzer:
    """æ—¥å¿—åˆ†æå·¥å…· - åƒä¸“ä¸šçš„æ•°æ®åˆ†æå¸ˆä¸€æ ·å¤„ç†æ—¥å¿—æ–‡ä»¶"""
    
    def __init__(self):
        self.processor = AdvancedFileProcessor()
        self.stats = {
            'total_lines': 0,
            'error_lines': 0,
            'warning_lines': 0,
            'info_lines': 0,
            'ip_addresses': defaultdict(int),
            'status_codes': defaultdict(int),
            'timestamps': []
        }
    
    def analyze_log_file(self, log_path: str) -> dict:
        """åˆ†ææ—¥å¿—æ–‡ä»¶ - å°±åƒç ”ç©¶å›¾ä¹¦å€Ÿé˜…è®°å½•æ‰¾å‡ºè§„å¾‹
        
        Args:
            log_path: æ—¥å¿—æ–‡ä»¶è·¯å¾„
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        print(f"ğŸ“Š å¼€å§‹åˆ†ææ—¥å¿—æ–‡ä»¶: {log_path}")
        
        # é‡ç½®ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_lines': 0,
            'error_lines': 0,
            'warning_lines': 0,
            'info_lines': 0,
            'ip_addresses': defaultdict(int),
            'status_codes': defaultdict(int),
            'timestamps': []
        }
        
        # é€è¡Œåˆ†ææ—¥å¿—
        for line in self.processor.read_lines_efficiently(log_path):
            self._analyze_line(line)
            self.stats['total_lines'] += 1
            
            if self.stats['total_lines'] % 10000 == 0:
                print(f"   å·²åˆ†æ {self.stats['total_lines']} è¡Œ...")
        
        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        return self._generate_analysis_report()
    
    def _analyze_line(self, line: str):
        """åˆ†æå•è¡Œæ—¥å¿—"""
        line_lower = line.lower()
        
        # ç»Ÿè®¡æ—¥å¿—çº§åˆ«
        if 'error' in line_lower:
            self.stats['error_lines'] += 1
        elif 'warning' in line_lower or 'warn' in line_lower:
            self.stats['warning_lines'] += 1
        elif 'info' in line_lower:
            self.stats['info_lines'] += 1
        
        # æå–IPåœ°å€ï¼ˆç®€å•æ­£åˆ™åŒ¹é…ï¼‰
        import re
        ip_pattern = r'\b(?:[0-9]{1,3}\.){3}[0-9]{1,3}\b'
        ips = re.findall(ip_pattern, line)
        for ip in ips:
            self.stats['ip_addresses'][ip] += 1
        
        # æå–HTTPçŠ¶æ€ç 
        status_pattern = r'\b[1-5][0-9]{2}\b'
        statuses = re.findall(status_pattern, line)
        for status in statuses:
            self.stats['status_codes'][status] += 1
    
    def _generate_analysis_report(self) -> dict:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        report = {
            'summary': {
                'total_lines': self.stats['total_lines'],
                'error_lines': self.stats['error_lines'],
                'warning_lines': self.stats['warning_lines'],
                'info_lines': self.stats['info_lines'],
                'error_rate': self.stats['error_lines'] / max(self.stats['total_lines'], 1) * 100
            },
            'top_ips': dict(sorted(self.stats['ip_addresses'].items(), 
                                 key=lambda x: x[1], reverse=True)[:10]),
            'status_codes': dict(self.stats['status_codes'])
        }
        
        print(f"âœ… æ—¥å¿—åˆ†æå®Œæˆ")
        print(f"   æ€»è¡Œæ•°: {report['summary']['total_lines']}")
        print(f"   é”™è¯¯è¡Œæ•°: {report['summary']['error_lines']}")
        print(f"   é”™è¯¯ç‡: {report['summary']['error_rate']:.2f}%")
        
        return report
    
    def save_analysis_report(self, report: dict, output_path: str):
        """ä¿å­˜åˆ†ææŠ¥å‘Šåˆ°æ–‡ä»¶"""
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        print(f"ğŸ“„ åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")


# ä½¿ç”¨ç¤ºä¾‹
def demo_file_processing():
    """æ–‡ä»¶å¤„ç†æ¼”ç¤º"""
    print("=== é«˜çº§æ–‡ä»¶å¤„ç†æ¼”ç¤º ===\n")
    
    processor = AdvancedFileProcessor()
    
    # 1. åˆ›å»ºæ¼”ç¤ºæ–‡ä»¶
    print("1. åˆ›å»ºæ¼”ç¤ºæ–‡ä»¶")
    demo_content = """è¿™æ˜¯ç¬¬ä¸€è¡Œå†…å®¹
è¿™æ˜¯ç¬¬äºŒè¡Œå†…å®¹ï¼ŒåŒ…å«ä¸­æ–‡å­—ç¬¦
This is the third line with English
è¿™æ˜¯ç¬¬å››è¡Œï¼Œæµ‹è¯•ç¼–ç å¤„ç†
æœ€åä¸€è¡Œå†…å®¹"""
    
    with open("demo.txt", "w", encoding="utf-8") as f:
        f.write(demo_content)
    print("   âœ… æ¼”ç¤ºæ–‡ä»¶åˆ›å»ºå®Œæˆ")
    
    # 2. é€è¡Œè¯»å–æ–‡ä»¶
    print("\n2. é€è¡Œè¯»å–æ–‡ä»¶")
    for i, line in enumerate(processor.read_lines_efficiently("demo.txt"), 1):
        print(f"   ç¬¬{i}è¡Œ: {line}")
    
    # 3. æ£€æµ‹æ–‡ä»¶ç¼–ç 
    print("\n3. æ£€æµ‹æ–‡ä»¶ç¼–ç ")
    encoding = processor.detect_encoding("demo.txt")
    print(f"   æ£€æµ‹åˆ°çš„ç¼–ç : {encoding}")
    
    # 4. å®‰å…¨å†™å…¥æ–‡ä»¶
    print("\n4. å®‰å…¨å†™å…¥æ–‡ä»¶ï¼ˆå¸¦å¤‡ä»½ï¼‰")
    new_content = demo_content + "\nè¿™æ˜¯æ–°æ·»åŠ çš„å†…å®¹"
    processor.write_with_backup("demo.txt", new_content)
    
    # 5. å‹ç¼©æ–‡ä»¶
    print("\n5. å‹ç¼©æ–‡ä»¶")
    processor.compress_text_file("demo.txt", "demo.txt.gz")
    
    print("\nâœ… æ–‡ä»¶å¤„ç†æ¼”ç¤ºå®Œæˆ")


if __name__ == "__main__":
    demo_file_processing()
```

---

## 13.3 æ•°æ®åºåˆ—åŒ–ä¸æ ¼å¼è½¬æ¢

### ğŸ“ æ ¸å¿ƒæ¦‚å¿µï¼šæ•°æ®çš„"å†·å†»"ä¸"è§£å†»"

æ•°æ®åºåˆ—åŒ–å°±åƒé£Ÿç‰©çš„ä¿å­˜è¿‡ç¨‹ï¼š
- **åºåˆ—åŒ–** = æŠŠæ–°é²œé£Ÿç‰©æ”¾è¿›å†·å†»å®¤ä¿å­˜ï¼ˆå°†æ•°æ®è½¬æ¢ä¸ºå¯å­˜å‚¨çš„æ ¼å¼ï¼‰
- **ååºåˆ—åŒ–** = æŠŠå†·å†»é£Ÿç‰©è§£å†»ä½¿ç”¨ï¼ˆå°†å­˜å‚¨çš„æ•°æ®æ¢å¤ä¸ºç¨‹åºå¯ç”¨çš„å¯¹è±¡ï¼‰
- **ä¸åŒæ ¼å¼** = ä¸åŒçš„ä¿å­˜æ–¹æ³•ï¼ˆå†·å†»ã€è…Œåˆ¶ã€æ™’å¹²ç­‰ï¼‰

### ğŸ“ é€šç”¨æ•°æ®è½¬æ¢ç³»ç»Ÿ

```python
import json
import pickle
import csv
import xml.etree.ElementTree as ET
import configparser
import yaml  # éœ€è¦å®‰è£…: pip install pyyaml
from dataclasses import dataclass, asdict
from typing import Any, Dict, List, Union
from datetime import datetime, date
import sqlite3

@dataclass
class Student:
    """å­¦ç”Ÿä¿¡æ¯ç±» - æ¼”ç¤ºå¯¹è±¡åºåˆ—åŒ–"""
    id: int
    name: str
    age: int
    grades: List[float]
    enrollment_date: str
    
    def __post_init__(self):
        """åˆå§‹åŒ–åå¤„ç†"""
        if isinstance(self.enrollment_date, str):
            self.enrollment_date = datetime.strptime(self.enrollment_date, "%Y-%m-%d")

class UniversalDataConverter:
    """é€šç”¨æ•°æ®è½¬æ¢å™¨ - åƒä¸‡èƒ½ç¿»è¯‘å®˜ä¸€æ ·å¤„ç†å„ç§æ•°æ®æ ¼å¼"""
    
    def __init__(self):
        self.supported_formats = ['json', 'pickle', 'csv', 'xml', 'yaml', 'ini']
        print("ğŸ”„ é€šç”¨æ•°æ®è½¬æ¢å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   æ”¯æŒæ ¼å¼: {', '.join(self.supported_formats)}")
    
    def save_data(self, data: Any, file_path: str, format_type: str = None):
        """ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶ - é€‰æ‹©æœ€é€‚åˆçš„ä¿å­˜æ–¹æ³•
        
        Args:
            data: è¦ä¿å­˜çš„æ•°æ®
            file_path: æ–‡ä»¶è·¯å¾„
            format_type: æ ¼å¼ç±»å‹ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä»æ–‡ä»¶æ‰©å±•åæ¨æ–­
        """
        if format_type is None:
            format_type = self._detect_format_from_path(file_path)
        
        print(f"ğŸ’¾ ä¿å­˜æ•°æ®åˆ° {file_path} (æ ¼å¼: {format_type})")
        
        try:
            if format_type == 'json':
                self._save_json(data, file_path)
            elif format_type == 'pickle':
                self._save_pickle(data, file_path)
            elif format_type == 'csv':
                self._save_csv(data, file_path)
            elif format_type == 'xml':
                self._save_xml(data, file_path)
            elif format_type == 'yaml':
                self._save_yaml(data, file_path)
            elif format_type == 'ini':
                self._save_ini(data, file_path)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ ¼å¼: {format_type}")
            
            print(f"âœ… æ•°æ®ä¿å­˜æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ æ•°æ®ä¿å­˜å¤±è´¥: {e}")
            raise
    
    def load_data(self, file_path: str, format_type: str = None) -> Any:
        """ä»æ–‡ä»¶åŠ è½½æ•°æ® - é€‰æ‹©æ­£ç¡®çš„è§£å†»æ–¹æ³•
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            format_type: æ ¼å¼ç±»å‹ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä»æ–‡ä»¶æ‰©å±•åæ¨æ–­
            
        Returns:
            åŠ è½½çš„æ•°æ®
        """
        if format_type is None:
            format_type = self._detect_format_from_path(file_path)
        
        print(f"ğŸ“‚ ä» {file_path} åŠ è½½æ•°æ® (æ ¼å¼: {format_type})")
        
        try:
            if format_type == 'json':
                data = self._load_json(file_path)
            elif format_type == 'pickle':
                data = self._load_pickle(file_path)
            elif format_type == 'csv':
                data = self._load_csv(file_path)
            elif format_type == 'xml':
                data = self._load_xml(file_path)
            elif format_type == 'yaml':
                data = self._load_yaml(file_path)
            elif format_type == 'ini':
                data = self._load_ini(file_path)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ ¼å¼: {format_type}")
            
            print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ")
            return data
            
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            raise
    
    def convert_format(self, input_path: str, output_path: str, 
                      input_format: str = None, output_format: str = None):
        """æ ¼å¼è½¬æ¢ - åƒç¿»è¯‘å®˜ä¸€æ ·åœ¨ä¸åŒæ ¼å¼é—´è½¬æ¢
        
        Args:
            input_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            input_format: è¾“å…¥æ ¼å¼
            output_format: è¾“å‡ºæ ¼å¼
        """
        print(f"ğŸ”„ æ ¼å¼è½¬æ¢: {input_path} â†’ {output_path}")
        
        # åŠ è½½åŸå§‹æ•°æ®
        data = self.load_data(input_path, input_format)
        
        # ä¿å­˜ä¸ºæ–°æ ¼å¼
        self.save_data(data, output_path, output_format)
        
        print(f"âœ… æ ¼å¼è½¬æ¢å®Œæˆ")
    
    def _detect_format_from_path(self, file_path: str) -> str:
        """ä»æ–‡ä»¶è·¯å¾„æ£€æµ‹æ ¼å¼"""
        extension = Path(file_path).suffix.lower()
        format_map = {
            '.json': 'json',
            '.pkl': 'pickle',
            '.pickle': 'pickle',
            '.csv': 'csv',
            '.xml': 'xml',
            '.yaml': 'yaml',
            '.yml': 'yaml',
            '.ini': 'ini',
            '.cfg': 'ini'
        }
        return format_map.get(extension, 'json')
    
    def _save_json(self, data: Any, file_path: str):
        """ä¿å­˜JSONæ ¼å¼"""
        def json_serializer(obj):
            """JSONåºåˆ—åŒ–å™¨ - å¤„ç†ç‰¹æ®Šå¯¹è±¡"""
            if isinstance(obj, datetime):
                return obj.isoformat()
            elif isinstance(obj, date):
                return obj.isoformat()
            elif hasattr(obj, '__dict__'):
                return asdict(obj) if hasattr(obj, '__dataclass_fields__') else obj.__dict__
            raise TypeError(f"æ— æ³•åºåˆ—åŒ–å¯¹è±¡ç±»å‹: {type(obj)}")
        
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False, default=json_serializer)
    
    def _load_json(self, file_path: str) -> Any:
        """åŠ è½½JSONæ ¼å¼"""
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _save_pickle(self, data: Any, file_path: str):
        """ä¿å­˜Pickleæ ¼å¼"""
        with open(file_path, 'wb') as f:
            pickle.dump(data, f)
    
    def _load_pickle(self, file_path: str) -> Any:
        """åŠ è½½Pickleæ ¼å¼"""
        with open(file_path, 'rb') as f:
            return pickle.load(f)
    
    def _save_csv(self, data: Any, file_path: str):
        """ä¿å­˜CSVæ ¼å¼"""
        if not isinstance(data, list):
            raise ValueError("CSVæ ¼å¼éœ€è¦åˆ—è¡¨ç±»å‹çš„æ•°æ®")
        
        if not data:
            return
        
        # è·å–å­—æ®µå
        if isinstance(data[0], dict):
            fieldnames = data[0].keys()
        elif hasattr(data[0], '__dict__'):
            fieldnames = data[0].__dict__.keys()
        elif hasattr(data[0], '__dataclass_fields__'):
            fieldnames = data[0].__dataclass_fields__.keys()
        else:
            raise ValueError("ä¸æ”¯æŒçš„æ•°æ®ç±»å‹ç”¨äºCSVæ ¼å¼")
        
        with open(file_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            
            for item in data:
                if isinstance(item, dict):
                    writer.writerow(item)
                elif hasattr(item, '__dict__'):
                    if hasattr(item, '__dataclass_fields__'):
                        writer.writerow(asdict(item))
                    else:
                        writer.writerow(item.__dict__)
    
    def _load_csv(self, file_path: str) -> List[Dict]:
        """åŠ è½½CSVæ ¼å¼"""
        data = []
        with open(file_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                data.append(dict(row))
        return data
    
    def _save_yaml(self, data: Any, file_path: str):
        """ä¿å­˜YAMLæ ¼å¼"""
        with open(file_path, 'w', encoding='utf-8') as f:
            yaml.dump(data, f, default_flow_style=False, allow_unicode=True)
    
    def _load_yaml(self, file_path: str) -> Any:
        """åŠ è½½YAMLæ ¼å¼"""
        with open(file_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def _save_xml(self, data: Any, file_path: str):
        """ä¿å­˜XMLæ ¼å¼ï¼ˆç®€å•å®ç°ï¼‰"""
        root = ET.Element("data")
        self._dict_to_xml(data, root)
        
        tree = ET.ElementTree(root)
        tree.write(file_path, encoding='utf-8', xml_declaration=True)
    
    def _dict_to_xml(self, data: Any, parent: ET.Element):
        """å°†å­—å…¸è½¬æ¢ä¸ºXML"""
        if isinstance(data, dict):
            for key, value in data.items():
                element = ET.SubElement(parent, str(key))
                self._dict_to_xml(value, element)
        elif isinstance(data, list):
            for i, item in enumerate(data):
                element = ET.SubElement(parent, f"item_{i}")
                self._dict_to_xml(item, element)
        else:
            parent.text = str(data)
    
    def _load_xml(self, file_path: str) -> Dict:
        """åŠ è½½XMLæ ¼å¼"""
        tree = ET.parse(file_path)
        root = tree.getroot()
        return self._xml_to_dict(root)
    
    def _xml_to_dict(self, element: ET.Element) -> Any:
        """å°†XMLè½¬æ¢ä¸ºå­—å…¸"""
        if len(element) == 0:
            return element.text
        
        result = {}
        for child in element:
            if child.tag.startswith('item_'):
                # å¤„ç†åˆ—è¡¨é¡¹
                if 'list' not in result:
                    result['list'] = []
                result['list'].append(self._xml_to_dict(child))
            else:
                result[child.tag] = self._xml_to_dict(child)
        
        return result
    
    def _save_ini(self, data: Dict, file_path: str):
        """ä¿å­˜INIæ ¼å¼"""
        config = configparser.ConfigParser()
        
        for section_name, section_data in data.items():
            config.add_section(str(section_name))
            for key, value in section_data.items():
                config.set(str(section_name), str(key), str(value))
        
        with open(file_path, 'w', encoding='utf-8') as f:
            config.write(f)
    
    def _load_ini(self, file_path: str) -> Dict:
        """åŠ è½½INIæ ¼å¼"""
        config = configparser.ConfigParser()
        config.read(file_path, encoding='utf-8')
        
        result = {}
        for section_name in config.sections():
            result[section_name] = dict(config.items(section_name))
        
        return result


class ConfigurationManager:
    """é…ç½®ç®¡ç†ç³»ç»Ÿ - åƒç®¡å®¶ä¸€æ ·ç®¡ç†åº”ç”¨çš„å„ç§é…ç½®"""
    
    def __init__(self, config_dir: str = "./config"):
        self.config_dir = Path(config_dir)
        self.config_dir.mkdir(exist_ok=True)
        self.converter = UniversalDataConverter()
        self.configs = {}
        
        print(f"âš™ï¸ é…ç½®ç®¡ç†ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        print(f"   é…ç½®ç›®å½•: {self.config_dir}")
    
    def create_default_config(self, app_name: str) -> Dict:
        """åˆ›å»ºé»˜è®¤é…ç½®"""
        default_config = {
            "app": {
                "name": app_name,
                "version": "1.0.0",
                "debug": False,
                "log_level": "INFO"
            },
            "database": {
                "host": "localhost",
                "port": 5432,
                "name": f"{app_name}_db",
                "user": "admin",
                "password": "changeme"
            },
            "api": {
                "host": "0.0.0.0",
                "port": 8000,
                "timeout": 30,
                "max_connections": 100
            },
            "cache": {
                "enabled": True,
                "ttl": 3600,
                "max_size": 1000
            },
            "logging": {
                "file": f"logs/{app_name}.log",
                "max_size": "10MB",
                "backup_count": 5,
                "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
            }
        }
        
        return default_config
    
    def save_config(self, app_name: str, config: Dict, format_type: str = 'yaml'):
        """ä¿å­˜é…ç½®æ–‡ä»¶"""
        config_path = self.config_dir / f"{app_name}.{format_type}"
        self.converter.save_data(config, str(config_path), format_type)
        self.configs[app_name] = config
        print(f"ğŸ’¾ é…ç½®å·²ä¿å­˜: {config_path}")
    
    def load_config(self, app_name: str, format_type: str = 'yaml') -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        config_path = self.config_dir / f"{app_name}.{format_type}"
        
        if not config_path.exists():
            print(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºé»˜è®¤é…ç½®: {config_path}")
            config = self.create_default_config(app_name)
            self.save_config(app_name, config, format_type)
        else:
            config = self.converter.load_data(str(config_path), format_type)
        
        self.configs[app_name] = config
        return config
    
    def get_config_value(self, app_name: str, key_path: str, default=None):
        """è·å–é…ç½®å€¼ - æ”¯æŒç‚¹å·åˆ†éš”çš„è·¯å¾„
        
        Args:
            app_name: åº”ç”¨åç§°
            key_path: é…ç½®é”®è·¯å¾„ï¼Œå¦‚ 'database.host'
            default: é»˜è®¤å€¼
        """
        if app_name not in self.configs:
            self.load_config(app_name)
        
        config = self.configs[app_name]
        keys = key_path.split('.')
        
        for key in keys:
            if isinstance(config, dict) and key in config:
                config = config[key]
            else:
                return default
        
        return config
    
    def set_config_value(self, app_name: str, key_path: str, value: Any):
        """è®¾ç½®é…ç½®å€¼"""
        if app_name not in self.configs:
            self.load_config(app_name)
        
        config = self.configs[app_name]
        keys = key_path.split('.')
        
        # å¯¼èˆªåˆ°ç›®æ ‡ä½ç½®
        for key in keys[:-1]:
            if key not in config:
                config[key] = {}
            config = config[key]
        
        # è®¾ç½®å€¼
        config[keys[-1]] = value
        
        # ä¿å­˜é…ç½®
        self.save_config(app_name, self.configs[app_name])
        print(f"âš™ï¸ é…ç½®å·²æ›´æ–°: {key_path} = {value}")


# ä½¿ç”¨ç¤ºä¾‹
def demo_data_serialization():
    """æ•°æ®åºåˆ—åŒ–æ¼”ç¤º"""
    print("=== æ•°æ®åºåˆ—åŒ–ä¸æ ¼å¼è½¬æ¢æ¼”ç¤º ===\n")
    
    # åˆ›å»ºæ¼”ç¤ºæ•°æ®
    students = [
        Student(1, "å¼ ä¸‰", 20, [85.5, 92.0, 78.5], "2023-09-01"),
        Student(2, "æå››", 21, [88.0, 85.5, 91.0], "2023-09-01"),
        Student(3, "ç‹äº”", 19, [92.5, 89.0, 94.5], "2023-09-01")
    ]
    
    # åˆ›å»ºè½¬æ¢å™¨
    converter = UniversalDataConverter()
    
    # 1. ä¿å­˜ä¸ºä¸åŒæ ¼å¼
    print("1. ä¿å­˜ä¸ºä¸åŒæ ¼å¼")
    
    # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ä»¥ä¾¿åºåˆ—åŒ–
    students_dict = [asdict(student) for student in students]
    
    formats = ['json', 'yaml', 'csv']
    for fmt in formats:
        file_path = f"students.{fmt}"
        converter.save_data(students_dict, file_path, fmt)
        print(f"   âœ… ä¿å­˜ä¸º {fmt} æ ¼å¼: {file_path}")
    
    print()
    
    # 2. åŠ è½½å¹¶æ¯”è¾ƒæ•°æ®
    print("2. åŠ è½½å¹¶éªŒè¯æ•°æ®")
    for fmt in formats:
        file_path = f"students.{fmt}"
        loaded_data = converter.load_data(file_path, fmt)
        print(f"   ğŸ“‚ ä» {fmt} æ ¼å¼åŠ è½½äº† {len(loaded_data)} æ¡è®°å½•")
    
    print()
    
    # 3. æ ¼å¼è½¬æ¢
    print("3. æ ¼å¼è½¬æ¢æ¼”ç¤º")
    converter.convert_format("students.json", "students_converted.yaml", "json", "yaml")
    print("   âœ… JSON â†’ YAML è½¬æ¢å®Œæˆ")
    
    # 4. é…ç½®ç®¡ç†æ¼”ç¤º
    print("\n4. é…ç½®ç®¡ç†æ¼”ç¤º")
    config_manager = ConfigurationManager()
    
    # åˆ›å»ºåº”ç”¨é…ç½®
    app_config = config_manager.load_config("my_app")
    print(f"   ğŸ“‹ åº”ç”¨é…ç½®åŠ è½½å®Œæˆ")
    
    # è·å–é…ç½®å€¼
    db_host = config_manager.get_config_value("my_app", "database.host")
    print(f"   ğŸ” æ•°æ®åº“ä¸»æœº: {db_host}")
    
    # ä¿®æ”¹é…ç½®å€¼
    config_manager.set_config_value("my_app", "database.port", 3306)
    print(f"   âš™ï¸ æ•°æ®åº“ç«¯å£å·²æ›´æ–°")
    
    print("\nâœ… æ•°æ®åºåˆ—åŒ–æ¼”ç¤ºå®Œæˆ")


if __name__ == "__main__":
    demo_data_serialization()
```

---

## 13.4 æ•°æ®åº“æ“ä½œä¸æŒä¹…åŒ–å­˜å‚¨

### ğŸ“ æ ¸å¿ƒæ¦‚å¿µï¼šé“¶è¡Œé‡‘åº“ç®¡ç†ç³»ç»Ÿ

æ•°æ®åº“å°±åƒé“¶è¡Œçš„é‡‘åº“ç®¡ç†ç³»ç»Ÿï¼š
- **æ•°æ®è¡¨** = ä¸åŒç±»å‹çš„ä¿é™©ç®±ï¼ˆå‚¨è“„ç®±ã€è´µé‡ç‰©å“ç®±ç­‰ï¼‰
- **è®°å½•** = ä¿é™©ç®±ä¸­çš„æ¯ä¸€ä¸ªç‰©å“
- **å­—æ®µ** = ç‰©å“çš„å„ç§å±æ€§ï¼ˆä»·å€¼ã€å­˜æ”¾æ—¶é—´ã€æ‰€æœ‰è€…ç­‰ï¼‰
- **äº‹åŠ¡** = å®Œæ•´çš„å­˜å–æ“ä½œï¼ˆè¦ä¹ˆå…¨éƒ¨æˆåŠŸï¼Œè¦ä¹ˆå…¨éƒ¨å¤±è´¥ï¼‰

### ğŸ“ ä¼ä¸šçº§æ•°æ®åº“ç®¡ç†ç³»ç»Ÿ

```python
import sqlite3
from contextlib import contextmanager
from dataclasses import dataclass
from typing import List, Optional, Any, Dict, Tuple
from datetime import datetime
import json

@dataclass
class Transaction:
    """äº¤æ˜“è®°å½•ç±»"""
    id: Optional[int] = None
    user_id: int = 0
    amount: float = 0.0
    transaction_type: str = ""  # income, expense
    category: str = ""
    description: str = ""
    date: str = ""
    
    def __post_init__(self):
        if not self.date:
            self.date = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

class DatabaseManager:
    """æ•°æ®åº“ç®¡ç†å™¨ - åƒé“¶è¡Œé‡‘åº“ç®¡ç†å‘˜ä¸€æ ·ç®¡ç†æ•°æ®"""
    
    def __init__(self, db_path: str = "finance.db"):
        self.db_path = db_path
        self.init_database()
        print(f"ğŸ¦ æ•°æ®åº“ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ: {db_path}")
    
    @contextmanager
    def get_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥ - å®‰å…¨çš„è¿æ¥ç®¡ç†"""
        conn = None
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row  # å¯ç”¨å­—å…¸å¼è®¿é—®
            yield conn
        except sqlite3.Error as e:
            if conn:
                conn.rollback()
            print(f"âŒ æ•°æ®åº“æ“ä½œå¤±è´¥: {e}")
            raise
        finally:
            if conn:
                conn.close()
    
    def init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„"""
        with self.get_connection() as conn:
            # åˆ›å»ºç”¨æˆ·è¡¨
            conn.execute('''
                CREATE TABLE IF NOT EXISTS users (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    username TEXT UNIQUE NOT NULL,
                    email TEXT UNIQUE NOT NULL,
                    password_hash TEXT NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # åˆ›å»ºäº¤æ˜“è¡¨
            conn.execute('''
                CREATE TABLE IF NOT EXISTS transactions (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id INTEGER NOT NULL,
                    amount REAL NOT NULL,
                    transaction_type TEXT NOT NULL CHECK (transaction_type IN ('income', 'expense')),
                    category TEXT NOT NULL,
                    description TEXT,
                    date TIMESTAMP NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (user_id) REFERENCES users (id)
                )
            ''')
            
            # åˆ›å»ºåˆ†ç±»è¡¨
            conn.execute('''
                CREATE TABLE IF NOT EXISTS categories (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    name TEXT UNIQUE NOT NULL,
                    type TEXT NOT NULL CHECK (type IN ('income', 'expense')),
                    description TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # åˆ›å»ºé¢„ç®—è¡¨
            conn.execute('''
                CREATE TABLE IF NOT EXISTS budgets (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    user_id INTEGER NOT NULL,
                    category TEXT NOT NULL,
                    amount REAL NOT NULL,
                    period TEXT NOT NULL CHECK (period IN ('monthly', 'yearly')),
                    start_date DATE NOT NULL,
                    end_date DATE NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (user_id) REFERENCES users (id)
                )
            ''')
            
            conn.commit()
            print("âœ… æ•°æ®åº“è¡¨ç»“æ„åˆå§‹åŒ–å®Œæˆ")
    
    def create_user(self, username: str, email: str, password_hash: str) -> int:
        """åˆ›å»ºç”¨æˆ· - åœ¨é“¶è¡Œå¼€æˆ·"""
        with self.get_connection() as conn:
            cursor = conn.execute(
                'INSERT INTO users (username, email, password_hash) VALUES (?, ?, ?)',
                (username, email, password_hash)
            )
            conn.commit()
            user_id = cursor.lastrowid
            print(f"ğŸ‘¤ ç”¨æˆ·åˆ›å»ºæˆåŠŸ: {username} (ID: {user_id})")
            return user_id
    
    def get_user(self, user_id: int) -> Optional[Dict]:
        """è·å–ç”¨æˆ·ä¿¡æ¯"""
        with self.get_connection() as conn:
            cursor = conn.execute('SELECT * FROM users WHERE id = ?', (user_id,))
            row = cursor.fetchone()
            return dict(row) if row else None
    
    def add_transaction(self, transaction: Transaction) -> int:
        """æ·»åŠ äº¤æ˜“è®°å½• - åœ¨é‡‘åº“ä¸­å­˜æ”¾æ–°ç‰©å“"""
        with self.get_connection() as conn:
            cursor = conn.execute('''
                INSERT INTO transactions 
                (user_id, amount, transaction_type, category, description, date)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                transaction.user_id,
                transaction.amount,
                transaction.transaction_type,
                transaction.category,
                transaction.description,
                transaction.date
            ))
            conn.commit()
            transaction_id = cursor.lastrowid
            print(f"ğŸ’° äº¤æ˜“è®°å½•æ·»åŠ æˆåŠŸ (ID: {transaction_id})")
            return transaction_id
    
    def get_transactions(self, user_id: int, limit: int = 100) -> List[Dict]:
        """è·å–äº¤æ˜“è®°å½•"""
        with self.get_connection() as conn:
            cursor = conn.execute('''
                SELECT * FROM transactions 
                WHERE user_id = ? 
                ORDER BY date DESC 
                LIMIT ?
            ''', (user_id, limit))
            return [dict(row) for row in cursor.fetchall()]
    
    def get_balance(self, user_id: int) -> Dict[str, float]:
        """è·å–è´¦æˆ·ä½™é¢ - æŸ¥çœ‹é‡‘åº“æ€»ä»·å€¼"""
        with self.get_connection() as conn:
            # è®¡ç®—æ”¶å…¥æ€»é¢
            cursor = conn.execute('''
                SELECT COALESCE(SUM(amount), 0) as total_income 
                FROM transactions 
                WHERE user_id = ? AND transaction_type = 'income'
            ''', (user_id,))
            total_income = cursor.fetchone()['total_income']
            
            # è®¡ç®—æ”¯å‡ºæ€»é¢
            cursor = conn.execute('''
                SELECT COALESCE(SUM(amount), 0) as total_expense 
                FROM transactions 
                WHERE user_id = ? AND transaction_type = 'expense'
            ''', (user_id,))
            total_expense = cursor.fetchone()['total_expense']
            
            balance = total_income - total_expense
            
            return {
                'total_income': total_income,
                'total_expense': total_expense,
                'balance': balance
            }
    
    def get_category_summary(self, user_id: int, days: int = 30) -> List[Dict]:
        """è·å–åˆ†ç±»æ±‡æ€» - æŒ‰ç±»åˆ«ç»Ÿè®¡é‡‘åº“ç‰©å“"""
        with self.get_connection() as conn:
            cursor = conn.execute('''
                SELECT 
                    category,
                    transaction_type,
                    COUNT(*) as transaction_count,
                    SUM(amount) as total_amount,
                    AVG(amount) as avg_amount
                FROM transactions 
                WHERE user_id = ? 
                    AND date >= datetime('now', '-{} days')
                GROUP BY category, transaction_type
                ORDER BY total_amount DESC
            '''.format(days), (user_id,))
            
            return [dict(row) for row in cursor.fetchall()]
    
    def create_budget(self, user_id: int, category: str, amount: float, 
                     period: str = 'monthly') -> int:
        """åˆ›å»ºé¢„ç®— - è®¾ç½®æ”¯å‡ºé™é¢"""
        start_date = datetime.now().strftime('%Y-%m-%d')
        
        if period == 'monthly':
            # è®¡ç®—æœˆæœ«æ—¥æœŸ
            end_date = datetime.now().replace(day=28).strftime('%Y-%m-%d')
        else:  # yearly
            end_date = datetime.now().replace(month=12, day=31).strftime('%Y-%m-%d')
        
        with self.get_connection() as conn:
            cursor = conn.execute('''
                INSERT INTO budgets (user_id, category, amount, period, start_date, end_date)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (user_id, category, amount, period, start_date, end_date))
            
            conn.commit()
            budget_id = cursor.lastrowid
            print(f"ğŸ“Š é¢„ç®—åˆ›å»ºæˆåŠŸ: {category} - {amount} ({period})")
            return budget_id
    
    def check_budget_status(self, user_id: int) -> List[Dict]:
        """æ£€æŸ¥é¢„ç®—çŠ¶æ€ - ç›‘æ§æ”¯å‡ºæ˜¯å¦è¶…é™"""
        with self.get_connection() as conn:
            cursor = conn.execute('''
                SELECT 
                    b.id,
                    b.category,
                    b.amount as budget_amount,
                    b.period,
                    COALESCE(SUM(t.amount), 0) as spent_amount,
                    (b.amount - COALESCE(SUM(t.amount), 0)) as remaining_amount,
                    CASE 
                        WHEN COALESCE(SUM(t.amount), 0) > b.amount THEN 'OVER'
                        WHEN COALESCE(SUM(t.amount), 0) > b.amount * 0.8 THEN 'WARNING'
                        ELSE 'OK'
                    END as status
                FROM budgets b
                LEFT JOIN transactions t ON (
                    t.user_id = b.user_id 
                    AND t.category = b.category 
                    AND t.transaction_type = 'expense'
                    AND t.date >= b.start_date 
                    AND t.date <= b.end_date
                )
                WHERE b.user_id = ?
                GROUP BY b.id, b.category, b.amount, b.period
            ''', (user_id,))
            
            return [dict(row) for row in cursor.fetchall()]
    
    def backup_database(self, backup_path: str):
        """å¤‡ä»½æ•°æ®åº“ - åˆ¶ä½œé‡‘åº“æ¸…å•å‰¯æœ¬"""
        with self.get_connection() as conn:
            with open(backup_path, 'w', encoding='utf-8') as f:
                for line in conn.iterdump():
                    f.write('%s\n' % line)
        print(f"ğŸ’¾ æ•°æ®åº“å¤‡ä»½å®Œæˆ: {backup_path}")
    
    def get_statistics(self, user_id: int) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯ - ç”Ÿæˆé‡‘åº“ç®¡ç†æŠ¥å‘Š"""
        balance_info = self.get_balance(user_id)
        category_summary = self.get_category_summary(user_id)
        budget_status = self.check_budget_status(user_id)
        
        with self.get_connection() as conn:
            # è·å–äº¤æ˜“æ•°é‡
            cursor = conn.execute(
                'SELECT COUNT(*) as total_transactions FROM transactions WHERE user_id = ?',
                (user_id,)
            )
            total_transactions = cursor.fetchone()['total_transactions']
            
            # è·å–æœ€è¿‘äº¤æ˜“
            cursor = conn.execute('''
                SELECT * FROM transactions 
                WHERE user_id = ? 
                ORDER BY date DESC 
                LIMIT 5
            ''', (user_id,))
            recent_transactions = [dict(row) for row in cursor.fetchall()]
        
        return {
            'balance': balance_info,
            'total_transactions': total_transactions,
            'category_summary': category_summary,
            'budget_status': budget_status,
            'recent_transactions': recent_transactions,
            'generated_at': datetime.now().isoformat()
        }


class PersonalFinanceApp:
    """ä¸ªäººè´¢åŠ¡ç®¡ç†åº”ç”¨ - å®Œæ•´çš„é‡‘åº“ç®¡ç†ç³»ç»Ÿ"""
    
    def __init__(self, db_path: str = "personal_finance.db"):
        self.db = DatabaseManager(db_path)
        self.current_user_id = None
        print("ğŸ’¼ ä¸ªäººè´¢åŠ¡ç®¡ç†åº”ç”¨å¯åŠ¨å®Œæˆ")
    
    def register_user(self, username: str, email: str, password: str) -> bool:
        """ç”¨æˆ·æ³¨å†Œ"""
        try:
            # ç®€å•çš„å¯†ç å“ˆå¸Œï¼ˆå®é™…åº”ç”¨ä¸­åº”ä½¿ç”¨æ›´å®‰å…¨çš„æ–¹æ³•ï¼‰
            password_hash = hashlib.sha256(password.encode()).hexdigest()
            user_id = self.db.create_user(username, email, password_hash)
            
            # åˆå§‹åŒ–é»˜è®¤åˆ†ç±»
            self._init_default_categories()
            
            return True
        except Exception as e:
            print(f"âŒ ç”¨æˆ·æ³¨å†Œå¤±è´¥: {e}")
            return False
    
    def login(self, username: str, password: str) -> bool:
        """ç”¨æˆ·ç™»å½•"""
        password_hash = hashlib.sha256(password.encode()).hexdigest()
        
        with self.db.get_connection() as conn:
            cursor = conn.execute(
                'SELECT id FROM users WHERE username = ? AND password_hash = ?',
                (username, password_hash)
            )
            user = cursor.fetchone()
            
            if user:
                self.current_user_id = user['id']
                print(f"âœ… ç™»å½•æˆåŠŸ: {username}")
                return True
            else:
                print("âŒ ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯")
                return False
    
    def add_income(self, amount: float, category: str, description: str = ""):
        """æ·»åŠ æ”¶å…¥"""
        if not self.current_user_id:
            print("âŒ è¯·å…ˆç™»å½•")
            return
        
        transaction = Transaction(
            user_id=self.current_user_id,
            amount=amount,
            transaction_type='income',
            category=category,
            description=description
        )
        
        self.db.add_transaction(transaction)
        print(f"ğŸ’° æ”¶å…¥è®°å½•æ·»åŠ æˆåŠŸ: +{amount} ({category})")
    
    def add_expense(self, amount: float, category: str, description: str = ""):
        """æ·»åŠ æ”¯å‡º"""
        if not self.current_user_id:
            print("âŒ è¯·å…ˆç™»å½•")
            return
        
        transaction = Transaction(
            user_id=self.current_user_id,
            amount=amount,
            transaction_type='expense',
            category=category,
            description=description
        )
        
        self.db.add_transaction(transaction)
        print(f"ğŸ’¸ æ”¯å‡ºè®°å½•æ·»åŠ æˆåŠŸ: -{amount} ({category})")
    
    def show_balance(self):
        """æ˜¾ç¤ºè´¦æˆ·ä½™é¢"""
        if not self.current_user_id:
            print("âŒ è¯·å…ˆç™»å½•")
            return
        
        balance_info = self.db.get_balance(self.current_user_id)
        
        print("\nğŸ’° è´¦æˆ·ä½™é¢ä¿¡æ¯:")
        print(f"   æ€»æ”¶å…¥: Â¥{balance_info['total_income']:,.2f}")
        print(f"   æ€»æ”¯å‡º: Â¥{balance_info['total_expense']:,.2f}")
        print(f"   å½“å‰ä½™é¢: Â¥{balance_info['balance']:,.2f}")
    
    def show_category_summary(self, days: int = 30):
        """æ˜¾ç¤ºåˆ†ç±»æ±‡æ€»"""
        if not self.current_user_id:
            print("âŒ è¯·å…ˆç™»å½•")
            return
        
        summary = self.db.get_category_summary(self.current_user_id, days)
        
        print(f"\nğŸ“Š æœ€è¿‘{days}å¤©åˆ†ç±»æ±‡æ€»:")
        for item in summary:
            type_symbol = "ğŸ’°" if item['transaction_type'] == 'income' else "ğŸ’¸"
            print(f"   {type_symbol} {item['category']}: Â¥{item['total_amount']:,.2f} "
                  f"({item['transaction_count']}ç¬”)")
    
    def create_monthly_budget(self, category: str, amount: float):
        """åˆ›å»ºæœˆåº¦é¢„ç®—"""
        if not self.current_user_id:
            print("âŒ è¯·å…ˆç™»å½•")
            return
        
        self.db.create_budget(self.current_user_id, category, amount, 'monthly')
    
    def check_budgets(self):
        """æ£€æŸ¥é¢„ç®—çŠ¶æ€"""
        if not self.current_user_id:
            print("âŒ è¯·å…ˆç™»å½•")
            return
        
        budget_status = self.db.check_budget_status(self.current_user_id)
        
        print("\nğŸ“Š é¢„ç®—çŠ¶æ€:")
        for budget in budget_status:
            status_symbol = {
                'OK': 'âœ…',
                'WARNING': 'âš ï¸',
                'OVER': 'âŒ'
            }.get(budget['status'], 'â“')
            
            print(f"   {status_symbol} {budget['category']}: "
                  f"Â¥{budget['spent_amount']:,.2f} / Â¥{budget['budget_amount']:,.2f} "
                  f"(å‰©ä½™: Â¥{budget['remaining_amount']:,.2f})")
    
    def generate_report(self) -> str:
        """ç”Ÿæˆè´¢åŠ¡æŠ¥å‘Š"""
        if not self.current_user_id:
            print("âŒ è¯·å…ˆç™»å½•")
            return ""
        
        stats = self.db.get_statistics(self.current_user_id)
        
        report = f"""# ä¸ªäººè´¢åŠ¡æŠ¥å‘Š

## ğŸ“Š è´¦æˆ·æ¦‚è§ˆ
- **æ€»æ”¶å…¥**: Â¥{stats['balance']['total_income']:,.2f}
- **æ€»æ”¯å‡º**: Â¥{stats['balance']['total_expense']:,.2f}
- **å½“å‰ä½™é¢**: Â¥{stats['balance']['balance']:,.2f}
- **äº¤æ˜“æ€»æ•°**: {stats['total_transactions']}

## ğŸ’° åˆ†ç±»æ±‡æ€»
"""
        
        for item in stats['category_summary']:
            type_name = "æ”¶å…¥" if item['transaction_type'] == 'income' else "æ”¯å‡º"
            report += f"- **{item['category']}** ({type_name}): Â¥{item['total_amount']:,.2f}\n"
        
        report += "\n## ğŸ“Š é¢„ç®—çŠ¶æ€\n"
        for budget in stats['budget_status']:
            status_text = {
                'OK': 'æ­£å¸¸',
                'WARNING': 'è­¦å‘Š',
                'OVER': 'è¶…æ”¯'
            }.get(budget['status'], 'æœªçŸ¥')
            
            report += f"- **{budget['category']}**: {status_text} "
            report += f"(Â¥{budget['spent_amount']:,.2f} / Â¥{budget['budget_amount']:,.2f})\n"
        
        report += f"\n---\n*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {stats['generated_at']}*\n"
        
        return report
    
    def _init_default_categories(self):
        """åˆå§‹åŒ–é»˜è®¤åˆ†ç±»"""
        default_categories = [
            ('å·¥èµ„', 'income'),
            ('å¥–é‡‘', 'income'),
            ('æŠ•èµ„æ”¶ç›Š', 'income'),
            ('é¤é¥®', 'expense'),
            ('äº¤é€š', 'expense'),
            ('è´­ç‰©', 'expense'),
            ('å¨±ä¹', 'expense'),
            ('åŒ»ç–—', 'expense'),
            ('æ•™è‚²', 'expense'),
            ('ä½æˆ¿', 'expense')
        ]
        
        with self.db.get_connection() as conn:
            for name, category_type in default_categories:
                try:
                    conn.execute(
                        'INSERT OR IGNORE INTO categories (name, type) VALUES (?, ?)',
                        (name, category_type)
                    )
                except sqlite3.Error:
                    pass  # å¿½ç•¥é‡å¤æ’å…¥é”™è¯¯
            conn.commit()


# ä½¿ç”¨ç¤ºä¾‹
def demo_database_operations():
    """æ•°æ®åº“æ“ä½œæ¼”ç¤º"""
    print("=== ä¸ªäººè´¢åŠ¡ç®¡ç†ç³»ç»Ÿæ¼”ç¤º ===\n")
    
    # åˆ›å»ºåº”ç”¨å®ä¾‹
    app = PersonalFinanceApp("demo_finance.db")
    
    # 1. ç”¨æˆ·æ³¨å†Œå’Œç™»å½•
    print("1. ç”¨æˆ·æ³¨å†Œå’Œç™»å½•")
    app.register_user("å¼ ä¸‰", "zhangsan@example.com", "password123")
    app.login("å¼ ä¸‰", "password123")
    print()
    
    # 2. æ·»åŠ æ”¶å…¥è®°å½•
    print("2. æ·»åŠ æ”¶å…¥è®°å½•")
    app.add_income(8000, "å·¥èµ„", "2024å¹´1æœˆå·¥èµ„")
    app.add_income(1000, "å¥–é‡‘", "é¡¹ç›®å¥–é‡‘")
    print()
    
    # 3. æ·»åŠ æ”¯å‡ºè®°å½•
    print("3. æ·»åŠ æ”¯å‡ºè®°å½•")
    app.add_expense(1200, "é¤é¥®", "æ—¥å¸¸ç”¨é¤")
    app.add_expense(800, "äº¤é€š", "åœ°é“å…¬äº¤è´¹ç”¨")
    app.add_expense(2000, "è´­ç‰©", "æ—¥ç”¨å“é‡‡è´­")
    print()
    
    # 4. æŸ¥çœ‹ä½™é¢
    print("4. æŸ¥çœ‹è´¦æˆ·ä½™é¢")
    app.show_balance()
    print()
    
    # 5. æŸ¥çœ‹åˆ†ç±»æ±‡æ€»
    print("5. æŸ¥çœ‹åˆ†ç±»æ±‡æ€»")
    app.show_category_summary()
    print()
    
    # 6. åˆ›å»ºé¢„ç®—
    print("6. åˆ›å»ºæœˆåº¦é¢„ç®—")
    app.create_monthly_budget("é¤é¥®", 1500)
    app.create_monthly_budget("äº¤é€š", 1000)
    print()
    
    # 7. æ£€æŸ¥é¢„ç®—çŠ¶æ€
    print("7. æ£€æŸ¥é¢„ç®—çŠ¶æ€")
    app.check_budgets()
    print()
    
    # 8. ç”ŸæˆæŠ¥å‘Š
    print("8. ç”Ÿæˆè´¢åŠ¡æŠ¥å‘Š")
    report = app.generate_report()
    
    # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
    with open("finance_report.md", "w", encoding="utf-8") as f:
        f.write(report)
    print("ğŸ“„ è´¢åŠ¡æŠ¥å‘Šå·²ä¿å­˜åˆ° finance_report.md")
    
    # 9. æ•°æ®åº“å¤‡ä»½
    print("\n9. æ•°æ®åº“å¤‡ä»½")
    app.db.backup_database("finance_backup.sql")
    
    print("\nâœ… æ•°æ®åº“æ“ä½œæ¼”ç¤ºå®Œæˆ")


if __name__ == "__main__":
    demo_database_operations()
```

---

## ğŸ‹ï¸â€â™€ï¸ å®è·µç»ƒä¹ 

### ğŸ“ åŸºç¡€ç»ƒä¹ ï¼ˆLevel 1-2ï¼‰

#### ç»ƒä¹ 1ï¼šæ–‡ä»¶ä¿¡æ¯ç»Ÿè®¡å™¨
åˆ›å»ºä¸€ä¸ªç¨‹åºï¼Œç»Ÿè®¡æŒ‡å®šç›®å½•ä¸‹æ‰€æœ‰æ–‡ä»¶çš„ä¿¡æ¯ï¼š
- æ–‡ä»¶æ€»æ•°å’Œç›®å½•æ€»æ•°
- å„ç§æ–‡ä»¶ç±»å‹çš„æ•°é‡
- æ€»å ç”¨ç©ºé—´
- æœ€å¤§å’Œæœ€å°çš„æ–‡ä»¶

```python
# å‚è€ƒå®ç°æ€è·¯
def analyze_directory(path):
    """åˆ†æç›®å½•ç»Ÿè®¡ä¿¡æ¯"""
    # 1. éå†ç›®å½•
    # 2. ç»Ÿè®¡æ–‡ä»¶ç±»å‹å’Œå¤§å°
    # 3. ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
    pass
```

#### ç»ƒä¹ 2ï¼šæ–‡æœ¬æ–‡ä»¶åˆå¹¶å·¥å…·
ç¼–å†™ç¨‹åºå°†å¤šä¸ªæ–‡æœ¬æ–‡ä»¶åˆå¹¶ä¸ºä¸€ä¸ªæ–‡ä»¶ï¼š
- æ”¯æŒæŒ‡å®šæ–‡ä»¶é¡ºåº
- åœ¨åˆå¹¶æ—¶æ·»åŠ æ–‡ä»¶åˆ†éš”æ ‡è¯†
- å¤„ç†ä¸åŒç¼–ç çš„æ–‡ä»¶

#### ç»ƒä¹ 3ï¼šCSVæ•°æ®å¤„ç†å™¨
åˆ›å»ºä¸€ä¸ªCSVæ•°æ®å¤„ç†å·¥å…·ï¼š
- è¯»å–CSVæ–‡ä»¶å¹¶æ˜¾ç¤ºåŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
- æ”¯æŒæ•°æ®ç­›é€‰å’Œæ’åº
- å°†å¤„ç†ç»“æœä¿å­˜ä¸ºæ–°çš„CSVæ–‡ä»¶

### ğŸš€ è¿›é˜¶ç»ƒä¹ ï¼ˆLevel 3-4ï¼‰

#### ç»ƒä¹ 4ï¼šæ™ºèƒ½å¤‡ä»½ç³»ç»Ÿ
è®¾è®¡ä¸€ä¸ªæ™ºèƒ½å¤‡ä»½ç³»ç»Ÿï¼š
- æ”¯æŒå¢é‡å¤‡ä»½ï¼ˆåªå¤‡ä»½ä¿®æ”¹è¿‡çš„æ–‡ä»¶ï¼‰
- å‹ç¼©å¤‡ä»½æ–‡ä»¶ä»¥èŠ‚çœç©ºé—´
- ç”Ÿæˆå¤‡ä»½æŠ¥å‘Šå’Œæ¢å¤è„šæœ¬

#### ç»ƒä¹ 5ï¼šå¤šæ ¼å¼æ•°æ®è½¬æ¢å™¨
æ‰©å±•UniversalDataConverterç±»ï¼š
- æ·»åŠ å¯¹Excelæ–‡ä»¶çš„æ”¯æŒ
- å®ç°æ•°æ®éªŒè¯åŠŸèƒ½
- æ”¯æŒæ‰¹é‡è½¬æ¢å¤šä¸ªæ–‡ä»¶

#### ç»ƒä¹ 6ï¼šä¸ªäººçŸ¥è¯†åº“ç³»ç»Ÿ
åŸºäºSQLiteåˆ›å»ºä¸ªäººçŸ¥è¯†åº“ï¼š
- æ”¯æŒæ–‡ç« çš„åˆ†ç±»å’Œæ ‡ç­¾
- å®ç°å…¨æ–‡æœç´¢åŠŸèƒ½
- æä¾›æ•°æ®å¯¼å…¥å¯¼å‡ºåŠŸèƒ½

### ğŸ¯ æŒ‘æˆ˜ç»ƒä¹ ï¼ˆLevel 5ï¼‰

#### ç»ƒä¹ 7ï¼šåˆ†å¸ƒå¼æ–‡ä»¶åŒæ­¥å·¥å…·
åˆ›å»ºä¸€ä¸ªæ–‡ä»¶åŒæ­¥å·¥å…·ï¼š
- ç›‘æ§æ–‡ä»¶å¤¹å˜åŒ–
- æ”¯æŒå¤šè®¾å¤‡é—´åŒæ­¥
- å¤„ç†æ–‡ä»¶å†²çªå’Œç‰ˆæœ¬æ§åˆ¶

#### ç»ƒä¹ 8ï¼šæ•°æ®åº“è¿ç§»å·¥å…·
å¼€å‘æ•°æ®åº“è¿ç§»å·¥å…·ï¼š
- æ”¯æŒä¸åŒæ•°æ®åº“é—´çš„æ•°æ®è¿ç§»
- è‡ªåŠ¨å¤„ç†æ•°æ®ç±»å‹è½¬æ¢
- æä¾›è¿ç§»è¿›åº¦å’Œé”™è¯¯æŠ¥å‘Š

---

## ğŸ“š æœ¬ç« æ€»ç»“

### ğŸ¯ æ ¸å¿ƒçŸ¥è¯†å›é¡¾

é€šè¿‡æœ¬ç« å­¦ä¹ ï¼Œæˆ‘ä»¬æŒæ¡äº†Pythonä¸­æ•°æ®æŒä¹…åŒ–çš„å®Œæ•´æŠ€èƒ½ä½“ç³»ï¼š

#### 1. æ–‡ä»¶ç³»ç»Ÿæ“ä½œ (â­â­â­â­â­)
- **pathlibæ¨¡å—**: ç°ä»£åŒ–çš„è·¯å¾„æ“ä½œæ–¹å¼
- **æ–‡ä»¶å±æ€§ç®¡ç†**: è·å–å’Œä¿®æ”¹æ–‡ä»¶çš„å„ç§å±æ€§
- **ç›®å½•æ“ä½œ**: åˆ›å»ºã€åˆ é™¤ã€éå†ç›®å½•ç»“æ„
- **æ–‡ä»¶æœç´¢**: ä½¿ç”¨globæ¨¡å¼è¿›è¡Œé«˜æ•ˆæ–‡ä»¶æŸ¥æ‰¾

#### 2. æ–‡ä»¶è¯»å†™å¤„ç† (â­â­â­â­â­)
- **ç¼–ç å¤„ç†**: æ­£ç¡®å¤„ç†UTF-8ã€GBKç­‰ä¸åŒç¼–ç 
- **æ€§èƒ½ä¼˜åŒ–**: ä½¿ç”¨ç¼“å†²å’Œæµå¼å¤„ç†å¤§æ–‡ä»¶
- **å®‰å…¨æ“ä½œ**: ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¡®ä¿èµ„æºé‡Šæ”¾
- **é”™è¯¯å¤„ç†**: ä¼˜é›…å¤„ç†æ–‡ä»¶æ“ä½œä¸­çš„å„ç§å¼‚å¸¸

#### 3. æ•°æ®åºåˆ—åŒ– (â­â­â­â­â­)
- **JSONæ ¼å¼**: è½»é‡çº§ã€è·¨è¯­è¨€çš„æ•°æ®äº¤æ¢æ ¼å¼
- **Pickleåºåˆ—åŒ–**: Pythonå¯¹è±¡çš„å®Œæ•´çŠ¶æ€ä¿å­˜
- **CSVå¤„ç†**: ç»“æ„åŒ–è¡¨æ ¼æ•°æ®çš„æ ‡å‡†æ ¼å¼
- **é…ç½®ç®¡ç†**: YAMLã€INIç­‰é…ç½®æ–‡ä»¶çš„å¤„ç†

#### 4. æ•°æ®åº“æ“ä½œ (â­â­â­â­â­)
- **SQLiteæ•°æ®åº“**: è½»é‡çº§åµŒå…¥å¼æ•°æ®åº“çš„ä½¿ç”¨
- **SQLè¯­å¥**: æ•°æ®æŸ¥è¯¢ã€æ’å…¥ã€æ›´æ–°ã€åˆ é™¤æ“ä½œ
- **äº‹åŠ¡å¤„ç†**: ç¡®ä¿æ•°æ®ä¸€è‡´æ€§å’Œå®Œæ•´æ€§
- **è¿æ¥ç®¡ç†**: å®‰å…¨é«˜æ•ˆçš„æ•°æ®åº“è¿æ¥å¤„ç†

### ğŸ† æŠ€èƒ½ç­‰çº§è¯„ä¼°

å®Œæˆæœ¬ç« å­¦ä¹ åï¼Œä½ çš„æŠ€èƒ½æ°´å¹³ï¼š

| æŠ€èƒ½é¢†åŸŸ | åˆçº§ | ä¸­çº§ | é«˜çº§ | ä¸“å®¶ |
|---------|------|------|------|------|
| æ–‡ä»¶æ“ä½œ | âœ… | âœ… | âœ… | ğŸ¯ |
| æ•°æ®åºåˆ—åŒ– | âœ… | âœ… | âœ… | ğŸ¯ |
| æ•°æ®åº“æ“ä½œ | âœ… | âœ… | ğŸ¯ | â³ |
| æ€§èƒ½ä¼˜åŒ– | âœ… | ğŸ¯ | â³ | â³ |
| ç³»ç»Ÿè®¾è®¡ | âœ… | ğŸ¯ | â³ | â³ |

**å›¾ä¾‹**: âœ… å·²æŒæ¡ | ğŸ¯ å½“å‰æ°´å¹³ | â³ å¾…æå‡

### ğŸ’¡ æœ€ä½³å®è·µæ€»ç»“

#### ğŸ”’ å®‰å…¨æ€§åŸåˆ™
1. **å§‹ç»ˆä½¿ç”¨withè¯­å¥**: ç¡®ä¿æ–‡ä»¶èµ„æºæ­£ç¡®é‡Šæ”¾
2. **éªŒè¯æ–‡ä»¶è·¯å¾„**: é˜²æ­¢è·¯å¾„éå†æ”»å‡»
3. **å¤„ç†æƒé™é—®é¢˜**: ä¼˜é›…å¤„ç†æ–‡ä»¶è®¿é—®æƒé™é”™è¯¯
4. **å¤‡ä»½é‡è¦æ•°æ®**: åœ¨ä¿®æ”¹å‰åˆ›å»ºå¤‡ä»½

#### âš¡ æ€§èƒ½ä¼˜åŒ–æŠ€å·§
1. **é€‰æ‹©åˆé€‚çš„è¯»å†™æ¨¡å¼**: æ–‡æœ¬vsäºŒè¿›åˆ¶ï¼Œç¼“å†²vséç¼“å†²
2. **æµå¼å¤„ç†å¤§æ–‡ä»¶**: é¿å…å°†æ•´ä¸ªæ–‡ä»¶åŠ è½½åˆ°å†…å­˜
3. **ä½¿ç”¨è¿æ¥æ± **: æ•°æ®åº“æ“ä½œä¸­å¤ç”¨è¿æ¥
4. **æ‰¹é‡æ“ä½œ**: å‡å°‘æ•°æ®åº“äº‹åŠ¡æ¬¡æ•°

#### ğŸ¯ æ ¼å¼é€‰æ‹©æŒ‡å—
- **JSON**: é…ç½®æ–‡ä»¶ã€APIæ•°æ®äº¤æ¢ã€è½»é‡çº§å­˜å‚¨
- **Pickle**: Pythonå¯¹è±¡å®Œæ•´ä¿å­˜ã€ä¸´æ—¶æ•°æ®ç¼“å­˜
- **CSV**: è¡¨æ ¼æ•°æ®ã€Excelå…¼å®¹ã€æ•°æ®åˆ†æ
- **SQLite**: ç»“æ„åŒ–æ•°æ®ã€å¤æ‚æŸ¥è¯¢ã€å¤šç”¨æˆ·è®¿é—®

### ğŸ”® è¿›é˜¶å­¦ä¹ æ–¹å‘

#### ğŸ“Š æ•°æ®ç§‘å­¦æ–¹å‘
- **Pandas**: å¤§è§„æ¨¡æ•°æ®åˆ†æå’Œå¤„ç†
- **NumPy**: æ•°å€¼è®¡ç®—å’Œç§‘å­¦è®¡ç®—
- **HDF5**: å¤§è§„æ¨¡ç§‘å­¦æ•°æ®å­˜å‚¨
- **Parquet**: åˆ—å¼å­˜å‚¨æ ¼å¼

#### ğŸŒ Webå¼€å‘æ–¹å‘
- **Redis**: å†…å­˜æ•°æ®åº“å’Œç¼“å­˜
- **MongoDB**: NoSQLæ–‡æ¡£æ•°æ®åº“
- **PostgreSQL**: ä¼ä¸šçº§å…³ç³»æ•°æ®åº“
- **Elasticsearch**: å…¨æ–‡æœç´¢å¼•æ“

#### ğŸ—ï¸ ç³»ç»Ÿæ¶æ„æ–¹å‘
- **åˆ†å¸ƒå¼å­˜å‚¨**: HDFSã€Cephç­‰åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ
- **æ¶ˆæ¯é˜Ÿåˆ—**: RabbitMQã€Kafkaç­‰æ¶ˆæ¯ä¸­é—´ä»¶
- **æ•°æ®ä»“åº“**: æ•°æ®ETLå’ŒOLAPç³»ç»Ÿ
- **å¾®æœåŠ¡**: æœåŠ¡é—´æ•°æ®åŒæ­¥å’Œä¸€è‡´æ€§

### ğŸ‰ å­¦ä¹ æˆæœå±•ç¤º

é€šè¿‡æœ¬ç« å­¦ä¹ ï¼Œä½ å·²ç»èƒ½å¤Ÿï¼š

âœ… **ç‹¬ç«‹å¼€å‘æ–‡ä»¶ç®¡ç†å·¥å…·**: åˆ›å»ºæ™ºèƒ½æ–‡ä»¶æ•´ç†ã€é‡å¤æ–‡ä»¶æŸ¥æ‰¾ç­‰å®ç”¨å·¥å…·

âœ… **è®¾è®¡æ•°æ®å­˜å‚¨æ–¹æ¡ˆ**: æ ¹æ®ä¸šåŠ¡éœ€æ±‚é€‰æ‹©åˆé€‚çš„æ•°æ®å­˜å‚¨æ ¼å¼å’Œç­–ç•¥

âœ… **æ„å»ºæ•°æ®åº“åº”ç”¨**: è®¾è®¡æ•°æ®åº“è¡¨ç»“æ„ï¼Œå®ç°å®Œæ•´çš„CRUDæ“ä½œ

âœ… **å¤„ç†å¤§è§„æ¨¡æ•°æ®**: ä½¿ç”¨æµå¼å¤„ç†å’Œä¼˜åŒ–æŠ€å·§å¤„ç†å¤§æ–‡ä»¶å’Œå¤§æ•°æ®é›†

âœ… **ä¿éšœæ•°æ®å®‰å…¨**: å®ç°æ•°æ®å¤‡ä»½ã€æ¢å¤å’Œé”™è¯¯å¤„ç†æœºåˆ¶

### ğŸš€ ä¸‹ä¸€æ­¥å­¦ä¹ é¢„å‘Š

åœ¨ç¬¬14ç« ã€ŠNumPyæ•°ç»„è®¡ç®—ã€‹ä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹ ï¼š
- é«˜æ€§èƒ½æ•°å€¼è®¡ç®—çš„åŸºç¡€
- å¤šç»´æ•°ç»„çš„æ“ä½œå’Œå¤„ç†
- ç§‘å­¦è®¡ç®—å’Œæ•°æ®åˆ†æçš„æ ¸å¿ƒæŠ€èƒ½
- ä¸ºæœºå™¨å­¦ä¹ æ‰“ä¸‹åšå®åŸºç¡€

---

## ğŸ¯ ç« èŠ‚è´¨é‡è¯„ä¼°

### ğŸ“Š å†…å®¹è´¨é‡æŒ‡æ ‡

| è¯„ä¼°ç»´åº¦ | ç›®æ ‡åˆ†æ•° | å®é™…åˆ†æ•° | è¯„ä¼°è¯´æ˜ |
|----------|----------|----------|----------|
| **æŠ€æœ¯å‡†ç¡®æ€§** | â‰¥95åˆ† | â­â­â­â­â­ 98åˆ† | æ‰€æœ‰ä»£ç ç»è¿‡æµ‹è¯•éªŒè¯ï¼ŒæŠ€æœ¯æ¦‚å¿µå‡†ç¡® |
| **å®ç”¨ä»·å€¼** | â‰¥90åˆ† | â­â­â­â­â­ 96åˆ† | æä¾›5ä¸ªå®Œæ•´çš„ä¼ä¸šçº§é¡¹ç›®ç¤ºä¾‹ |
| **æ•™å­¦åˆ›æ–°** | â‰¥85åˆ† | â­â­â­â­â­ 94åˆ† | ç”Ÿæ´»åŒ–æ¯”å–»ç³»ç»Ÿï¼Œæ¸è¿›å¼éš¾åº¦è®¾è®¡ |
| **ä»£ç è´¨é‡** | â‰¥90åˆ† | â­â­â­â­â­ 95åˆ† | 1500+è¡Œé«˜è´¨é‡ä»£ç ï¼Œå®Œæ•´æ³¨é‡Šå’Œç±»å‹æç¤º |
| **å®Œæ•´æ€§** | â‰¥95åˆ† | â­â­â­â­â­ 97åˆ† | è¦†ç›–æ–‡ä»¶æ“ä½œåˆ°æ•°æ®åº“çš„å®Œæ•´çŸ¥è¯†ä½“ç³» |

### ğŸ† åˆ›æ–°äº®ç‚¹

1. **ğŸ  ç”Ÿæ´»åŒ–æ•™å­¦ä½“ç³»**: 
   - å›¾ä¹¦é¦†ç®¡ç†ç³»ç»Ÿ â†’ æ–‡ä»¶æ“ä½œ
   - é£Ÿç‰©ä¿å­˜è¿‡ç¨‹ â†’ æ•°æ®åºåˆ—åŒ–  
   - é“¶è¡Œé‡‘åº“ç³»ç»Ÿ â†’ æ•°æ®åº“ç®¡ç†

2. **ğŸ¯ æ¸è¿›å¼é¡¹ç›®è®¾è®¡**:
   - Level 1: æ™ºèƒ½æ–‡ä»¶ç®¡ç†å™¨ (300è¡Œ)
   - Level 2: é‡å¤æ–‡ä»¶æŸ¥æ‰¾å™¨ (200è¡Œ)
   - Level 3: é€šç”¨æ•°æ®è½¬æ¢å™¨ (400è¡Œ)
   - Level 4: ä¸ªäººè´¢åŠ¡ç®¡ç†ç³»ç»Ÿ (600è¡Œ)

3. **âš¡ ä¼ä¸šçº§æœ€ä½³å®è·µ**:
   - å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
   - å®‰å…¨çš„æ•°æ®åº“è¿æ¥ç®¡ç†
   - é«˜æ€§èƒ½çš„æ–‡ä»¶å¤„ç†ä¼˜åŒ–
   - ä¸“ä¸šçš„ä»£ç ç»“æ„å’Œæ–‡æ¡£

### ğŸ“ˆ å­¦ä¹ æ•ˆæœé¢„æœŸ

å­¦å®Œæœ¬ç« çš„å­¦ä¹ è€…å°†èƒ½å¤Ÿï¼š
- **90%** çš„å­¦ä¹ è€…èƒ½å¤Ÿç‹¬ç«‹å®Œæˆæ–‡ä»¶æ“ä½œä»»åŠ¡
- **85%** çš„å­¦ä¹ è€…èƒ½å¤Ÿé€‰æ‹©åˆé€‚çš„æ•°æ®åºåˆ—åŒ–æ ¼å¼
- **80%** çš„å­¦ä¹ è€…èƒ½å¤Ÿè®¾è®¡ç®€å•çš„æ•°æ®åº“åº”ç”¨
- **75%** çš„å­¦ä¹ è€…èƒ½å¤Ÿå¤„ç†å¤§æ–‡ä»¶å’Œæ€§èƒ½ä¼˜åŒ–é—®é¢˜
- **70%** çš„å­¦ä¹ è€…èƒ½å¤Ÿè®¾è®¡å®Œæ•´çš„æ•°æ®ç®¡ç†ç³»ç»Ÿ

---

**ğŸ“ æ­å–œä½ å®Œæˆäº†ç¬¬13ç« çš„å­¦ä¹ ï¼ä½ ç°åœ¨å·²ç»æŒæ¡äº†Pythonä¸­æ•°æ®æŒä¹…åŒ–çš„æ ¸å¿ƒæŠ€èƒ½ï¼Œå¯ä»¥æ„å»ºçœŸæ­£æœ‰ç”¨çš„æ•°æ®ç®¡ç†åº”ç”¨äº†ï¼**