# ç¬¬14ç«  NumPyæ•°ç»„è®¡ç®—

> "åœ¨æ•°æ®ç§‘å­¦çš„ä¸–ç•Œé‡Œï¼ŒNumPyå°±åƒæ˜¯ä¸€åº§é«˜æ•ˆçš„æ•°æ®å·¥å‚ï¼Œå®ƒèƒ½å¤Ÿä»¥é—ªç”µèˆ¬çš„é€Ÿåº¦å¤„ç†æµ·é‡æ•°æ®ï¼Œè®©å¤æ‚çš„æ•°å€¼è®¡ç®—å˜å¾—è½»æ¾æ„‰å¿«ã€‚"

## ğŸ¯ æœ¬ç« å­¦ä¹ ç›®æ ‡

å­¦å®Œæœ¬ç« ï¼Œä½ å°†èƒ½å¤Ÿï¼š
- ğŸ”§ **æŒæ¡NumPyåŸºç¡€**: ç†Ÿç»ƒåˆ›å»ºã€æ“ä½œå’Œç®¡ç†å¤šç»´æ•°ç»„
- âš¡ **æ•°ç»„è®¡ç®—æŠ€èƒ½**: æŒæ¡å‘é‡åŒ–è®¡ç®—ã€å¹¿æ’­æœºåˆ¶å’Œæ•°å­¦è¿ç®—
- ğŸ” **æ•°æ®å¤„ç†èƒ½åŠ›**: èƒ½å¤Ÿè¿›è¡Œæ•°ç»„ç´¢å¼•ã€åˆ‡ç‰‡ã€é‡å¡‘å’Œèšåˆæ“ä½œ
- ğŸ§® **ç§‘å­¦è®¡ç®—åº”ç”¨**: ä½¿ç”¨NumPyè§£å†³å®é™…çš„æ•°å€¼è®¡ç®—é—®é¢˜
- ğŸš€ **æ€§èƒ½ä¼˜åŒ–æ„è¯†**: ç†è§£NumPyçš„æ€§èƒ½ä¼˜åŠ¿å’Œæœ€ä½³å®è·µ

## ğŸ“š ç« èŠ‚å†…å®¹å¯¼è§ˆ

```mermaid
mindmap
  root((NumPyæ•°ç»„è®¡ç®—))
    NumPyåŸºç¡€
      æ•°ç»„åˆ›å»º
      æ•°æ®ç±»å‹
      æ•°ç»„å±æ€§
      ç§‘å­¦æ•°æ®ç”Ÿæˆå™¨
    æ•°ç»„æ“ä½œ
      ç´¢å¼•è®¿é—®
      åˆ‡ç‰‡æ“ä½œ
      å¸ƒå°”ç´¢å¼•
      æ•°æ®ç­›é€‰å™¨
    æ•°ç»„è®¡ç®—
      å‘é‡åŒ–è®¡ç®—
      å¹¿æ’­æœºåˆ¶
      æ•°å­¦å‡½æ•°
      æ•°å€¼è®¡ç®—å¼•æ“
    é«˜çº§æ“ä½œ
      æ•°ç»„é‡å¡‘
      æ•°ç»„è¿æ¥
      çº¿æ€§ä»£æ•°
      çŸ©é˜µè®¡ç®—å™¨
```

---

## 14.1 NumPyåŸºç¡€ä¸æ•°ç»„åˆ›å»º

### ğŸ­ NumPyçš„å·¥å‚åŒ–æ€ç»´

æƒ³è±¡ä¸€ä¸‹ï¼Œå¦‚æœPythonçš„åˆ—è¡¨æ˜¯æ‰‹å·¥ä½œåŠï¼Œé‚£ä¹ˆNumPyæ•°ç»„å°±æ˜¯ç°ä»£åŒ–çš„å·¥å‚æµæ°´çº¿ï¼š

- **æ‰‹å·¥ä½œåŠï¼ˆPythonåˆ—è¡¨ï¼‰**: çµæ´»ä½†æ•ˆç‡ä½ï¼Œæ¯ä¸ªäº§å“éƒ½éœ€è¦å•ç‹¬å¤„ç†
- **å·¥å‚æµæ°´çº¿ï¼ˆNumPyæ•°ç»„ï¼‰**: æ ‡å‡†åŒ–ã€æ‰¹é‡åŒ–ã€é«˜æ•ˆç‡çš„æ•°æ®å¤„ç†

```python
import numpy as np
import time

# ğŸ”§ æ€§èƒ½å¯¹æ¯”ï¼šæ‰‹å·¥ä½œåŠ vs å·¥å‚æµæ°´çº¿
def compare_performance():
    """å¯¹æ¯”Pythonåˆ—è¡¨å’ŒNumPyæ•°ç»„çš„æ€§èƒ½å·®å¼‚"""
    size = 1000000
    
    # Pythonåˆ—è¡¨çš„æ‰‹å·¥ä½œåŠæ–¹å¼
    start_time = time.time()
    python_list = list(range(size))
    result_list = [x * 2 for x in python_list]
    python_time = time.time() - start_time
    
    # NumPyæ•°ç»„çš„å·¥å‚æµæ°´çº¿æ–¹å¼
    start_time = time.time()
    numpy_array = np.arange(size)
    result_array = numpy_array * 2
    numpy_time = time.time() - start_time
    
    print(f"ğŸŒ Pythonåˆ—è¡¨æ—¶é—´: {python_time:.4f}ç§’")
    print(f"âš¡ NumPyæ•°ç»„æ—¶é—´: {numpy_time:.4f}ç§’")
    print(f"ğŸš€ NumPyé€Ÿåº¦æå‡: {python_time/numpy_time:.1f}å€")

# è¿è¡Œæ€§èƒ½å¯¹æ¯”
compare_performance()
```

### ğŸ“¦ NumPyæ•°ç»„çš„åˆ›å»ºæ–¹æ³•

NumPyæä¾›äº†å¤šç§"å·¥å‚æ¨¡å¼"æ¥åˆ›å»ºæ•°ç»„ï¼Œå°±åƒä¸åŒçš„ç”Ÿäº§çº¿ä¸“é—¨åˆ¶é€ ä¸åŒç±»å‹çš„äº§å“ï¼š

#### 1. åŸºç¡€åˆ›å»ºæ–¹æ³•

```python
import numpy as np

# ğŸ—ï¸ ä»Pythonåˆ—è¡¨åˆ›å»ºæ•°ç»„ï¼ˆæœ€å¸¸ç”¨çš„å…¥é—¨æ–¹å¼ï¼‰
def create_from_list():
    """ä»Pythonæ•°æ®ç»“æ„åˆ›å»ºNumPyæ•°ç»„"""
    # ä¸€ç»´æ•°ç»„
    arr_1d = np.array([1, 2, 3, 4, 5])
    print(f"ä¸€ç»´æ•°ç»„: {arr_1d}")
    print(f"æ•°ç»„ç±»å‹: {type(arr_1d)}")
    print(f"å…ƒç´ ç±»å‹: {arr_1d.dtype}")
    
    # äºŒç»´æ•°ç»„ï¼ˆçŸ©é˜µï¼‰
    arr_2d = np.array([[1, 2, 3], [4, 5, 6]])
    print(f"äºŒç»´æ•°ç»„:\n{arr_2d}")
    print(f"æ•°ç»„å½¢çŠ¶: {arr_2d.shape}")
    
    # ä¸‰ç»´æ•°ç»„ï¼ˆç«‹ä½“æ•°æ®ï¼‰
    arr_3d = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])
    print(f"ä¸‰ç»´æ•°ç»„:\n{arr_3d}")
    print(f"æ•°ç»„ç»´åº¦: {arr_3d.ndim}")
    
    return arr_1d, arr_2d, arr_3d

# ğŸ­ æ ‡å‡†åŒ–ç”Ÿäº§çº¿ï¼ˆåˆ›å»ºç‰¹æ®Šæ•°ç»„ï¼‰
def create_special_arrays():
    """åˆ›å»ºç‰¹æ®Šç”¨é€”çš„æ•°ç»„"""
    # å…¨é›¶æ•°ç»„ï¼ˆåˆå§‹åŒ–ä¸“ç”¨ï¼‰
    zeros_arr = np.zeros((3, 4))
    print(f"å…¨é›¶æ•°ç»„:\n{zeros_arr}")
    
    # å…¨ä¸€æ•°ç»„ï¼ˆåŸºç¡€æ¨¡æ¿ï¼‰
    ones_arr = np.ones((2, 3, 4))
    print(f"å…¨ä¸€æ•°ç»„å½¢çŠ¶: {ones_arr.shape}")
    
    # å•ä½çŸ©é˜µï¼ˆçº¿æ€§ä»£æ•°ä¸“ç”¨ï¼‰
    identity_arr = np.eye(4)
    print(f"å•ä½çŸ©é˜µ:\n{identity_arr}")
    
    # æŒ‡å®šå€¼å¡«å……
    full_arr = np.full((2, 3), 7)
    print(f"æŒ‡å®šå€¼æ•°ç»„:\n{full_arr}")
    
    return zeros_arr, ones_arr, identity_arr, full_arr

# ğŸ“ æ•°å€¼åºåˆ—ç”Ÿäº§çº¿
def create_sequences():
    """åˆ›å»ºæ•°å€¼åºåˆ—æ•°ç»„"""
    # ç­‰å·®æ•°åˆ—ï¼ˆæœ€å¸¸ç”¨ï¼‰
    range_arr = np.arange(0, 10, 2)  # èµ·å§‹ã€ç»“æŸã€æ­¥é•¿
    print(f"ç­‰å·®æ•°åˆ—: {range_arr}")
    
    # ç­‰é—´è·æ•°åˆ—ï¼ˆç§‘å­¦è®¡ç®—ä¸“ç”¨ï¼‰
    linspace_arr = np.linspace(0, 1, 11)  # èµ·å§‹ã€ç»“æŸã€ç‚¹æ•°
    print(f"ç­‰é—´è·æ•°åˆ—: {linspace_arr}")
    
    # å¯¹æ•°åºåˆ—ï¼ˆç‰¹æ®Šç”¨é€”ï¼‰
    logspace_arr = np.logspace(0, 2, 5)  # 10^0 åˆ° 10^2ï¼Œ5ä¸ªç‚¹
    print(f"å¯¹æ•°åºåˆ—: {logspace_arr}")
    
    return range_arr, linspace_arr, logspace_arr

# ğŸ² éšæœºæ•°ç”Ÿäº§çº¿
def create_random_arrays():
    """åˆ›å»ºéšæœºæ•°ç»„"""
    # è®¾ç½®éšæœºç§å­ç¡®ä¿ç»“æœå¯é‡ç°
    np.random.seed(42)
    
    # å‡åŒ€åˆ†å¸ƒéšæœºæ•°
    uniform_arr = np.random.random((2, 3))
    print(f"å‡åŒ€åˆ†å¸ƒéšæœºæ•°:\n{uniform_arr}")
    
    # æ­£æ€åˆ†å¸ƒéšæœºæ•°
    normal_arr = np.random.normal(0, 1, (2, 3))  # å‡å€¼0ï¼Œæ ‡å‡†å·®1
    print(f"æ­£æ€åˆ†å¸ƒéšæœºæ•°:\n{normal_arr}")
    
    # æ•´æ•°éšæœºæ•°
    randint_arr = np.random.randint(1, 10, (2, 3))
    print(f"æ•´æ•°éšæœºæ•°:\n{randint_arr}")
    
    return uniform_arr, normal_arr, randint_arr

# è¿è¡Œæ‰€æœ‰åˆ›å»ºç¤ºä¾‹
create_from_list()
print("\n" + "="*50 + "\n")
create_special_arrays()
print("\n" + "="*50 + "\n")
create_sequences()
print("\n" + "="*50 + "\n")
create_random_arrays()
```

#### 2. æ•°æ®ç±»å‹ç³»ç»Ÿ

NumPyçš„æ•°æ®ç±»å‹ç³»ç»Ÿå°±åƒå·¥å‚çš„è´¨é‡æ ‡å‡†ï¼Œç²¾ç¡®æ§åˆ¶æ¯ä¸ªäº§å“çš„è§„æ ¼ï¼š

```python
# ğŸ”¬ æ•°æ®ç±»å‹ç²¾ç¡®æ§åˆ¶
def explore_data_types():
    """æ¢ç´¢NumPyçš„æ•°æ®ç±»å‹ç³»ç»Ÿ"""
    
    # æ•´æ•°ç±»å‹å®¶æ—
    int8_arr = np.array([1, 2, 3], dtype=np.int8)    # 8ä½æ•´æ•° (-128åˆ°127)
    int32_arr = np.array([1, 2, 3], dtype=np.int32)  # 32ä½æ•´æ•°
    int64_arr = np.array([1, 2, 3], dtype=np.int64)  # 64ä½æ•´æ•°
    
    print("æ•´æ•°ç±»å‹å®¶æ—:")
    print(f"int8:  {int8_arr.dtype}, å†…å­˜: {int8_arr.nbytes}å­—èŠ‚")
    print(f"int32: {int32_arr.dtype}, å†…å­˜: {int32_arr.nbytes}å­—èŠ‚")
    print(f"int64: {int64_arr.dtype}, å†…å­˜: {int64_arr.nbytes}å­—èŠ‚")
    
    # æµ®ç‚¹æ•°ç±»å‹å®¶æ—
    float32_arr = np.array([1.1, 2.2, 3.3], dtype=np.float32)
    float64_arr = np.array([1.1, 2.2, 3.3], dtype=np.float64)
    
    print("\næµ®ç‚¹æ•°ç±»å‹å®¶æ—:")
    print(f"float32: {float32_arr.dtype}, ç²¾åº¦: å•ç²¾åº¦")
    print(f"float64: {float64_arr.dtype}, ç²¾åº¦: åŒç²¾åº¦")
    
    # å¤æ•°ç±»å‹
    complex_arr = np.array([1+2j, 3+4j], dtype=np.complex128)
    print(f"\nå¤æ•°ç±»å‹: {complex_arr.dtype}")
    print(f"å¤æ•°æ•°ç»„: {complex_arr}")
    
    # å¸ƒå°”ç±»å‹
    bool_arr = np.array([True, False, True], dtype=np.bool_)
    print(f"\nå¸ƒå°”ç±»å‹: {bool_arr.dtype}")
    print(f"å¸ƒå°”æ•°ç»„: {bool_arr}")
    
    # å­—ç¬¦ä¸²ç±»å‹
    str_arr = np.array(['apple', 'banana', 'cherry'], dtype='U10')
    print(f"\nå­—ç¬¦ä¸²ç±»å‹: {str_arr.dtype}")
    print(f"å­—ç¬¦ä¸²æ•°ç»„: {str_arr}")

# ğŸ”„ æ•°æ®ç±»å‹è½¬æ¢
def type_conversion_demo():
    """æ¼”ç¤ºæ•°æ®ç±»å‹è½¬æ¢"""
    original = np.array([1.7, 2.3, 3.9])
    print(f"åŸå§‹æ•°ç»„: {original}, ç±»å‹: {original.dtype}")
    
    # è½¬æ¢ä¸ºæ•´æ•°ï¼ˆæˆªæ–­ï¼‰
    to_int = original.astype(np.int32)
    print(f"è½¬ä¸ºæ•´æ•°: {to_int}, ç±»å‹: {to_int.dtype}")
    
    # è½¬æ¢ä¸ºå­—ç¬¦ä¸²
    to_str = original.astype('U10')
    print(f"è½¬ä¸ºå­—ç¬¦ä¸²: {to_str}, ç±»å‹: {to_str.dtype}")
    
    # è‡ªåŠ¨ç±»å‹æ¨æ–­
    mixed = np.array([1, 2.5, 3])  # è‡ªåŠ¨é€‰æ‹©float64
    print(f"è‡ªåŠ¨æ¨æ–­: {mixed}, ç±»å‹: {mixed.dtype}")

explore_data_types()
print("\n" + "="*50 + "\n")
type_conversion_demo()
```

#### 3. æ•°ç»„å±æ€§è¯¦è§£

NumPyæ•°ç»„çš„å±æ€§å°±åƒäº§å“çš„è§„æ ¼è¯´æ˜ä¹¦ï¼Œå‘Šè¯‰æˆ‘ä»¬å…³äºæ•°æ®çš„æ‰€æœ‰é‡è¦ä¿¡æ¯ï¼š

```python
# ğŸ“‹ æ•°ç»„å±æ€§å…¨è§£æ
def array_attributes_demo():
    """è¯¦ç»†å±•ç¤ºNumPyæ•°ç»„çš„å„ç§å±æ€§"""
    
    # åˆ›å»ºä¸€ä¸ªå¤æ‚çš„å¤šç»´æ•°ç»„ä½œä¸ºç¤ºä¾‹
    sample_array = np.random.randint(1, 100, (3, 4, 5)).astype(np.float32)
    
    print("ğŸ” æ•°ç»„å±æ€§è¯¦è§£:")
    print(f"æ•°ç»„å†…å®¹:\n{sample_array[0]}  # åªæ˜¾ç¤ºç¬¬ä¸€å±‚")
    print(f"\nğŸ“ å½¢çŠ¶å±æ€§:")
    print(f"  shape (å½¢çŠ¶): {sample_array.shape}")
    print(f"  ndim (ç»´åº¦æ•°): {sample_array.ndim}")
    print(f"  size (å…ƒç´ æ€»æ•°): {sample_array.size}")
    
    print(f"\nğŸ”§ æ•°æ®å±æ€§:")
    print(f"  dtype (æ•°æ®ç±»å‹): {sample_array.dtype}")
    print(f"  itemsize (æ¯ä¸ªå…ƒç´ å­—èŠ‚æ•°): {sample_array.itemsize}")
    print(f"  nbytes (æ€»å­—èŠ‚æ•°): {sample_array.nbytes}")
    
    print(f"\nğŸ’¾ å†…å­˜å±æ€§:")
    print(f"  flags.c_contiguous (Cè¿ç»­): {sample_array.flags.c_contiguous}")
    print(f"  flags.f_contiguous (Fortranè¿ç»­): {sample_array.flags.f_contiguous}")
    print(f"  flags.writeable (å¯å†™): {sample_array.flags.writeable}")
    
    # è®¡ç®—å†…å­˜ä½¿ç”¨æ•ˆç‡
    python_list_size = sample_array.size * 8  # Pythonå¯¹è±¡å¤§çº¦8å­—èŠ‚
    numpy_size = sample_array.nbytes
    efficiency = python_list_size / numpy_size
    
    print(f"\nâš¡ å†…å­˜æ•ˆç‡:")
    print(f"  Pythonåˆ—è¡¨ä¼°è®¡: {python_list_size} å­—èŠ‚")
    print(f"  NumPyæ•°ç»„å®é™…: {numpy_size} å­—èŠ‚")
    print(f"  å†…å­˜æ•ˆç‡æå‡: {efficiency:.1f}å€")

array_attributes_demo()
```

### ğŸ› ï¸ å®æˆ˜é¡¹ç›®ï¼šç§‘å­¦æ•°æ®ç”Ÿæˆå™¨

ç°åœ¨è®©æˆ‘ä»¬æ„å»ºä¸€ä¸ªå®Œæ•´çš„ç§‘å­¦æ•°æ®ç”Ÿæˆå™¨ï¼Œå±•ç¤ºNumPyæ•°ç»„åˆ›å»ºçš„å®é™…åº”ç”¨ï¼š

```python
import numpy as np
import matplotlib.pyplot as plt
from typing import Tuple, List, Union

class ScientificDataGenerator:
    """ç§‘å­¦æ•°æ®ç”Ÿæˆå™¨ï¼šä¸“ä¸šçš„æ•°æ®é›†åˆ›å»ºå·¥å…·
    
    è¿™ä¸ªç±»å°±åƒä¸€ä¸ªå¤šåŠŸèƒ½çš„æ•°æ®å·¥å‚ï¼Œèƒ½å¤Ÿç”Ÿæˆå„ç§ç§‘å­¦è®¡ç®—
    å’Œæ•°æ®åˆ†æä¸­å¸¸ç”¨çš„æ•°æ®é›†ã€‚
    """
    
    def __init__(self, seed: int = 42):
        """åˆå§‹åŒ–æ•°æ®ç”Ÿæˆå™¨
        
        Args:
            seed: éšæœºç§å­ï¼Œç¡®ä¿ç»“æœå¯é‡ç°
        """
        self.seed = seed
        np.random.seed(seed)
        print(f"ğŸ­ ç§‘å­¦æ•°æ®ç”Ÿæˆå™¨å·²å¯åŠ¨ (ç§å­: {seed})")
    
    def generate_time_series(self, 
                           length: int = 1000,
                           sampling_rate: float = 1.0,
                           trend_coeff: float = 0.01,
                           noise_level: float = 0.1) -> Tuple[np.ndarray, np.ndarray]:
        """ç”Ÿæˆæ—¶é—´åºåˆ—æ•°æ®
        
        Args:
            length: æ•°æ®ç‚¹æ•°é‡
            sampling_rate: é‡‡æ ·ç‡
            trend_coeff: è¶‹åŠ¿ç³»æ•°
            noise_level: å™ªå£°æ°´å¹³
            
        Returns:
            æ—¶é—´è½´å’Œå¯¹åº”çš„æ•°å€¼
        """
        print(f"ğŸ“ˆ ç”Ÿæˆæ—¶é—´åºåˆ—æ•°æ® (é•¿åº¦: {length})")
        
        # åˆ›å»ºæ—¶é—´è½´
        time = np.linspace(0, length/sampling_rate, length)
        
        # ç”ŸæˆåŸºç¡€ä¿¡å·ï¼ˆæ­£å¼¦æ³¢ + è¶‹åŠ¿ + å™ªå£°ï¼‰
        signal = (np.sin(2 * np.pi * 0.1 * time) +           # ä¸»é¢‘ç‡
                 0.5 * np.sin(2 * np.pi * 0.3 * time) +      # é«˜é¢‘æˆåˆ†
                 trend_coeff * time +                          # çº¿æ€§è¶‹åŠ¿
                 noise_level * np.random.normal(0, 1, length)) # é«˜æ–¯å™ªå£°
        
        print(f"  âœ… æ—¶é—´èŒƒå›´: {time[0]:.2f} - {time[-1]:.2f}")
        print(f"  âœ… æ•°å€¼èŒƒå›´: {signal.min():.2f} - {signal.max():.2f}")
        
        return time, signal
    
    def generate_experimental_data(self, 
                                 n_experiments: int = 50,
                                 n_measurements: int = 20) -> np.ndarray:
        """ç”Ÿæˆå®éªŒæ•°æ®çŸ©é˜µ
        
        Args:
            n_experiments: å®éªŒæ¬¡æ•°
            n_measurements: æ¯æ¬¡å®éªŒçš„æµ‹é‡æ¬¡æ•°
            
        Returns:
            å®éªŒæ•°æ®çŸ©é˜µ (n_experiments Ã— n_measurements)
        """
        print(f"ğŸ§ª ç”Ÿæˆå®éªŒæ•°æ®çŸ©é˜µ ({n_experiments}Ã—{n_measurements})")
        
        # ç”ŸæˆåŸºç¡€å®éªŒæ•°æ®
        base_value = 100.0
        experiment_variation = np.random.normal(0, 10, (n_experiments, 1))
        measurement_noise = np.random.normal(0, 2, (n_experiments, n_measurements))
        
        # ç»„åˆæˆæœ€ç»ˆæ•°æ®
        data = base_value + experiment_variation + measurement_noise
        
        print(f"  âœ… æ•°æ®å½¢çŠ¶: {data.shape}")
        print(f"  âœ… å¹³å‡å€¼: {data.mean():.2f}")
        print(f"  âœ… æ ‡å‡†å·®: {data.std():.2f}")
        
        return data
    
    def generate_image_data(self, 
                          width: int = 64, 
                          height: int = 64,
                          pattern_type: str = 'gradient') -> np.ndarray:
        """ç”Ÿæˆå›¾åƒæ•°æ®
        
        Args:
            width: å›¾åƒå®½åº¦
            height: å›¾åƒé«˜åº¦
            pattern_type: å›¾æ¡ˆç±»å‹ ('gradient', 'checkerboard', 'noise')
            
        Returns:
            å›¾åƒæ•°æ®æ•°ç»„
        """
        print(f"ğŸ–¼ï¸ ç”Ÿæˆå›¾åƒæ•°æ® ({width}Ã—{height}, ç±»å‹: {pattern_type})")
        
        if pattern_type == 'gradient':
            # æ¸å˜å›¾æ¡ˆ
            x = np.linspace(0, 1, width)
            y = np.linspace(0, 1, height)
            X, Y = np.meshgrid(x, y)
            image = X + Y
            
        elif pattern_type == 'checkerboard':
            # æ£‹ç›˜å›¾æ¡ˆ
            x = np.arange(width) // 8
            y = np.arange(height) // 8
            X, Y = np.meshgrid(x, y)
            image = (X + Y) % 2
            
        elif pattern_type == 'noise':
            # éšæœºå™ªå£°
            image = np.random.random((height, width))
            
        else:
            raise ValueError(f"æœªçŸ¥çš„å›¾æ¡ˆç±»å‹: {pattern_type}")
        
        print(f"  âœ… å›¾åƒå½¢çŠ¶: {image.shape}")
        print(f"  âœ… åƒç´ èŒƒå›´: {image.min():.3f} - {image.max():.3f}")
        
        return image
    
    def generate_statistical_samples(self, 
                                   distribution: str = 'normal',
                                   size: int = 1000,
                                   **kwargs) -> np.ndarray:
        """ç”Ÿæˆç»Ÿè®¡åˆ†å¸ƒæ ·æœ¬
        
        Args:
            distribution: åˆ†å¸ƒç±»å‹
            size: æ ·æœ¬æ•°é‡
            **kwargs: åˆ†å¸ƒå‚æ•°
            
        Returns:
            ç»Ÿè®¡æ ·æœ¬æ•°ç»„
        """
        print(f"ğŸ“Š ç”Ÿæˆç»Ÿè®¡æ ·æœ¬ (åˆ†å¸ƒ: {distribution}, å¤§å°: {size})")
        
        if distribution == 'normal':
            loc = kwargs.get('loc', 0)  # å‡å€¼
            scale = kwargs.get('scale', 1)  # æ ‡å‡†å·®
            samples = np.random.normal(loc, scale, size)
            
        elif distribution == 'exponential':
            scale = kwargs.get('scale', 1)
            samples = np.random.exponential(scale, size)
            
        elif distribution == 'uniform':
            low = kwargs.get('low', 0)
            high = kwargs.get('high', 1)
            samples = np.random.uniform(low, high, size)
            
        elif distribution == 'poisson':
            lam = kwargs.get('lam', 1)
            samples = np.random.poisson(lam, size)
            
        else:
            raise ValueError(f"æœªæ”¯æŒçš„åˆ†å¸ƒç±»å‹: {distribution}")
        
        print(f"  âœ… æ ·æœ¬ç»Ÿè®¡: å‡å€¼={samples.mean():.3f}, æ ‡å‡†å·®={samples.std():.3f}")
        
        return samples
    
    def create_dataset_summary(self, datasets: dict) -> None:
        """åˆ›å»ºæ•°æ®é›†æ‘˜è¦æŠ¥å‘Š
        
        Args:
            datasets: æ•°æ®é›†å­—å…¸
        """
        print("\n" + "="*60)
        print("ğŸ“‹ æ•°æ®é›†æ‘˜è¦æŠ¥å‘Š")
        print("="*60)
        
        total_elements = 0
        total_memory = 0
        
        for name, data in datasets.items():
            elements = data.size
            memory_mb = data.nbytes / (1024**2)
            total_elements += elements
            total_memory += memory_mb
            
            print(f"\nğŸ“ {name}:")
            print(f"  å½¢çŠ¶: {data.shape}")
            print(f"  æ•°æ®ç±»å‹: {data.dtype}")
            print(f"  å…ƒç´ æ•°é‡: {elements:,}")
            print(f"  å†…å­˜ä½¿ç”¨: {memory_mb:.2f} MB")
            print(f"  æ•°å€¼èŒƒå›´: [{data.min():.3f}, {data.max():.3f}]")
        
        print(f"\nğŸ¯ æ€»è®¡:")
        print(f"  æ€»å…ƒç´ æ•°: {total_elements:,}")
        print(f"  æ€»å†…å­˜: {total_memory:.2f} MB")
        print("="*60)

# ğŸš€ ç§‘å­¦æ•°æ®ç”Ÿæˆå™¨ä½¿ç”¨ç¤ºä¾‹
def demo_scientific_data_generator():
    """æ¼”ç¤ºç§‘å­¦æ•°æ®ç”Ÿæˆå™¨çš„ä½¿ç”¨"""
    print("ğŸ¯ ç§‘å­¦æ•°æ®ç”Ÿæˆå™¨æ¼”ç¤º\n")
    
    # åˆ›å»ºç”Ÿæˆå™¨å®ä¾‹
    generator = ScientificDataGenerator(seed=42)
    
    # ç”Ÿæˆå„ç§ç±»å‹çš„æ•°æ®
    datasets = {}
    
    # 1. æ—¶é—´åºåˆ—æ•°æ®
    time, signal = generator.generate_time_series(length=1000, noise_level=0.2)
    datasets['æ—¶é—´åºåˆ—'] = signal
    
    # 2. å®éªŒæ•°æ®
    exp_data = generator.generate_experimental_data(n_experiments=30, n_measurements=15)
    datasets['å®éªŒæ•°æ®'] = exp_data
    
    # 3. å›¾åƒæ•°æ®
    image_gradient = generator.generate_image_data(64, 64, 'gradient')
    datasets['æ¢¯åº¦å›¾åƒ'] = image_gradient
    
    image_checkerboard = generator.generate_image_data(64, 64, 'checkerboard')
    datasets['æ£‹ç›˜å›¾åƒ'] = image_checkerboard
    
    # 4. ç»Ÿè®¡æ ·æœ¬
    normal_samples = generator.generate_statistical_samples('normal', 1000, loc=50, scale=10)
    datasets['æ­£æ€åˆ†å¸ƒæ ·æœ¬'] = normal_samples
    
    exponential_samples = generator.generate_statistical_samples('exponential', 1000, scale=2)
    datasets['æŒ‡æ•°åˆ†å¸ƒæ ·æœ¬'] = exponential_samples
    
    # ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
    generator.create_dataset_summary(datasets)
    
    return datasets

# è¿è¡Œæ¼”ç¤º
if __name__ == "__main__":
    datasets = demo_scientific_data_generator()
```

### ğŸ’¡ å­¦ä¹ è¦ç‚¹æ€»ç»“

é€šè¿‡æœ¬èŠ‚çš„å­¦ä¹ ï¼Œæˆ‘ä»¬æŒæ¡äº†ï¼š

1. **NumPyçš„æ ¸å¿ƒä¼˜åŠ¿**: ç›¸æ¯”Pythonåˆ—è¡¨ï¼ŒNumPyæ•°ç»„åœ¨æ€§èƒ½ä¸Šæœ‰æ˜¾è‘—æå‡
2. **æ•°ç»„åˆ›å»ºæ–¹æ³•**: ä»åŸºç¡€çš„åˆ—è¡¨è½¬æ¢åˆ°ä¸“ä¸šçš„åºåˆ—ç”Ÿæˆ
3. **æ•°æ®ç±»å‹ç³»ç»Ÿ**: ç²¾ç¡®æ§åˆ¶å†…å­˜ä½¿ç”¨å’Œè®¡ç®—ç²¾åº¦
4. **æ•°ç»„å±æ€§**: æ·±å…¥ç†è§£æ•°ç»„çš„å„ç§ç‰¹æ€§å’Œå†…å­˜å¸ƒå±€
5. **å®é™…åº”ç”¨**: é€šè¿‡ç§‘å­¦æ•°æ®ç”Ÿæˆå™¨é¡¹ç›®ï¼Œå­¦ä¼šç»¼åˆè¿ç”¨å„ç§åˆ›å»ºæ–¹æ³•

### ğŸ¯ æœ¬èŠ‚ç»ƒä¹ 

1. **åŸºç¡€ç»ƒä¹ **: åˆ›å»ºä¸€ä¸ª3Ã—4çš„éšæœºæ•´æ•°æ•°ç»„ï¼Œå…ƒç´ èŒƒå›´åœ¨1-100ä¹‹é—´
2. **è¿›é˜¶ç»ƒä¹ **: æ¯”è¾ƒä¸åŒæ•°æ®ç±»å‹çš„å†…å­˜ä½¿ç”¨æ•ˆç‡
3. **åº”ç”¨ç»ƒä¹ **: æ‰©å±•ç§‘å­¦æ•°æ®ç”Ÿæˆå™¨ï¼Œæ·»åŠ æ–°çš„æ•°æ®ç±»å‹ç”ŸæˆåŠŸèƒ½

---

## 14.2 æ•°ç»„æ“ä½œä¸ç´¢å¼•åˆ‡ç‰‡

### ğŸ“š å›¾ä¹¦é¦†å®šä½ç³»ç»Ÿï¼šç†è§£æ•°ç»„ç´¢å¼•

æƒ³è±¡NumPyæ•°ç»„å°±åƒä¸€ä¸ªå·¨å¤§çš„å›¾ä¹¦é¦†ï¼Œè€Œç´¢å¼•å°±æ˜¯ç²¾ç¡®çš„å®šä½ç³»ç»Ÿã€‚æ— è®ºä½ è¦æ‰¾å“ªæœ¬ä¹¦ï¼ˆæ•°æ®ï¼‰ï¼Œéƒ½èƒ½é€šè¿‡åæ ‡ç³»ç»Ÿå¿«é€Ÿå®šä½åˆ°ç¡®åˆ‡ä½ç½®ã€‚

```python
import numpy as np

# ğŸ›ï¸ ä¸€ç»´æ•°ç»„ï¼šåƒä¹¦æ¶ä¸Šçš„ä¸€æ’ä¹¦
def one_dimensional_indexing():
    """ä¸€ç»´æ•°ç»„ç´¢å¼•ï¼šæœ€åŸºç¡€çš„å®šä½æ–¹å¼"""
    books = np.array(['Pythonç¼–ç¨‹', 'NumPyæŒ‡å—', 'æ•°æ®ç§‘å­¦', 'æœºå™¨å­¦ä¹ ', 'æ·±åº¦å­¦ä¹ '])
    
    print("ğŸ“š å›¾ä¹¦é¦†ä¹¦æ¶:")
    for i, book in enumerate(books):
        print(f"  ä½ç½® {i}: {book}")
    
    print(f"\nğŸ¯ ç´¢å¼•è®¿é—®:")
    print(f"  ç¬¬ä¸€æœ¬ä¹¦ books[0]: {books[0]}")
    print(f"  æœ€åä¸€æœ¬ä¹¦ books[-1]: {books[-1]}")
    print(f"  å€’æ•°ç¬¬äºŒæœ¬ books[-2]: {books[-2]}")
    
    # ä¿®æ”¹å…ƒç´ 
    books[2] = 'æ•°æ®åˆ†æ'
    print(f"  ä¿®æ”¹å books[2]: {books[2]}")
    
    return books

# ğŸ¢ äºŒç»´æ•°ç»„ï¼šåƒå›¾ä¹¦é¦†çš„æ¥¼å±‚å’Œä¹¦æ¶
def two_dimensional_indexing():
    """äºŒç»´æ•°ç»„ç´¢å¼•ï¼šæ¥¼å±‚-ä¹¦æ¶å®šä½ç³»ç»Ÿ"""
    library = np.array([
        ['PythonåŸºç¡€', 'Pythonè¿›é˜¶', 'Pythonå®æˆ˜'],
        ['æ•°æ®åˆ†æ', 'æ•°æ®å¯è§†åŒ–', 'æ•°æ®æŒ–æ˜'],
        ['æœºå™¨å­¦ä¹ ', 'æ·±åº¦å­¦ä¹ ', 'äººå·¥æ™ºèƒ½'],
        ['Webå¼€å‘', 'ç½‘ç»œç¼–ç¨‹', 'æ•°æ®åº“']
    ])
    
    print("ğŸ¢ å›¾ä¹¦é¦†æ¥¼å±‚å¸ƒå±€:")
    floors = ['1æ¥¼-ç¼–ç¨‹åŸºç¡€', '2æ¥¼-æ•°æ®ç§‘å­¦', '3æ¥¼-AIæŠ€æœ¯', '4æ¥¼-å·¥ç¨‹åº”ç”¨']
    for i, (floor_name, floor_books) in enumerate(zip(floors, library)):
        print(f"  {floor_name}: {floor_books}")
    
    print(f"\nğŸ¯ äºŒç»´ç´¢å¼•è®¿é—®:")
    print(f"  2æ¥¼ç¬¬1æœ¬ä¹¦ library[1, 0]: {library[1, 0]}")
    print(f"  3æ¥¼æœ€åä¸€æœ¬ library[2, -1]: {library[2, -1]}")
    print(f"  æ•´ä¸ª1æ¥¼ library[0]: {library[0]}")
    print(f"  æ‰€æœ‰æ¥¼å±‚ç¬¬2æœ¬ä¹¦ library[:, 1]: {library[:, 1]}")
    
    return library

# ğŸ—ï¸ å¤šç»´æ•°ç»„ï¼šåƒç«‹ä½“ä¹¦åº“
def multi_dimensional_indexing():
    """å¤šç»´æ•°ç»„ç´¢å¼•ï¼šç«‹ä½“å®šä½ç³»ç»Ÿ"""
    # 3ç»´æ•°ç»„ï¼šå»ºç­‘ç‰©-æ¥¼å±‚-ä¹¦æ¶
    book_complex = np.random.randint(1, 100, (2, 3, 4))  # 2æ ‹å»ºç­‘ï¼Œ3å±‚æ¥¼ï¼Œ4ä¸ªä¹¦æ¶
    
    print("ğŸ—ï¸ ç«‹ä½“ä¹¦åº“ç»“æ„:")
    print(f"  æ€»ä½“å½¢çŠ¶: {book_complex.shape}")
    print(f"  å»ºç­‘ç‰©æ•°é‡: {book_complex.shape[0]}")
    print(f"  æ¯æ ‹æ¥¼å±‚æ•°: {book_complex.shape[1]}")
    print(f"  æ¯å±‚ä¹¦æ¶æ•°: {book_complex.shape[2]}")
    
    print(f"\nğŸ¯ å¤šç»´ç´¢å¼•è®¿é—®:")
    print(f"  ç¬¬1æ ‹å»ºç­‘:\n{book_complex[0]}")
    print(f"  ç¬¬2æ ‹å»ºç­‘ç¬¬3å±‚: {book_complex[1, 2]}")
    print(f"  ç¬¬1æ ‹ç¬¬2å±‚ç¬¬3ä¸ªä¹¦æ¶: {book_complex[0, 1, 2]}")
    
    return book_complex

# è¿è¡Œç´¢å¼•æ¼”ç¤º
one_dimensional_indexing()
print("\n" + "="*50 + "\n")
two_dimensional_indexing()
print("\n" + "="*50 + "\n")
multi_dimensional_indexing()
```

### âœ‚ï¸ æ•°ç»„åˆ‡ç‰‡ï¼šé«˜æ•ˆçš„æ•°æ®æå–

æ•°ç»„åˆ‡ç‰‡å°±åƒä½¿ç”¨ä¸“ä¸šçš„åˆ‡å‰²å·¥å…·ï¼Œèƒ½å¤Ÿç²¾ç¡®åœ°æå–æ‰€éœ€çš„æ•°æ®ç‰‡æ®µï¼š

```python
# ğŸ”ª ä¸€ç»´åˆ‡ç‰‡ï¼šçº¿æ€§åˆ‡å‰²
def one_dimensional_slicing():
    """ä¸€ç»´æ•°ç»„åˆ‡ç‰‡ï¼šåŸºç¡€åˆ‡å‰²æŠ€æœ¯"""
    data = np.arange(0, 20, 2)  # [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]
    print(f"åŸå§‹æ•°æ®: {data}")
    
    print(f"\nâœ‚ï¸ åŸºç¡€åˆ‡ç‰‡æ“ä½œ:")
    print(f"  å‰5ä¸ªå…ƒç´  data[:5]: {data[:5]}")
    print(f"  å5ä¸ªå…ƒç´  data[-5:]: {data[-5:]}")
    print(f"  ä¸­é—´éƒ¨åˆ† data[2:8]: {data[2:8]}")
    print(f"  æ¯éš”2ä¸ªå–ä¸€ä¸ª data[::2]: {data[::2]}")
    print(f"  åå‘æ’åˆ— data[::-1]: {data[::-1]}")
    print(f"  å¤æ‚åˆ‡ç‰‡ data[1:9:2]: {data[1:9:2]}")
    
    return data

# ğŸ¯ äºŒç»´åˆ‡ç‰‡ï¼šçŸ©å½¢åŒºåŸŸæå–
def two_dimensional_slicing():
    """äºŒç»´æ•°ç»„åˆ‡ç‰‡ï¼šçŸ©å½¢åŒºåŸŸåˆ‡å‰²"""
    matrix = np.arange(24).reshape(4, 6)  # 4Ã—6çŸ©é˜µ
    print(f"åŸå§‹çŸ©é˜µ:\n{matrix}")
    
    print(f"\nâœ‚ï¸ äºŒç»´åˆ‡ç‰‡æ“ä½œ:")
    print(f"  å‰2è¡Œ: \n{matrix[:2]}")
    print(f"  å‰3åˆ—: \n{matrix[:, :3]}")
    print(f"  ä¸­å¿ƒ2Ã—2åŒºåŸŸ: \n{matrix[1:3, 2:4]}")
    print(f"  æ¯éš”ä¸€è¡Œä¸€åˆ—: \n{matrix[::2, ::2]}")
    print(f"  æœ€åä¸€è¡Œ: {matrix[-1, :]}")
    print(f"  æœ€åä¸€åˆ—: {matrix[:, -1]}")
    
    return matrix

# ğŸ”§ é«˜çº§åˆ‡ç‰‡æŠ€å·§
def advanced_slicing():
    """é«˜çº§åˆ‡ç‰‡æŠ€æœ¯"""
    data = np.arange(30).reshape(5, 6)
    print(f"åŸå§‹æ•°æ®:\n{data}")
    
    print(f"\nğŸ”§ é«˜çº§åˆ‡ç‰‡æŠ€å·§:")
    
    # ä½¿ç”¨çœç•¥å·
    print(f"  ä½¿ç”¨çœç•¥å· data[..., :3]: \n{data[..., :3]}")
    
    # æ¡ä»¶åˆ‡ç‰‡
    mask = data > 15
    print(f"  å¤§äº15çš„å…ƒç´ : {data[mask]}")
    
    # å¤šæ¡ä»¶ç»„åˆ
    complex_mask = (data > 10) & (data < 20)
    print(f"  10-20ä¹‹é—´çš„å…ƒç´ : {data[complex_mask]}")
    
    return data

# è¿è¡Œåˆ‡ç‰‡æ¼”ç¤º
one_dimensional_slicing()
print("\n" + "="*50 + "\n")
two_dimensional_slicing()
print("\n" + "="*50 + "\n")
advanced_slicing()
```

### ğŸ­ å¸ƒå°”ç´¢å¼•ï¼šæ™ºèƒ½ç­›é€‰ç³»ç»Ÿ

å¸ƒå°”ç´¢å¼•å°±åƒæ™ºèƒ½ç­›é€‰å™¨ï¼Œèƒ½å¤Ÿæ ¹æ®æ¡ä»¶è‡ªåŠ¨ç­›é€‰å‡ºç¬¦åˆè¦æ±‚çš„æ•°æ®ï¼š

```python
# ğŸ” å¸ƒå°”ç´¢å¼•åŸºç¡€
def boolean_indexing_basics():
    """å¸ƒå°”ç´¢å¼•åŸºç¡€ï¼šæ¡ä»¶ç­›é€‰"""
    scores = np.array([85, 92, 78, 96, 88, 73, 91, 84, 79, 95])
    names = np.array(['Alice', 'Bob', 'Charlie', 'Diana', 'Eve', 
                     'Frank', 'Grace', 'Henry', 'Iris', 'Jack'])
    
    print(f"å­¦ç”Ÿæˆç»©: {scores}")
    print(f"å­¦ç”Ÿå§“å: {names}")
    
    print(f"\nğŸ” å¸ƒå°”ç´¢å¼•ç­›é€‰:")
    
    # å•æ¡ä»¶ç­›é€‰
    high_scores = scores > 90
    print(f"  é«˜åˆ†æ¡ä»¶ (>90): {high_scores}")
    print(f"  é«˜åˆ†å­¦ç”Ÿ: {names[high_scores]}")
    print(f"  é«˜åˆ†æˆç»©: {scores[high_scores]}")
    
    # å¤šæ¡ä»¶ç»„åˆ
    medium_scores = (scores >= 80) & (scores < 90)
    print(f"  ä¸­ç­‰æˆç»©å­¦ç”Ÿ: {names[medium_scores]}")
    print(f"  ä¸­ç­‰æˆç»©åˆ†æ•°: {scores[medium_scores]}")
    
    # æ¡ä»¶ä¿®æ”¹
    scores_copy = scores.copy()
    scores_copy[scores_copy < 80] = 80  # æœ€ä½åˆ†è®¾ä¸º80
    print(f"  è°ƒæ•´åæˆç»©: {scores_copy}")
    
    return scores, names

# ğŸ¯ é«˜çº§å¸ƒå°”ç´¢å¼•
def advanced_boolean_indexing():
    """é«˜çº§å¸ƒå°”ç´¢å¼•ï¼šå¤æ‚æ¡ä»¶ç­›é€‰"""
    # åˆ›å»ºå­¦ç”Ÿæ•°æ®çŸ©é˜µ
    np.random.seed(42)
    students_data = np.random.randint(60, 100, (10, 4))  # 10ä¸ªå­¦ç”Ÿï¼Œ4é—¨è¯¾
    subjects = ['æ•°å­¦', 'ç‰©ç†', 'åŒ–å­¦', 'è‹±è¯­']
    student_names = [f'å­¦ç”Ÿ{i+1}' for i in range(10)]
    
    print(f"å­¦ç”Ÿæˆç»©çŸ©é˜µ (è¡Œ=å­¦ç”Ÿ, åˆ—=ç§‘ç›®):")
    print(f"ç§‘ç›®: {subjects}")
    for i, (name, grades) in enumerate(zip(student_names, students_data)):
        print(f"  {name}: {grades}")
    
    print(f"\nğŸ¯ é«˜çº§ç­›é€‰æ¡ä»¶:")
    
    # å…¨ç§‘åŠæ ¼ (æ‰€æœ‰ç§‘ç›®>=70)
    all_pass = np.all(students_data >= 70, axis=1)
    print(f"  å…¨ç§‘åŠæ ¼å­¦ç”Ÿ: {np.array(student_names)[all_pass]}")
    
    # è‡³å°‘ä¸€ç§‘ä¼˜ç§€ (ä»»ä¸€ç§‘ç›®>=90)
    any_excellent = np.any(students_data >= 90, axis=1)
    print(f"  è‡³å°‘ä¸€ç§‘ä¼˜ç§€: {np.array(student_names)[any_excellent]}")
    
    # æ•°å­¦æˆç»©å‰3å
    math_scores = students_data[:, 0]
    top3_math = np.argsort(math_scores)[-3:][::-1]  # é™åºæ’åˆ—å‰3
    print(f"  æ•°å­¦å‰3å: {np.array(student_names)[top3_math]}")
    print(f"  å¯¹åº”æˆç»©: {math_scores[top3_math]}")
    
    # å¹³å‡åˆ†è¶…è¿‡80çš„å­¦ç”Ÿ
    avg_scores = np.mean(students_data, axis=1)
    high_avg = avg_scores > 80
    print(f"  å¹³å‡åˆ†>80å­¦ç”Ÿ: {np.array(student_names)[high_avg]}")
    print(f"  å¯¹åº”å¹³å‡åˆ†: {avg_scores[high_avg]}")
    
    return students_data, student_names

# è¿è¡Œå¸ƒå°”ç´¢å¼•æ¼”ç¤º
boolean_indexing_basics()
print("\n" + "="*50 + "\n")
advanced_boolean_indexing()
```

### ğŸª èŠ±å¼ç´¢å¼•ï¼šé«˜çº§å®šä½æŠ€æœ¯

èŠ±å¼ç´¢å¼•å°±åƒé­”æœ¯å¸ˆçš„æŠ€å·§ï¼Œèƒ½å¤Ÿç”¨æ•°ç»„ä½œä¸ºç´¢å¼•ï¼Œå®ç°å¤æ‚çš„æ•°æ®è®¿é—®æ¨¡å¼ï¼š

```python
# ğŸª èŠ±å¼ç´¢å¼•åŸºç¡€
def fancy_indexing_basics():
    """èŠ±å¼ç´¢å¼•åŸºç¡€ï¼šæ•°ç»„ç´¢å¼•"""
    data = np.arange(10, 50, 4)  # [10, 14, 18, 22, 26, 30, 34, 38, 42, 46]
    print(f"åŸå§‹æ•°æ®: {data}")
    
    print(f"\nğŸª èŠ±å¼ç´¢å¼•æ“ä½œ:")
    
    # ä½¿ç”¨æ•´æ•°æ•°ç»„ä½œä¸ºç´¢å¼•
    indices = np.array([1, 3, 5, 7])
    print(f"  ç´¢å¼•æ•°ç»„: {indices}")
    print(f"  é€‰æ‹©çš„å…ƒç´ : {data[indices]}")
    
    # ä½¿ç”¨è´Ÿç´¢å¼•
    negative_indices = np.array([-1, -3, -5])
    print(f"  è´Ÿç´¢å¼•: {negative_indices}")
    print(f"  å¯¹åº”å…ƒç´ : {data[negative_indices]}")
    
    # é‡å¤ç´¢å¼•
    repeat_indices = np.array([0, 0, 2, 2, 4, 4])
    print(f"  é‡å¤ç´¢å¼•: {repeat_indices}")
    print(f"  é‡å¤å…ƒç´ : {data[repeat_indices]}")
    
    return data

# ğŸ­ äºŒç»´èŠ±å¼ç´¢å¼•
def fancy_indexing_2d():
    """äºŒç»´æ•°ç»„çš„èŠ±å¼ç´¢å¼•"""
    matrix = np.arange(24).reshape(4, 6)
    print(f"åŸå§‹çŸ©é˜µ:\n{matrix}")
    
    print(f"\nğŸ­ äºŒç»´èŠ±å¼ç´¢å¼•:")
    
    # é€‰æ‹©ç‰¹å®šè¡Œ
    row_indices = np.array([0, 2, 3])
    print(f"  é€‰æ‹©è¡Œ {row_indices}:\n{matrix[row_indices]}")
    
    # é€‰æ‹©ç‰¹å®šå…ƒç´  (è¡Œç´¢å¼•, åˆ—ç´¢å¼•)
    row_idx = np.array([0, 1, 2, 3])
    col_idx = np.array([1, 2, 3, 4])
    print(f"  å¯¹è§’çº¿å…ƒç´ : {matrix[row_idx, col_idx]}")
    
    # ç»„åˆèŠ±å¼ç´¢å¼•å’Œåˆ‡ç‰‡
    selected_rows = np.array([1, 3])
    print(f"  é€‰æ‹©è¡Œ1å’Œ3çš„å‰4åˆ—:\n{matrix[selected_rows, :4]}")
    
    return matrix

# ğŸ”§ èŠ±å¼ç´¢å¼•çš„å®é™…åº”ç”¨
def fancy_indexing_applications():
    """èŠ±å¼ç´¢å¼•çš„å®é™…åº”ç”¨åœºæ™¯"""
    
    # æ•°æ®é‡æ’åº
    data = np.array([100, 85, 92, 78, 96, 88])
    student_ids = np.array(['S001', 'S002', 'S003', 'S004', 'S005', 'S006'])
    
    print(f"åŸå§‹æ•°æ®:")
    print(f"  å­¦ç”ŸID: {student_ids}")
    print(f"  æˆç»©: {data}")
    
    # æŒ‰æˆç»©æ’åº
    sort_indices = np.argsort(data)[::-1]  # é™åºæ’åˆ—
    print(f"\nğŸ“Š æŒ‰æˆç»©æ’åº:")
    print(f"  æ’åºç´¢å¼•: {sort_indices}")
    print(f"  æ’åºåID: {student_ids[sort_indices]}")
    print(f"  æ’åºåæˆç»©: {data[sort_indices]}")
    
    # éšæœºé‡‡æ ·
    np.random.seed(42)
    sample_indices = np.random.choice(len(data), 3, replace=False)
    print(f"\nğŸ² éšæœºé‡‡æ ·:")
    print(f"  é‡‡æ ·ç´¢å¼•: {sample_indices}")
    print(f"  é‡‡æ ·ID: {student_ids[sample_indices]}")
    print(f"  é‡‡æ ·æˆç»©: {data[sample_indices]}")
    
    # æ¡ä»¶é‡ç»„
    high_performers = data > 90
    medium_performers = (data >= 80) & (data <= 90)
    
    print(f"\nğŸ† æ€§èƒ½åˆ†ç»„:")
    print(f"  é«˜åˆ†ç»„: {student_ids[high_performers]}")
    print(f"  ä¸­åˆ†ç»„: {student_ids[medium_performers]}")
    
    return data, student_ids

# è¿è¡ŒèŠ±å¼ç´¢å¼•æ¼”ç¤º
fancy_indexing_basics()
print("\n" + "="*50 + "\n")
fancy_indexing_2d()
print("\n" + "="*50 + "\n")
fancy_indexing_applications()
```

### ğŸ› ï¸ å®æˆ˜é¡¹ç›®ï¼šé«˜æ•ˆæ•°æ®ç­›é€‰å™¨

ç°åœ¨è®©æˆ‘ä»¬æ„å»ºä¸€ä¸ªå®Œæ•´çš„æ•°æ®ç­›é€‰å™¨ï¼Œå±•ç¤ºå„ç§ç´¢å¼•æŠ€æœ¯çš„ç»¼åˆåº”ç”¨ï¼š

```python
import numpy as np
from typing import Dict, List, Tuple, Any, Optional

class DataFilter:
    """é«˜æ•ˆæ•°æ®ç­›é€‰å™¨ï¼šä¸“ä¸šçš„æ•°æ®æŸ¥è¯¢å’Œç­›é€‰å·¥å…·
    
    è¿™ä¸ªç±»æ•´åˆäº†NumPyçš„å„ç§ç´¢å¼•æŠ€æœ¯ï¼Œæä¾›äº†å¼ºå¤§è€Œçµæ´»çš„
    æ•°æ®ç­›é€‰åŠŸèƒ½ï¼Œå°±åƒæ•°æ®åº“çš„æŸ¥è¯¢å¼•æ“ã€‚
    """
    
    def __init__(self, data: np.ndarray, columns: List[str] = None):
        """åˆå§‹åŒ–æ•°æ®ç­›é€‰å™¨
        
        Args:
            data: æ•°æ®çŸ©é˜µ
            columns: åˆ—ååˆ—è¡¨
        """
        self.data = data.copy()
        self.original_data = data.copy()
        self.columns = columns or [f'col_{i}' for i in range(data.shape[1])]
        self.row_count, self.col_count = data.shape
        
        print(f"ğŸ” æ•°æ®ç­›é€‰å™¨å·²åˆå§‹åŒ–")
        print(f"  æ•°æ®å½¢çŠ¶: {self.data.shape}")
        print(f"  åˆ—å: {self.columns}")
    
    def filter_by_condition(self, 
                          column: str, 
                          operator: str, 
                          value: Any) -> 'DataFilter':
        """åŸºäºæ¡ä»¶ç­›é€‰æ•°æ®
        
        Args:
            column: åˆ—å
            operator: æ“ä½œç¬¦ ('>', '<', '>=', '<=', '==', '!=')
            value: æ¯”è¾ƒå€¼
            
        Returns:
            æ–°çš„ç­›é€‰å™¨å®ä¾‹
        """
        if column not in self.columns:
            raise ValueError(f"åˆ— '{column}' ä¸å­˜åœ¨")
        
        col_idx = self.columns.index(column)
        col_data = self.data[:, col_idx]
        
        # æ ¹æ®æ“ä½œç¬¦åˆ›å»ºå¸ƒå°”æ©ç 
        if operator == '>':
            mask = col_data > value
        elif operator == '<':
            mask = col_data < value
        elif operator == '>=':
            mask = col_data >= value
        elif operator == '<=':
            mask = col_data <= value
        elif operator == '==':
            mask = col_data == value
        elif operator == '!=':
            mask = col_data != value
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ“ä½œç¬¦: {operator}")
        
        filtered_data = self.data[mask]
        result = DataFilter(filtered_data, self.columns)
        
        print(f"ğŸ“Š æ¡ä»¶ç­›é€‰: {column} {operator} {value}")
        print(f"  ç­›é€‰å‰: {self.data.shape[0]} è¡Œ")
        print(f"  ç­›é€‰å: {filtered_data.shape[0]} è¡Œ")
        
        return result
    
    def filter_by_range(self, 
                       column: str, 
                       min_val: Any, 
                       max_val: Any, 
                       inclusive: bool = True) -> 'DataFilter':
        """æŒ‰èŒƒå›´ç­›é€‰æ•°æ®
        
        Args:
            column: åˆ—å
            min_val: æœ€å°å€¼
            max_val: æœ€å¤§å€¼
            inclusive: æ˜¯å¦åŒ…å«è¾¹ç•Œå€¼
            
        Returns:
            æ–°çš„ç­›é€‰å™¨å®ä¾‹
        """
        if column not in self.columns:
            raise ValueError(f"åˆ— '{column}' ä¸å­˜åœ¨")
        
        col_idx = self.columns.index(column)
        col_data = self.data[:, col_idx]
        
        if inclusive:
            mask = (col_data >= min_val) & (col_data <= max_val)
        else:
            mask = (col_data > min_val) & (col_data < max_val)
        
        filtered_data = self.data[mask]
        result = DataFilter(filtered_data, self.columns)
        
        boundary = "åŒ…å«" if inclusive else "ä¸åŒ…å«"
        print(f"ğŸ“Š èŒƒå›´ç­›é€‰: {column} âˆˆ [{min_val}, {max_val}] ({boundary}è¾¹ç•Œ)")
        print(f"  ç­›é€‰å‰: {self.data.shape[0]} è¡Œ")
        print(f"  ç­›é€‰å: {filtered_data.shape[0]} è¡Œ")
        
        return result
    
    def filter_by_percentile(self, 
                           column: str, 
                           percentile: float, 
                           above: bool = True) -> 'DataFilter':
        """æŒ‰ç™¾åˆ†ä½æ•°ç­›é€‰
        
        Args:
            column: åˆ—å
            percentile: ç™¾åˆ†ä½æ•° (0-100)
            above: Trueä¸ºé«˜äºè¯¥ç™¾åˆ†ä½æ•°ï¼ŒFalseä¸ºä½äº
            
        Returns:
            æ–°çš„ç­›é€‰å™¨å®ä¾‹
        """
        if column not in self.columns:
            raise ValueError(f"åˆ— '{column}' ä¸å­˜åœ¨")
        
        col_idx = self.columns.index(column)
        col_data = self.data[:, col_idx]
        threshold = np.percentile(col_data, percentile)
        
        if above:
            mask = col_data >= threshold
            direction = "é«˜äº"
        else:
            mask = col_data <= threshold
            direction = "ä½äº"
        
        filtered_data = self.data[mask]
        result = DataFilter(filtered_data, self.columns)
        
        print(f"ğŸ“Š ç™¾åˆ†ä½ç­›é€‰: {column} {direction} {percentile}% åˆ†ä½æ•° ({threshold:.2f})")
        print(f"  ç­›é€‰å‰: {self.data.shape[0]} è¡Œ")
        print(f"  ç­›é€‰å: {filtered_data.shape[0]} è¡Œ")
        
        return result
    
    def select_columns(self, columns: List[str]) -> 'DataFilter':
        """é€‰æ‹©ç‰¹å®šåˆ—
        
        Args:
            columns: è¦é€‰æ‹©çš„åˆ—ååˆ—è¡¨
            
        Returns:
            æ–°çš„ç­›é€‰å™¨å®ä¾‹
        """
        col_indices = []
        for col in columns:
            if col not in self.columns:
                raise ValueError(f"åˆ— '{col}' ä¸å­˜åœ¨")
            col_indices.append(self.columns.index(col))
        
        selected_data = self.data[:, col_indices]
        result = DataFilter(selected_data, columns)
        
        print(f"ğŸ“‹ åˆ—é€‰æ‹©: {columns}")
        print(f"  åŸå§‹åˆ—æ•°: {len(self.columns)}")
        print(f"  é€‰æ‹©åˆ—æ•°: {len(columns)}")
        
        return result
    
    def sample_rows(self, 
                   n: Optional[int] = None, 
                   fraction: Optional[float] = None, 
                   random_state: int = None) -> 'DataFilter':
        """éšæœºé‡‡æ ·è¡Œ
        
        Args:
            n: é‡‡æ ·è¡Œæ•°
            fraction: é‡‡æ ·æ¯”ä¾‹ (0-1)
            random_state: éšæœºç§å­
            
        Returns:
            æ–°çš„ç­›é€‰å™¨å®ä¾‹
        """
        if random_state is not None:
            np.random.seed(random_state)
        
        if n is not None:
            sample_size = min(n, self.data.shape[0])
        elif fraction is not None:
            sample_size = int(self.data.shape[0] * fraction)
        else:
            raise ValueError("å¿…é¡»æŒ‡å®š n æˆ– fraction å‚æ•°")
        
        sample_indices = np.random.choice(self.data.shape[0], sample_size, replace=False)
        sampled_data = self.data[sample_indices]
        result = DataFilter(sampled_data, self.columns)
        
        print(f"ğŸ² éšæœºé‡‡æ ·:")
        print(f"  åŸå§‹è¡Œæ•°: {self.data.shape[0]}")
        print(f"  é‡‡æ ·è¡Œæ•°: {sample_size}")
        
        return result
    
    def sort_by_column(self, 
                      column: str, 
                      ascending: bool = True) -> 'DataFilter':
        """æŒ‰åˆ—æ’åº
        
        Args:
            column: æ’åºåˆ—å
            ascending: æ˜¯å¦å‡åº
            
        Returns:
            æ–°çš„ç­›é€‰å™¨å®ä¾‹
        """
        if column not in self.columns:
            raise ValueError(f"åˆ— '{column}' ä¸å­˜åœ¨")
        
        col_idx = self.columns.index(column)
        sort_indices = np.argsort(self.data[:, col_idx])
        
        if not ascending:
            sort_indices = sort_indices[::-1]
        
        sorted_data = self.data[sort_indices]
        result = DataFilter(sorted_data, self.columns)
        
        order = "å‡åº" if ascending else "é™åº"
        print(f"ğŸ“Š æ’åº: æŒ‰ {column} {order}")
        
        return result
    
    def get_statistics(self, column: str = None) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            column: ç‰¹å®šåˆ—åï¼ŒNoneè¡¨ç¤ºæ‰€æœ‰æ•°å€¼åˆ—
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        if column is not None:
            if column not in self.columns:
                raise ValueError(f"åˆ— '{column}' ä¸å­˜åœ¨")
            col_idx = self.columns.index(column)
            data = self.data[:, col_idx]
            
            stats = {
                'count': len(data),
                'mean': np.mean(data),
                'std': np.std(data),
                'min': np.min(data),
                'max': np.max(data),
                'median': np.median(data),
                'q25': np.percentile(data, 25),
                'q75': np.percentile(data, 75)
            }
            
            print(f"ğŸ“ˆ {column} åˆ—ç»Ÿè®¡:")
            for key, value in stats.items():
                print(f"  {key}: {value:.3f}")
            
        else:
            stats = {}
            for i, col in enumerate(self.columns):
                try:
                    col_data = self.data[:, i].astype(float)
                    stats[col] = {
                        'count': len(col_data),
                        'mean': np.mean(col_data),
                        'std': np.std(col_data),
                        'min': np.min(col_data),
                        'max': np.max(col_data)
                    }
                except (ValueError, TypeError):
                    stats[col] = {'type': 'non-numeric'}
            
            print(f"ğŸ“ˆ å…¨ä½“ç»Ÿè®¡æ‘˜è¦:")
            for col, stat in stats.items():
                if 'mean' in stat:
                    print(f"  {col}: å‡å€¼={stat['mean']:.2f}, æ ‡å‡†å·®={stat['std']:.2f}")
                else:
                    print(f"  {col}: {stat['type']}")
        
        return stats
    
    def to_array(self) -> np.ndarray:
        """è¿”å›å½“å‰æ•°æ®æ•°ç»„"""
        return self.data.copy()
    
    def shape(self) -> Tuple[int, int]:
        """è¿”å›æ•°æ®å½¢çŠ¶"""
        return self.data.shape
    
    def head(self, n: int = 5) -> None:
        """æ˜¾ç¤ºå‰nè¡Œæ•°æ®"""
        print(f"ğŸ“‹ å‰ {n} è¡Œæ•°æ®:")
        print(f"  åˆ—å: {self.columns}")
        for i in range(min(n, self.data.shape[0])):
            print(f"  è¡Œ{i}: {self.data[i]}")

# ğŸš€ æ•°æ®ç­›é€‰å™¨ä½¿ç”¨ç¤ºä¾‹
def demo_data_filter():
    """æ¼”ç¤ºæ•°æ®ç­›é€‰å™¨çš„ä½¿ç”¨"""
    print("ğŸ¯ æ•°æ®ç­›é€‰å™¨æ¼”ç¤º\n")
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®é›†
    np.random.seed(42)
    n_samples = 1000
    
    # ç”Ÿæˆå­¦ç”Ÿæ•°æ®
    ages = np.random.randint(18, 25, n_samples)
    scores = np.random.normal(75, 15, n_samples).clip(0, 100)
    study_hours = np.random.exponential(3, n_samples).clip(0, 10)
    grades = np.random.choice([1, 2, 3, 4], n_samples, p=[0.1, 0.3, 0.4, 0.2])
    
    data = np.column_stack([ages, scores, study_hours, grades])
    columns = ['å¹´é¾„', 'æˆç»©', 'å­¦ä¹ æ—¶é—´', 'å¹´çº§']
    
    # åˆ›å»ºç­›é€‰å™¨
    filter_engine = DataFilter(data, columns)
    
    print("ğŸ” åŸå§‹æ•°æ®æ¦‚è§ˆ:")
    filter_engine.head()
    filter_engine.get_statistics()
    
    print("\n" + "="*60 + "\n")
    
    # æ¼”ç¤ºå„ç§ç­›é€‰æ“ä½œ
    print("ğŸ“Š ç­›é€‰æ¼”ç¤º:")
    
    # 1. æ¡ä»¶ç­›é€‰
    high_scores = filter_engine.filter_by_condition('æˆç»©', '>=', 85)
    high_scores.get_statistics('æˆç»©')
    
    print("\n" + "-"*40 + "\n")
    
    # 2. èŒƒå›´ç­›é€‰
    young_students = filter_engine.filter_by_range('å¹´é¾„', 18, 20)
    young_students.get_statistics('å¹´é¾„')
    
    print("\n" + "-"*40 + "\n")
    
    # 3. ç™¾åˆ†ä½ç­›é€‰
    top_performers = filter_engine.filter_by_percentile('æˆç»©', 90, above=True)
    top_performers.get_statistics('æˆç»©')
    
    print("\n" + "-"*40 + "\n")
    
    # 4. ç»„åˆç­›é€‰
    elite_students = (filter_engine
                     .filter_by_condition('æˆç»©', '>=', 80)
                     .filter_by_condition('å­¦ä¹ æ—¶é—´', '>=', 4)
                     .filter_by_range('å¹´é¾„', 20, 23))
    
    elite_students.head()
    print(f"ç²¾è‹±å­¦ç”Ÿæ•°é‡: {elite_students.shape()[0]}")
    
    print("\n" + "-"*40 + "\n")
    
    # 5. æ’åºå’Œé‡‡æ ·
    sorted_by_score = filter_engine.sort_by_column('æˆç»©', ascending=False)
    top_100 = sorted_by_score.sample_rows(n=100, random_state=42)
    
    top_100.get_statistics('æˆç»©')
    
    return filter_engine

# è¿è¡Œæ¼”ç¤º
if __name__ == "__main__":
    demo_filter = demo_data_filter()
```

### ğŸ’¡ å­¦ä¹ è¦ç‚¹æ€»ç»“

é€šè¿‡æœ¬èŠ‚çš„å­¦ä¹ ï¼Œæˆ‘ä»¬æŒæ¡äº†ï¼š

1. **åŸºç¡€ç´¢å¼•**: ä¸€ç»´ã€äºŒç»´å’Œå¤šç»´æ•°ç»„çš„ç²¾ç¡®å®šä½
2. **æ•°ç»„åˆ‡ç‰‡**: é«˜æ•ˆæå–æ•°æ®å­é›†çš„å„ç§æŠ€å·§
3. **å¸ƒå°”ç´¢å¼•**: åŸºäºæ¡ä»¶çš„æ™ºèƒ½æ•°æ®ç­›é€‰
4. **èŠ±å¼ç´¢å¼•**: ä½¿ç”¨æ•°ç»„ä½œä¸ºç´¢å¼•çš„é«˜çº§æŠ€æœ¯
5. **ç»¼åˆåº”ç”¨**: é€šè¿‡æ•°æ®ç­›é€‰å™¨é¡¹ç›®ï¼Œå­¦ä¼šç»¼åˆè¿ç”¨å„ç§ç´¢å¼•æŠ€æœ¯

### ğŸ¯ æœ¬èŠ‚ç»ƒä¹ 

1. **åŸºç¡€ç»ƒä¹ **: åˆ›å»ºä¸€ä¸ª5Ã—5çŸ©é˜µï¼Œæå–å…¶å¯¹è§’çº¿å…ƒç´ 
2. **è¿›é˜¶ç»ƒä¹ **: ä½¿ç”¨å¸ƒå°”ç´¢å¼•æ‰¾å‡ºçŸ©é˜µä¸­æ‰€æœ‰å¤§äºå¹³å‡å€¼çš„å…ƒç´ 
3. **åº”ç”¨ç»ƒä¹ **: æ‰©å±•æ•°æ®ç­›é€‰å™¨ï¼Œæ·»åŠ æ›´å¤šç­›é€‰æ¡ä»¶å’Œç»Ÿè®¡åŠŸèƒ½

---

## 14.3 æ•°ç»„è®¡ç®—ä¸å¹¿æ’­æœºåˆ¶

### âš¡ å‘é‡åŒ–è®¡ç®—ï¼šå·¥ä¸šæµæ°´çº¿çš„æ•ˆç‡

æƒ³è±¡ä¼ ç»Ÿçš„Pythonå¾ªç¯å°±åƒæ‰‹å·¥ä½œåŠï¼Œä¸€ä¸ªä¸€ä¸ªåœ°å¤„ç†æ•°æ®ï¼›è€ŒNumPyçš„å‘é‡åŒ–è®¡ç®—å°±åƒç°ä»£åŒ–çš„å·¥ä¸šæµæ°´çº¿ï¼Œèƒ½å¤ŸåŒæ—¶å¤„ç†å¤§æ‰¹é‡æ•°æ®ï¼Œæ•ˆç‡æå‡æ•°åå€ç”šè‡³æ•°ç™¾å€ã€‚

```python
import numpy as np
import time

# âš¡ å‘é‡åŒ–è®¡ç®—çš„å¨åŠ›æ¼”ç¤º
def vectorization_demo():
    """æ¼”ç¤ºå‘é‡åŒ–è®¡ç®—çš„å¼ºå¤§å¨åŠ›"""
    size = 1000000
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    a = np.random.random(size)
    b = np.random.random(size)
    
    print(f"ğŸ”¬ å‘é‡åŒ–è®¡ç®—æ€§èƒ½å¯¹æ¯” (æ•°æ®è§„æ¨¡: {size:,})")
    
    # Pythonå¾ªç¯æ–¹å¼
    start_time = time.time()
    result_loop = [a[i] * b[i] + np.sin(a[i]) for i in range(size)]
    python_time = time.time() - start_time
    
    # NumPyå‘é‡åŒ–æ–¹å¼
    start_time = time.time()
    result_vectorized = a * b + np.sin(a)
    numpy_time = time.time() - start_time
    
    print(f"  ğŸŒ Pythonå¾ªç¯: {python_time:.4f}ç§’")
    print(f"  âš¡ NumPyå‘é‡åŒ–: {numpy_time:.4f}ç§’")
    print(f"  ğŸš€ æ€§èƒ½æå‡: {python_time/numpy_time:.1f}å€")

vectorization_demo()
```

### ğŸ“¡ å¹¿æ’­æœºåˆ¶ï¼šæ™ºèƒ½çš„å°ºå¯¸é€‚é…å™¨

å¹¿æ’­æœºåˆ¶è®©ä¸åŒå½¢çŠ¶çš„æ•°ç»„èƒ½å¤Ÿè¿›è¡Œè¿ç®—ï¼Œæ— éœ€æ‰‹åŠ¨è°ƒæ•´å°ºå¯¸ï¼š

```python
# ğŸ“¡ å¹¿æ’­æœºåˆ¶æ¼”ç¤º
def broadcasting_demo():
    """æ¼”ç¤ºNumPyçš„å¹¿æ’­æœºåˆ¶"""
    
    # æ ‡é‡ä¸æ•°ç»„
    arr = np.array([[1, 2, 3], [4, 5, 6]])
    scalar = 10
    print(f"æ•°ç»„ + æ ‡é‡: \n{arr + scalar}")
    
    # ä¸€ç»´ä¸äºŒç»´æ•°ç»„
    arr_2d = np.array([[1, 2, 3], [4, 5, 6]])  # (2, 3)
    arr_1d = np.array([10, 20, 30])            # (3,)
    print(f"2D + 1Då¹¿æ’­: \n{arr_2d + arr_1d}")
    
    # æ•°æ®æ ‡å‡†åŒ–åº”ç”¨
    data = np.random.normal(50, 10, (100, 4))
    mean = np.mean(data, axis=0)  # (4,)
    std = np.std(data, axis=0)    # (4,)
    standardized = (data - mean) / std  # å¹¿æ’­åº”ç”¨
    print(f"æ ‡å‡†åŒ–åå‡å€¼: {np.mean(standardized, axis=0)}")

broadcasting_demo()
```

---

## 14.4 æ•°ç»„é‡å¡‘ä¸é«˜çº§æ“ä½œ

### ğŸ§© æ•°ç»„é‡å¡‘ï¼šåƒé­”æ–¹ä¸€æ ·é‡ç»„æ•°æ®

æ•°ç»„é‡å¡‘å°±åƒç©é­”æ–¹ï¼Œèƒ½å¤Ÿåœ¨ä¸æ”¹å˜æ•°æ®å†…å®¹çš„æƒ…å†µä¸‹ï¼Œé‡æ–°ç»„ç»‡æ•°æ®çš„ç»“æ„ï¼š

```python
# ğŸ§© æ•°ç»„é‡å¡‘æ“ä½œ
def array_reshaping():
    """æ•°ç»„é‡å¡‘æ“ä½œæ¼”ç¤º"""
    
    # åˆ›å»ºåŸå§‹æ•°ç»„
    original = np.arange(24)
    print(f"åŸå§‹æ•°ç»„: {original}")
    print(f"åŸå§‹å½¢çŠ¶: {original.shape}")
    
    # é‡å¡‘ä¸ºä¸åŒå½¢çŠ¶
    reshaped_2d = original.reshape(4, 6)
    reshaped_3d = original.reshape(2, 3, 4)
    
    print(f"é‡å¡‘ä¸º4Ã—6:\n{reshaped_2d}")
    print(f"é‡å¡‘ä¸º2Ã—3Ã—4:\n{reshaped_3d}")
    
    # å±•å¹³æ“ä½œ
    flattened = reshaped_3d.flatten()
    raveled = reshaped_3d.ravel()
    
    print(f"å±•å¹³å: {flattened}")
    print(f"æ˜¯å¦å…±äº«å†…å­˜: {np.shares_memory(reshaped_3d, raveled)}")

array_reshaping()
```

### ğŸ”— æ•°ç»„è¿æ¥ä¸åˆ†å‰²

æ•°ç»„è¿æ¥å°±åƒæ‹¼æ¥ç§¯æœ¨ï¼Œèƒ½å¤Ÿå°†å¤šä¸ªæ•°ç»„ç»„åˆæˆæ›´å¤§çš„æ•°ç»„ï¼š

```python
# ğŸ”— æ•°ç»„è¿æ¥æ“ä½œ
def array_concatenation():
    """æ•°ç»„è¿æ¥æ“ä½œæ¼”ç¤º"""
    
    arr1 = np.array([[1, 2], [3, 4]])
    arr2 = np.array([[5, 6], [7, 8]])
    
    print(f"æ•°ç»„1:\n{arr1}")
    print(f"æ•°ç»„2:\n{arr2}")
    
    # å‚ç›´è¿æ¥
    v_concat = np.vstack([arr1, arr2])
    print(f"å‚ç›´è¿æ¥:\n{v_concat}")
    
    # æ°´å¹³è¿æ¥
    h_concat = np.hstack([arr1, arr2])
    print(f"æ°´å¹³è¿æ¥:\n{h_concat}")
    
    # é€šç”¨è¿æ¥
    concat_axis0 = np.concatenate([arr1, arr2], axis=0)
    concat_axis1 = np.concatenate([arr1, arr2], axis=1)
    
    print(f"axis=0è¿æ¥:\n{concat_axis0}")
    print(f"axis=1è¿æ¥:\n{concat_axis1}")

array_concatenation()
```

### ğŸ§® çº¿æ€§ä»£æ•°è¿ç®—

NumPyæä¾›äº†å®Œæ•´çš„çº¿æ€§ä»£æ•°è¿ç®—åŠŸèƒ½ï¼š

```python
# ğŸ§® çº¿æ€§ä»£æ•°è¿ç®—
def linear_algebra_operations():
    """çº¿æ€§ä»£æ•°è¿ç®—æ¼”ç¤º"""
    
    # åˆ›å»ºçŸ©é˜µ
    A = np.array([[1, 2], [3, 4]])
    B = np.array([[5, 6], [7, 8]])
    
    print(f"çŸ©é˜µA:\n{A}")
    print(f"çŸ©é˜µB:\n{B}")
    
    # çŸ©é˜µä¹˜æ³•
    matrix_mult = np.dot(A, B)
    print(f"çŸ©é˜µä¹˜æ³• AÂ·B:\n{matrix_mult}")
    
    # è½¬ç½®
    A_transpose = A.T
    print(f"Açš„è½¬ç½®:\n{A_transpose}")
    
    # è¡Œåˆ—å¼
    det_A = np.linalg.det(A)
    print(f"Açš„è¡Œåˆ—å¼: {det_A}")
    
    # ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡
    eigenvalues, eigenvectors = np.linalg.eig(A)
    print(f"ç‰¹å¾å€¼: {eigenvalues}")
    print(f"ç‰¹å¾å‘é‡:\n{eigenvectors}")

linear_algebra_operations()
```

## ğŸ“š æœ¬ç« æ€»ç»“

é€šè¿‡æœ¬ç« çš„å­¦ä¹ ï¼Œæˆ‘ä»¬å…¨é¢æŒæ¡äº†NumPyæ•°ç»„è®¡ç®—çš„æ ¸å¿ƒæŠ€èƒ½ï¼š

### ğŸ¯ æ ¸å¿ƒçŸ¥è¯†ç‚¹å›é¡¾

1. **NumPyåŸºç¡€**: æ•°ç»„åˆ›å»ºã€æ•°æ®ç±»å‹ã€å±æ€§ç®¡ç†
2. **ç´¢å¼•åˆ‡ç‰‡**: ç²¾ç¡®çš„æ•°æ®å®šä½å’Œæå–æŠ€æœ¯
3. **æ•°ç»„è®¡ç®—**: å‘é‡åŒ–è¿ç®—å’Œå¹¿æ’­æœºåˆ¶
4. **é«˜çº§æ“ä½œ**: æ•°ç»„é‡å¡‘ã€è¿æ¥åˆ†å‰²ã€çº¿æ€§ä»£æ•°

### ğŸš€ æ€§èƒ½ä¼˜åŠ¿æ€»ç»“

- **è®¡ç®—é€Ÿåº¦**: æ¯”çº¯Pythonæå‡10-100å€
- **å†…å­˜æ•ˆç‡**: æ›´ç´§å‡‘çš„æ•°æ®å­˜å‚¨
- **åŠŸèƒ½ä¸°å¯Œ**: å®Œæ•´çš„ç§‘å­¦è®¡ç®—å‡½æ•°åº“
- **å¹¿æ’­æœºåˆ¶**: æ™ºèƒ½çš„æ•°ç»„è¿ç®—è§„åˆ™

### ğŸ’¡ æœ€ä½³å®è·µ

1. **ä¼˜å…ˆå‘é‡åŒ–**: é¿å…æ˜¾å¼Pythonå¾ªç¯
2. **åˆç†é€‰æ‹©æ•°æ®ç±»å‹**: å¹³è¡¡ç²¾åº¦å’Œå†…å­˜
3. **åˆ©ç”¨å¹¿æ’­**: ç®€åŒ–ä¸åŒå½¢çŠ¶æ•°ç»„çš„è¿ç®—
4. **é¢„åˆ†é…æ•°ç»„**: é¿å…åŠ¨æ€å¢é•¿çš„æ€§èƒ½æŸå¤±

### ğŸ”® åç»­å­¦ä¹ æ–¹å‘

- **Pandas**: åŸºäºNumPyçš„æ•°æ®åˆ†æåº“
- **SciPy**: é«˜çº§ç§‘å­¦è®¡ç®—åŠŸèƒ½
- **Matplotlib**: æ•°æ®å¯è§†åŒ–
- **æœºå™¨å­¦ä¹ **: ç®—æ³•çš„æ•°å€¼è®¡ç®—åŸºç¡€

---

**æ­å–œä½ å®Œæˆäº†NumPyæ•°ç»„è®¡ç®—çš„å­¦ä¹ ï¼** ğŸ‰

ä½ ç°åœ¨å·²ç»å…·å¤‡äº†å¼ºå¤§çš„æ•°å€¼è®¡ç®—èƒ½åŠ›ï¼Œä¸ºæ•°æ®ç§‘å­¦ä¹‹è·¯æ‰“ä¸‹äº†åšå®çš„åŸºç¡€ã€‚æ¥ä¸‹æ¥çš„å­¦ä¹ ä¸­ï¼Œè¿™äº›æŠ€èƒ½å°†æˆä¸ºä½ æ¢ç´¢æ›´é«˜çº§ä¸»é¢˜çš„é‡è¦å·¥å…·ï¼ 